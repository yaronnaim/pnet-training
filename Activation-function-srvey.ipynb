{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Outputs\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Input, Layer, PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACES_PATH = '../data/face_detection/faces/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/face_detection/faces/\n"
     ]
    }
   ],
   "source": [
    "print(FACES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 6000\n",
    "\n",
    "def read_pos_images():\n",
    "    #Read positive images:\n",
    "    path, __, filenames = next(os.walk(FACES_PATH+'pos_train/'))\n",
    "    file_count = training_size #len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[0.0,1.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    file = open(FACES_PATH+'coordinates.txt','r')\n",
    "    lines = file.readlines()\n",
    "    lines = [line[:-1] for line in lines]\n",
    "    #idx=[1,0,3,2]\n",
    "    idx=[0,1,2,3]\n",
    "    f_count = 0\n",
    "    for line in lines:\n",
    "        line = line.split(\" \")\n",
    "        line = line[1]\n",
    "        line=line[1:-1]\n",
    "        line = line.split(\",\")\n",
    "        #Transpose coordinates\n",
    "        x=0\n",
    "        nline=[]\n",
    "        for i in idx:\n",
    "            nline.append(line[i])\n",
    "            x=x+1\n",
    "        line=[[[float(c) for c in nline]]]\n",
    "        coordinates.append(line)\n",
    "        f_count = f_count+1\n",
    "        if f_count == file_count:\n",
    "            break\n",
    "    #Return images, probs, and coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "def read_neg_images():\n",
    "    #Read negative images:\n",
    "    path, __, filenames = next(os.walk(FACES_PATH+'neg_train/'))\n",
    "    file_count = training_size #len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[1.0,0.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    for i in range(file_count):\n",
    "        coordinates.append([[[0.0,0.0,0.0,0.0]]])\n",
    "    #Return images, prob, coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "#Read in all images, probabilities, and coordinates\n",
    "pimages, pprob, pcoordinates = read_pos_images()\n",
    "nimages, nprob, ncoordinates = read_neg_images()\n",
    "o_images=np.append(pimages,nimages,axis=0)\n",
    "o_images=np.reshape(o_images,(-1,12,12,3))\n",
    "o_prob=pprob+nprob\n",
    "o_coordinates=pcoordinates+ncoordinates\n",
    "\n",
    "#Shuffle them up using an index\n",
    "idx=np.arange(len(o_prob))\n",
    "np.random.shuffle(idx)\n",
    "images=np.empty_like(o_images)\n",
    "c=0\n",
    "for i in idx:\n",
    "    images[c]=o_images[i]\n",
    "    c=c+1\n",
    "#images=(np.float32)(images-127.5)/128.0\n",
    "images=(np.float32)(images)/255\n",
    "\n",
    "#images = np.transpose(images, (0, 2, 1, 3)) #Transpose images\n",
    "prob=[]\n",
    "for i in idx:\n",
    "    prob.append(o_prob[i])\n",
    "coordinates=[]\n",
    "for i in idx:\n",
    "    coordinates.append(o_coordinates[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train , Image batch shape  (12000, 12, 12, 3)\n",
      "y_train , Classification ground true batch shape  (12000, 1, 1, 2)\n",
      "y_train , Coordinates ground true batch shape  (12000, 1, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('X_train , Image batch shape ', images.shape)\n",
    "print('y_train , Classification ground true batch shape ' ,np.array(prob).shape)\n",
    "print('y_train , Coordinates ground true batch shape ', np.array(coordinates).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X_data for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape (12000, 12, 12, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X_data shape',X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create \"y_data\" for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.concatenate((np.array(prob), np.array(coordinates)), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data shape (12000, 1, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "print('y_data shape',y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data Classification shape (12000, 1, 1, 2)\n",
      "y_data Coordinate shape (12000, 1, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('y_data Classification shape', y_data[:,:,:,:2].shape)\n",
    "print('y_data Coordinate shape',y_data[:,:,:,2:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide dataset to \"train', \"val\" and \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X, y, training_prec = 0.7, val_prec = 0.1, test_prec = 0.2):\n",
    "        data_length = len(X)\n",
    "        num_training = np.int(data_length * training_prec)\n",
    "        num_validation = np.int(data_length * val_prec)\n",
    "        \n",
    "        mask = range(num_training)\n",
    "        X_train = X[mask]\n",
    "        y_train = y[mask]\n",
    "        mask = range(num_training, num_training + num_validation)\n",
    "        X_val = X[mask]\n",
    "        y_val = y[mask]\n",
    "        mask = range(num_training + num_validation, data_length)\n",
    "        X_test = X[mask]\n",
    "        y_test = y[mask]\n",
    "        \n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (8400, 12, 12, 3)\n",
      "Train labels shape:  (8400, 1, 1, 6) float64\n",
      "Validation data shape:  (1200, 12, 12, 3)\n",
      "Validation labels shape:  (1200, 1, 1, 6)\n",
      "Test data shape:  (2400, 12, 12, 3)\n",
      "Test labels shape:  (2400, 1, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data(X_data, y_data)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build P-Net Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. PReLU activation function (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRelu_PNet():\n",
    "    \n",
    "    initializer = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "    # input layer\n",
    "    visible = Input(shape=(12,12,3))\n",
    "    \n",
    "    # CNN Stage 1\n",
    "    conv1 = Conv2D(10, kernel_size=(3,3))(visible)\n",
    "    prelu1 = PReLU(alpha_initializer='zero', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(prelu1)\n",
    "   \n",
    "    #CNN Stage 2\n",
    "    conv2 = Conv2D(16, kernel_size=(3,3))(pool1)\n",
    "    prelu2 = PReLU(alpha_initializer='zero', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(conv2)\n",
    "    \n",
    "    # CNN stage 3\n",
    "    conv3 = Conv2D(32, kernel_size=(3,3))(prelu2)\n",
    "    prelu3 = PReLU(alpha_initializer='zero', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(conv3)\n",
    "    \n",
    "    # output \n",
    "    pred_classification = Conv2D(2, kernel_size=(1,1), activation='softmax', name='classification')(prelu3)\n",
    "    pred_bbox = Conv2D(4, kernel_size=(1,1), name='bbox')(prelu3)\n",
    "    \n",
    "    model = Model(inputs=visible, outputs=[pred_classification, pred_bbox])\n",
    "                  \n",
    " \n",
    "    #compute the loss function over bounding box \n",
    "    bbox_loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # Define bbox loss : MSE(bounding_bbox) * y_classification[1] (...ignore if no face)\n",
    "    # Actually, \n",
    "    # we could use 'mse' but because bbox error is \"zero\" if \"no face\", we need to multiply 'mse' by \"y_classification\"  \n",
    "    def bbox_loss_fn():\n",
    "            #Create boox loss function \n",
    "        def loss(y_true,y_pred):\n",
    "            return (bbox_loss(pred_bbox, y_bbox) * y_classification[:,:,:,1])\n",
    "        # Return a function\n",
    "        return loss\n",
    "    \n",
    " \n",
    "    # create placeholder for targets\n",
    "    y_classification = tf.keras.backend.placeholder(dtype='float32', shape=pred_classification.shape) # shapes of output1 your target has\n",
    "    y_bbox = tf.keras.backend.placeholder(dtype='float32', shape=pred_bbox.shape) # shapes of output2 your target has\n",
    "    \n",
    "    # Set optimizer\n",
    "    learning_rate = 1e-3\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=adam, \n",
    "                  loss ={'classification': 'binary_crossentropy',\n",
    "                         'bbox': bbox_loss_fn()},\n",
    "                  loss_weights = {'classification': 1.0, \n",
    "                                  'bbox': 0.5},\n",
    "                  target_tensors=[y_classification,y_bbox],\n",
    "                  metrics={'classification': 'accuracy',\n",
    "                           'bbox': 'mse'})\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    # plot graph\n",
    "    plot_model(model, to_file='MTCNN P-Net relu.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 12, 12, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 10, 10, 10)   280         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu (PReLU)                 (None, 10, 10, 10)   10          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 5, 5, 10)     0           p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 3, 3, 16)     1456        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 3, 3, 16)     16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1, 1, 32)     4640        p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 1, 1, 32)     32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classification (Conv2D)         (None, 1, 1, 2)      66          p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bbox (Conv2D)                   (None, 1, 1, 4)      132         p_re_lu_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,632\n",
      "Trainable params: 6,632\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = PRelu_PNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'logs\\\\pnet-benchmark\\\\PReLU'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\\pnet-benchmark\\PReLU20200521-120123\\\n"
     ]
    }
   ],
   "source": [
    "print(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8400 samples, validate on 1200 samples\n",
      "Epoch 1/60\n",
      "8400/8400 [==============================] - 5s 638us/sample - loss: 0.6109 - classification_loss: 0.5857 - bbox_loss: 0.0511 - classification_accuracy: 0.6914 - bbox_mse: 0.1011 - val_loss: 0.4799 - val_classification_loss: 0.4609 - val_bbox_loss: 0.0390 - val_classification_accuracy: 0.8008 - val_bbox_mse: 0.0778\n",
      "Epoch 2/60\n",
      "8400/8400 [==============================] - 3s 311us/sample - loss: 0.4400 - classification_loss: 0.4215 - bbox_loss: 0.0335 - classification_accuracy: 0.8151 - bbox_mse: 0.0671 - val_loss: 0.3684 - val_classification_loss: 0.3572 - val_bbox_loss: 0.0272 - val_classification_accuracy: 0.8517 - val_bbox_mse: 0.0547\n",
      "Epoch 3/60\n",
      "8400/8400 [==============================] - 2s 295us/sample - loss: 0.3730 - classification_loss: 0.3599 - bbox_loss: 0.0270 - classification_accuracy: 0.8496 - bbox_mse: 0.0536 - val_loss: 0.3801 - val_classification_loss: 0.3684 - val_bbox_loss: 0.0272 - val_classification_accuracy: 0.8383 - val_bbox_mse: 0.0547\n",
      "Epoch 4/60\n",
      "8400/8400 [==============================] - 2s 288us/sample - loss: 0.3377 - classification_loss: 0.3254 - bbox_loss: 0.0244 - classification_accuracy: 0.8667 - bbox_mse: 0.0486 - val_loss: 0.3039 - val_classification_loss: 0.2924 - val_bbox_loss: 0.0231 - val_classification_accuracy: 0.8733 - val_bbox_mse: 0.0461\n",
      "Epoch 5/60\n",
      "8400/8400 [==============================] - 3s 304us/sample - loss: 0.3136 - classification_loss: 0.3022 - bbox_loss: 0.0228 - classification_accuracy: 0.8770 - bbox_mse: 0.0453 - val_loss: 0.2815 - val_classification_loss: 0.2707 - val_bbox_loss: 0.0213 - val_classification_accuracy: 0.8808 - val_bbox_mse: 0.0425\n",
      "Epoch 6/60\n",
      "8400/8400 [==============================] - 2s 284us/sample - loss: 0.2919 - classification_loss: 0.2815 - bbox_loss: 0.0213 - classification_accuracy: 0.8850 - bbox_mse: 0.0424 - val_loss: 0.2757 - val_classification_loss: 0.2652 - val_bbox_loss: 0.0201 - val_classification_accuracy: 0.8825 - val_bbox_mse: 0.0404\n",
      "Epoch 7/60\n",
      "8400/8400 [==============================] - 2s 241us/sample - loss: 0.2794 - classification_loss: 0.2690 - bbox_loss: 0.0204 - classification_accuracy: 0.8893 - bbox_mse: 0.0408 - val_loss: 0.2459 - val_classification_loss: 0.2369 - val_bbox_loss: 0.0190 - val_classification_accuracy: 0.8983 - val_bbox_mse: 0.0380\n",
      "Epoch 8/60\n",
      "8400/8400 [==============================] - 2s 253us/sample - loss: 0.2598 - classification_loss: 0.2508 - bbox_loss: 0.0192 - classification_accuracy: 0.8975 - bbox_mse: 0.0382 - val_loss: 0.3173 - val_classification_loss: 0.3054 - val_bbox_loss: 0.0213 - val_classification_accuracy: 0.8658 - val_bbox_mse: 0.0436\n",
      "Epoch 9/60\n",
      "8400/8400 [==============================] - 2s 239us/sample - loss: 0.2468 - classification_loss: 0.2382 - bbox_loss: 0.0183 - classification_accuracy: 0.9025 - bbox_mse: 0.0365 - val_loss: 0.2328 - val_classification_loss: 0.2249 - val_bbox_loss: 0.0176 - val_classification_accuracy: 0.9092 - val_bbox_mse: 0.0350\n",
      "Epoch 10/60\n",
      "8400/8400 [==============================] - 2s 267us/sample - loss: 0.2279 - classification_loss: 0.2203 - bbox_loss: 0.0172 - classification_accuracy: 0.9094 - bbox_mse: 0.0344 - val_loss: 0.2191 - val_classification_loss: 0.2101 - val_bbox_loss: 0.0175 - val_classification_accuracy: 0.9225 - val_bbox_mse: 0.0353cation_loss: 0.2148 - bbox_loss: 0.0170 - classification_accuracy: 0\n",
      "Epoch 11/60\n",
      "8400/8400 [==============================] - 2s 281us/sample - loss: 0.2102 - classification_loss: 0.2027 - bbox_loss: 0.0165 - classification_accuracy: 0.9187 - bbox_mse: 0.0327 - val_loss: 0.1947 - val_classification_loss: 0.1870 - val_bbox_loss: 0.0156 - val_classification_accuracy: 0.9325 - val_bbox_mse: 0.0314\n",
      "Epoch 12/60\n",
      "8400/8400 [==============================] - 2s 264us/sample - loss: 0.2066 - classification_loss: 0.1980 - bbox_loss: 0.0160 - classification_accuracy: 0.9198 - bbox_mse: 0.0319 - val_loss: 0.1996 - val_classification_loss: 0.1925 - val_bbox_loss: 0.0155 - val_classification_accuracy: 0.9242 - val_bbox_mse: 0.0308\n",
      "Epoch 13/60\n",
      "8400/8400 [==============================] - 3s 355us/sample - loss: 0.1861 - classification_loss: 0.1792 - bbox_loss: 0.0149 - classification_accuracy: 0.9281 - bbox_mse: 0.0297 - val_loss: 0.1944 - val_classification_loss: 0.1868 - val_bbox_loss: 0.0155 - val_classification_accuracy: 0.9250 - val_bbox_mse: 0.0311\n",
      "Epoch 14/60\n",
      "8400/8400 [==============================] - 2s 271us/sample - loss: 0.1820 - classification_loss: 0.1743 - bbox_loss: 0.0145 - classification_accuracy: 0.9279 - bbox_mse: 0.0290 - val_loss: 0.1813 - val_classification_loss: 0.1747 - val_bbox_loss: 0.0141 - val_classification_accuracy: 0.9333 - val_bbox_mse: 0.0285\n",
      "Epoch 15/60\n",
      "8400/8400 [==============================] - 2s 252us/sample - loss: 0.1684 - classification_loss: 0.1607 - bbox_loss: 0.0138 - classification_accuracy: 0.9386 - bbox_mse: 0.0274 - val_loss: 0.1827 - val_classification_loss: 0.1751 - val_bbox_loss: 0.0152 - val_classification_accuracy: 0.9308 - val_bbox_mse: 0.0303\n",
      "Epoch 16/60\n",
      "8400/8400 [==============================] - 2s 210us/sample - loss: 0.1599 - classification_loss: 0.1532 - bbox_loss: 0.0135 - classification_accuracy: 0.9394 - bbox_mse: 0.0268 - val_loss: 0.1649 - val_classification_loss: 0.1573 - val_bbox_loss: 0.0140 - val_classification_accuracy: 0.9375 - val_bbox_mse: 0.0279\n",
      "Epoch 17/60\n",
      "8400/8400 [==============================] - 2s 243us/sample - loss: 0.1557 - classification_loss: 0.1485 - bbox_loss: 0.0130 - classification_accuracy: 0.9426 - bbox_mse: 0.0259 - val_loss: 0.1590 - val_classification_loss: 0.1522 - val_bbox_loss: 0.0136 - val_classification_accuracy: 0.9442 - val_bbox_mse: 0.0273\n",
      "Epoch 18/60\n",
      "8400/8400 [==============================] - 2s 238us/sample - loss: 0.1406 - classification_loss: 0.1344 - bbox_loss: 0.0124 - classification_accuracy: 0.9496 - bbox_mse: 0.0245 - val_loss: 0.1490 - val_classification_loss: 0.1422 - val_bbox_loss: 0.0129 - val_classification_accuracy: 0.9467 - val_bbox_mse: 0.0256\n",
      "Epoch 19/60\n",
      "8400/8400 [==============================] - 2s 286us/sample - loss: 0.1398 - classification_loss: 0.1348 - bbox_loss: 0.0124 - classification_accuracy: 0.9477 - bbox_mse: 0.0244 - val_loss: 0.1734 - val_classification_loss: 0.1666 - val_bbox_loss: 0.0133 - val_classification_accuracy: 0.9358 - val_bbox_mse: 0.0267assification_loss: 0.1346 - bbox_loss: 0.0125 - classification_acc\n",
      "Epoch 20/60\n",
      "8400/8400 [==============================] - 2s 290us/sample - loss: 0.1365 - classification_loss: 0.1314 - bbox_loss: 0.0121 - classification_accuracy: 0.9479 - bbox_mse: 0.0240 - val_loss: 0.1502 - val_classification_loss: 0.1450 - val_bbox_loss: 0.0129 - val_classification_accuracy: 0.9492 - val_bbox_mse: 0.0257\n",
      "Epoch 21/60\n",
      "8400/8400 [==============================] - 2s 277us/sample - loss: 0.1257 - classification_loss: 0.1194 - bbox_loss: 0.0116 - classification_accuracy: 0.9574 - bbox_mse: 0.0231 - val_loss: 0.1696 - val_classification_loss: 0.1613 - val_bbox_loss: 0.0138 - val_classification_accuracy: 0.9383 - val_bbox_mse: 0.0278\n",
      "Epoch 22/60\n",
      "8400/8400 [==============================] - 3s 305us/sample - loss: 0.1214 - classification_loss: 0.1159 - bbox_loss: 0.0115 - classification_accuracy: 0.9564 - bbox_mse: 0.0228 - val_loss: 0.1560 - val_classification_loss: 0.1500 - val_bbox_loss: 0.0127 - val_classification_accuracy: 0.9442 - val_bbox_mse: 0.0253s: 0.1106 - bbox_loss: 0.0110 - cl\n",
      "Epoch 23/60\n",
      "8400/8400 [==============================] - 2s 263us/sample - loss: 0.1124 - classification_loss: 0.1062 - bbox_loss: 0.0112 - classification_accuracy: 0.9589 - bbox_mse: 0.0222 - val_loss: 0.1372 - val_classification_loss: 0.1316 - val_bbox_loss: 0.0124 - val_classification_accuracy: 0.9517 - val_bbox_mse: 0.0247\n",
      "Epoch 24/60\n",
      "8400/8400 [==============================] - 2s 247us/sample - loss: 0.1120 - classification_loss: 0.1059 - bbox_loss: 0.0111 - classification_accuracy: 0.9598 - bbox_mse: 0.0221 - val_loss: 0.1382 - val_classification_loss: 0.1316 - val_bbox_loss: 0.0119 - val_classification_accuracy: 0.9508 - val_bbox_mse: 0.0240\n",
      "Epoch 25/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 2s 280us/sample - loss: 0.1049 - classification_loss: 0.0992 - bbox_loss: 0.0108 - classification_accuracy: 0.9617 - bbox_mse: 0.0216 - val_loss: 0.1293 - val_classification_loss: 0.1222 - val_bbox_loss: 0.0114 - val_classification_accuracy: 0.9533 - val_bbox_mse: 0.0231\n",
      "Epoch 26/60\n",
      "8400/8400 [==============================] - 2s 269us/sample - loss: 0.0960 - classification_loss: 0.0911 - bbox_loss: 0.0105 - classification_accuracy: 0.9667 - bbox_mse: 0.0208 - val_loss: 0.1450 - val_classification_loss: 0.1387 - val_bbox_loss: 0.0124 - val_classification_accuracy: 0.9467 - val_bbox_mse: 0.0248\n",
      "Epoch 27/60\n",
      "8400/8400 [==============================] - 2s 256us/sample - loss: 0.0950 - classification_loss: 0.0902 - bbox_loss: 0.0106 - classification_accuracy: 0.9665 - bbox_mse: 0.0210 - val_loss: 0.1347 - val_classification_loss: 0.1291 - val_bbox_loss: 0.0119 - val_classification_accuracy: 0.9517 - val_bbox_mse: 0.0237\n",
      "Epoch 28/60\n",
      "8400/8400 [==============================] - 3s 350us/sample - loss: 0.0944 - classification_loss: 0.0896 - bbox_loss: 0.0106 - classification_accuracy: 0.9675 - bbox_mse: 0.0211 - val_loss: 0.1278 - val_classification_loss: 0.1210 - val_bbox_loss: 0.0121 - val_classification_accuracy: 0.9550 - val_bbox_mse: 0.0248\n",
      "Epoch 29/60\n",
      "8400/8400 [==============================] - 2s 291us/sample - loss: 0.0888 - classification_loss: 0.0846 - bbox_loss: 0.0107 - classification_accuracy: 0.9693 - bbox_mse: 0.0213 - val_loss: 0.1337 - val_classification_loss: 0.1284 - val_bbox_loss: 0.0120 - val_classification_accuracy: 0.9525 - val_bbox_mse: 0.0241\n",
      "Epoch 30/60\n",
      "8400/8400 [==============================] - 2s 218us/sample - loss: 0.0818 - classification_loss: 0.0764 - bbox_loss: 0.0099 - classification_accuracy: 0.9735 - bbox_mse: 0.0196 - val_loss: 0.1391 - val_classification_loss: 0.1324 - val_bbox_loss: 0.0116 - val_classification_accuracy: 0.9517 - val_bbox_mse: 0.0230\n",
      "Epoch 31/60\n",
      "8400/8400 [==============================] - 2s 208us/sample - loss: 0.0778 - classification_loss: 0.0728 - bbox_loss: 0.0099 - classification_accuracy: 0.9730 - bbox_mse: 0.0197 - val_loss: 0.1255 - val_classification_loss: 0.1198 - val_bbox_loss: 0.0112 - val_classification_accuracy: 0.9550 - val_bbox_mse: 0.0224\n",
      "Epoch 32/60\n",
      "8400/8400 [==============================] - 2s 211us/sample - loss: 0.0794 - classification_loss: 0.0742 - bbox_loss: 0.0100 - classification_accuracy: 0.9733 - bbox_mse: 0.0198 - val_loss: 0.1290 - val_classification_loss: 0.1232 - val_bbox_loss: 0.0109 - val_classification_accuracy: 0.9575 - val_bbox_mse: 0.0221\n",
      "Epoch 33/60\n",
      "8400/8400 [==============================] - 2s 205us/sample - loss: 0.0683 - classification_loss: 0.0639 - bbox_loss: 0.0093 - classification_accuracy: 0.9776 - bbox_mse: 0.0186 - val_loss: 0.1215 - val_classification_loss: 0.1156 - val_bbox_loss: 0.0116 - val_classification_accuracy: 0.9542 - val_bbox_mse: 0.0234\n",
      "Epoch 34/60\n",
      "8400/8400 [==============================] - 2s 190us/sample - loss: 0.0662 - classification_loss: 0.0616 - bbox_loss: 0.0095 - classification_accuracy: 0.9781 - bbox_mse: 0.0189 - val_loss: 0.1294 - val_classification_loss: 0.1235 - val_bbox_loss: 0.0111 - val_classification_accuracy: 0.9558 - val_bbox_mse: 0.0221\n",
      "Epoch 35/60\n",
      "8400/8400 [==============================] - 2s 192us/sample - loss: 0.0645 - classification_loss: 0.0598 - bbox_loss: 0.0090 - classification_accuracy: 0.9781 - bbox_mse: 0.0179 - val_loss: 0.1585 - val_classification_loss: 0.1514 - val_bbox_loss: 0.0126 - val_classification_accuracy: 0.9542 - val_bbox_mse: 0.0254\n",
      "Epoch 36/60\n",
      "8400/8400 [==============================] - 3s 359us/sample - loss: 0.0630 - classification_loss: 0.0580 - bbox_loss: 0.0093 - classification_accuracy: 0.9806 - bbox_mse: 0.0186 - val_loss: 0.1110 - val_classification_loss: 0.1046 - val_bbox_loss: 0.0106 - val_classification_accuracy: 0.9600 - val_bbox_mse: 0.0214\n",
      "Epoch 37/60\n",
      "8400/8400 [==============================] - 2s 255us/sample - loss: 0.0622 - classification_loss: 0.0588 - bbox_loss: 0.0093 - classification_accuracy: 0.9788 - bbox_mse: 0.0184 - val_loss: 0.1376 - val_classification_loss: 0.1304 - val_bbox_loss: 0.0114 - val_classification_accuracy: 0.9592 - val_bbox_mse: 0.0232\n",
      "Epoch 38/60\n",
      "8400/8400 [==============================] - 2s 291us/sample - loss: 0.0527 - classification_loss: 0.0488 - bbox_loss: 0.0087 - classification_accuracy: 0.9835 - bbox_mse: 0.0173 - val_loss: 0.1121 - val_classification_loss: 0.1059 - val_bbox_loss: 0.0109 - val_classification_accuracy: 0.9608 - val_bbox_mse: 0.0218\n",
      "Epoch 39/60\n",
      "8400/8400 [==============================] - 3s 303us/sample - loss: 0.0561 - classification_loss: 0.0514 - bbox_loss: 0.0089 - classification_accuracy: 0.9804 - bbox_mse: 0.0177 - val_loss: 0.1400 - val_classification_loss: 0.1336 - val_bbox_loss: 0.0114 - val_classification_accuracy: 0.9525 - val_bbox_mse: 0.0233\n",
      "Epoch 40/60\n",
      "8400/8400 [==============================] - 2s 297us/sample - loss: 0.0502 - classification_loss: 0.0458 - bbox_loss: 0.0085 - classification_accuracy: 0.9845 - bbox_mse: 0.0170 - val_loss: 0.1172 - val_classification_loss: 0.1108 - val_bbox_loss: 0.0107 - val_classification_accuracy: 0.9608 - val_bbox_mse: 0.0212\n",
      "Epoch 41/60\n",
      "8400/8400 [==============================] - 3s 400us/sample - loss: 0.0512 - classification_loss: 0.0466 - bbox_loss: 0.0087 - classification_accuracy: 0.9835 - bbox_mse: 0.0172 - val_loss: 0.1358 - val_classification_loss: 0.1307 - val_bbox_loss: 0.0110 - val_classification_accuracy: 0.9558 - val_bbox_mse: 0.0218\n",
      "Epoch 42/60\n",
      "8400/8400 [==============================] - 2s 285us/sample - loss: 0.0534 - classification_loss: 0.0493 - bbox_loss: 0.0087 - classification_accuracy: 0.9813 - bbox_mse: 0.0173 - val_loss: 0.1144 - val_classification_loss: 0.1081 - val_bbox_loss: 0.0112 - val_classification_accuracy: 0.9617 - val_bbox_mse: 0.0223\n",
      "Epoch 43/60\n",
      "8400/8400 [==============================] - 2s 220us/sample - loss: 0.0432 - classification_loss: 0.0388 - bbox_loss: 0.0084 - classification_accuracy: 0.9876 - bbox_mse: 0.0167 - val_loss: 0.1139 - val_classification_loss: 0.1092 - val_bbox_loss: 0.0103 - val_classification_accuracy: 0.9658 - val_bbox_mse: 0.0207\n",
      "Epoch 44/60\n",
      "8400/8400 [==============================] - 2s 210us/sample - loss: 0.0411 - classification_loss: 0.0372 - bbox_loss: 0.0082 - classification_accuracy: 0.9879 - bbox_mse: 0.0163 - val_loss: 0.1276 - val_classification_loss: 0.1214 - val_bbox_loss: 0.0109 - val_classification_accuracy: 0.9617 - val_bbox_mse: 0.0220\n",
      "Epoch 45/60\n",
      "8400/8400 [==============================] - 2s 198us/sample - loss: 0.0394 - classification_loss: 0.0351 - bbox_loss: 0.0081 - classification_accuracy: 0.9888 - bbox_mse: 0.0162 - val_loss: 0.1080 - val_classification_loss: 0.1025 - val_bbox_loss: 0.0102 - val_classification_accuracy: 0.9667 - val_bbox_mse: 0.0203\n",
      "Epoch 46/60\n",
      "8400/8400 [==============================] - 2s 193us/sample - loss: 0.0369 - classification_loss: 0.0329 - bbox_loss: 0.0080 - classification_accuracy: 0.9889 - bbox_mse: 0.0159 - val_loss: 0.1374 - val_classification_loss: 0.1352 - val_bbox_loss: 0.0110 - val_classification_accuracy: 0.9617 - val_bbox_mse: 0.0220\n",
      "Epoch 47/60\n",
      "8400/8400 [==============================] - 2s 204us/sample - loss: 0.0347 - classification_loss: 0.0306 - bbox_loss: 0.0080 - classification_accuracy: 0.9896 - bbox_mse: 0.0158 - val_loss: 0.1314 - val_classification_loss: 0.1255 - val_bbox_loss: 0.0101 - val_classification_accuracy: 0.9608 - val_bbox_mse: 0.0207\n",
      "Epoch 48/60\n",
      "8400/8400 [==============================] - 2s 192us/sample - loss: 0.0319 - classification_loss: 0.0278 - bbox_loss: 0.0079 - classification_accuracy: 0.9912 - bbox_mse: 0.0158 - val_loss: 0.1142 - val_classification_loss: 0.1082 - val_bbox_loss: 0.0104 - val_classification_accuracy: 0.9650 - val_bbox_mse: 0.0211\n",
      "Epoch 49/60\n",
      "8400/8400 [==============================] - 2s 191us/sample - loss: 0.0318 - classification_loss: 0.0279 - bbox_loss: 0.0078 - classification_accuracy: 0.9908 - bbox_mse: 0.0155 - val_loss: 0.1229 - val_classification_loss: 0.1167 - val_bbox_loss: 0.0101 - val_classification_accuracy: 0.9608 - val_bbox_mse: 0.0204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/60\n",
      "8400/8400 [==============================] - 2s 203us/sample - loss: 0.0304 - classification_loss: 0.0266 - bbox_loss: 0.0077 - classification_accuracy: 0.9921 - bbox_mse: 0.0152 - val_loss: 0.1186 - val_classification_loss: 0.1148 - val_bbox_loss: 0.0110 - val_classification_accuracy: 0.9658 - val_bbox_mse: 0.0221\n",
      "Epoch 51/60\n",
      "8400/8400 [==============================] - 2s 188us/sample - loss: 0.0238 - classification_loss: 0.0200 - bbox_loss: 0.0075 - classification_accuracy: 0.9942 - bbox_mse: 0.0148 - val_loss: 0.1070 - val_classification_loss: 0.1051 - val_bbox_loss: 0.0103 - val_classification_accuracy: 0.9658 - val_bbox_mse: 0.0204\n",
      "Epoch 52/60\n",
      "8400/8400 [==============================] - 2s 198us/sample - loss: 0.0216 - classification_loss: 0.0180 - bbox_loss: 0.0072 - classification_accuracy: 0.9955 - bbox_mse: 0.0143 - val_loss: 0.1121 - val_classification_loss: 0.1058 - val_bbox_loss: 0.0098 - val_classification_accuracy: 0.9658 - val_bbox_mse: 0.0196\n",
      "Epoch 53/60\n",
      "8400/8400 [==============================] - 2s 206us/sample - loss: 0.0245 - classification_loss: 0.0207 - bbox_loss: 0.0074 - classification_accuracy: 0.9931 - bbox_mse: 0.0147 - val_loss: 0.1331 - val_classification_loss: 0.1273 - val_bbox_loss: 0.0107 - val_classification_accuracy: 0.9617 - val_bbox_mse: 0.0217\n",
      "Epoch 54/60\n",
      "8400/8400 [==============================] - 2s 186us/sample - loss: 0.0227 - classification_loss: 0.0190 - bbox_loss: 0.0072 - classification_accuracy: 0.9940 - bbox_mse: 0.0144 - val_loss: 0.1249 - val_classification_loss: 0.1231 - val_bbox_loss: 0.0098 - val_classification_accuracy: 0.9658 - val_bbox_mse: 0.0198\n",
      "Epoch 55/60\n",
      "8400/8400 [==============================] - 2s 187us/sample - loss: 0.0229 - classification_loss: 0.0191 - bbox_loss: 0.0074 - classification_accuracy: 0.9940 - bbox_mse: 0.0146 - val_loss: 0.1106 - val_classification_loss: 0.1048 - val_bbox_loss: 0.0099 - val_classification_accuracy: 0.9642 - val_bbox_mse: 0.0198\n",
      "Epoch 56/60\n",
      "8400/8400 [==============================] - 2s 208us/sample - loss: 0.0205 - classification_loss: 0.0169 - bbox_loss: 0.0072 - classification_accuracy: 0.9952 - bbox_mse: 0.0144 - val_loss: 0.1358 - val_classification_loss: 0.1288 - val_bbox_loss: 0.0106 - val_classification_accuracy: 0.9550 - val_bbox_mse: 0.0213\n",
      "Epoch 57/60\n",
      "8400/8400 [==============================] - 2s 188us/sample - loss: 0.0188 - classification_loss: 0.0152 - bbox_loss: 0.0071 - classification_accuracy: 0.9963 - bbox_mse: 0.0140 - val_loss: 0.1213 - val_classification_loss: 0.1161 - val_bbox_loss: 0.0099 - val_classification_accuracy: 0.9617 - val_bbox_mse: 0.0198\n",
      "Epoch 58/60\n",
      "8400/8400 [==============================] - 2s 193us/sample - loss: 0.0175 - classification_loss: 0.0140 - bbox_loss: 0.0069 - classification_accuracy: 0.9962 - bbox_mse: 0.0138 - val_loss: 0.1213 - val_classification_loss: 0.1156 - val_bbox_loss: 0.0101 - val_classification_accuracy: 0.9658 - val_bbox_mse: 0.0206\n",
      "Epoch 59/60\n",
      "8400/8400 [==============================] - 2s 205us/sample - loss: 0.0255 - classification_loss: 0.0217 - bbox_loss: 0.0074 - classification_accuracy: 0.9921 - bbox_mse: 0.0147 - val_loss: 0.1639 - val_classification_loss: 0.1568 - val_bbox_loss: 0.0111 - val_classification_accuracy: 0.9625 - val_bbox_mse: 0.0225\n",
      "Epoch 60/60\n",
      "8400/8400 [==============================] - 2s 196us/sample - loss: 0.0441 - classification_loss: 0.0412 - bbox_loss: 0.0093 - classification_accuracy: 0.9844 - bbox_mse: 0.0183 - val_loss: 0.1699 - val_classification_loss: 0.1615 - val_bbox_loss: 0.0131 - val_classification_accuracy: 0.9592 - val_bbox_mse: 0.0264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x145af521a88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, [y_train[:,:,:,:2],y_train[:,:,:,2:]], batch_size=64, epochs=60,\n",
    "            validation_data=(X_val, [y_val[:,:,:,:2],y_val[:,:,:,2:]]),\n",
    "            callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ReLU Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu_PNet():\n",
    "    \n",
    "    initializer = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "    # input layer\n",
    "    visible = Input(shape=(12,12,3))\n",
    "    \n",
    "    # CNN Stage 1\n",
    "    conv1 = Conv2D(10, kernel_size=(3,3), activation='relu')(visible)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "   \n",
    "    #CNN Stage 2\n",
    "    conv2 = Conv2D(16, kernel_size=(3,3), activation='relu')(pool1)\n",
    "    \n",
    "    # CNN stage 3\n",
    "    conv3 = Conv2D(32, kernel_size=(3,3), activation='relu')(conv2)\n",
    "    \n",
    "    # output \n",
    "    pred_classification = Conv2D(2, kernel_size=(1,1), activation='softmax', name='classification')(conv3)\n",
    "    pred_bbox = Conv2D(4, kernel_size=(1,1), name='bbox')(conv3)\n",
    "    \n",
    "    model = Model(inputs=visible, outputs=[pred_classification, pred_bbox])\n",
    "                  \n",
    " \n",
    "    #compute the loss function over bounding box \n",
    "    bbox_loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # Define bbox loss : MSE(bounding_bbox) * y_classification[1] (...ignore if no face)\n",
    "    # Actually, \n",
    "    # we could use 'mse' but because bbox error is \"zero\" if \"no face\", we need to multiply 'mse' by \"y_classification\"  \n",
    "    def bbox_loss_fn():\n",
    "            #Create boox loss function \n",
    "        def loss(y_true,y_pred):\n",
    "            return (bbox_loss(pred_bbox, y_bbox) * y_classification[:,:,:,1])\n",
    "        # Return a function\n",
    "        return loss\n",
    "    \n",
    " \n",
    "    # create placeholder for targets\n",
    "    y_classification = tf.keras.backend.placeholder(dtype='float32', shape=pred_classification.shape) # shapes of output1 your target has\n",
    "    y_bbox = tf.keras.backend.placeholder(dtype='float32', shape=pred_bbox.shape) # shapes of output2 your target has\n",
    "    \n",
    "    # Set optimizer\n",
    "    learning_rate = 1e-3\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=adam, \n",
    "                  loss ={'classification': 'binary_crossentropy',\n",
    "                         'bbox': bbox_loss_fn()},\n",
    "                  loss_weights = {'classification': 1.0, \n",
    "                                  'bbox': 0.5},\n",
    "                  target_tensors=[y_classification,y_bbox],\n",
    "                  metrics={'classification': 'accuracy',\n",
    "                           'bbox': 'mse'})\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    # plot graph\n",
    "    plot_model(model, to_file='MTCNN P-Net relu.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 12, 12, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 10)   280         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 10)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 16)     1456        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 1, 1, 32)     4640        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classification (Conv2D)         (None, 1, 1, 2)      66          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bbox (Conv2D)                   (None, 1, 1, 4)      132         conv2d_5[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,574\n",
      "Trainable params: 6,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ReLU_model = Relu_PNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'logs\\\\pnet-benchmark\\\\ReLU'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\\pnet-benchmark\\ReLU20200521-122707\\\n"
     ]
    }
   ],
   "source": [
    "print(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8400 samples, validate on 1200 samples\n",
      "Epoch 1/60\n",
      "8400/8400 [==============================] - 4s 500us/sample - loss: 0.5794 - classification_loss: 0.5574 - bbox_loss: 0.0423 - classification_accuracy: 0.7440 - bbox_mse: 0.0842 - val_loss: 0.5059 - val_classification_loss: 0.4921 - val_bbox_loss: 0.0331 - val_classification_accuracy: 0.7650 - val_bbox_mse: 0.0676\n",
      "Epoch 2/60\n",
      "8400/8400 [==============================] - 2s 224us/sample - loss: 0.4233 - classification_loss: 0.4080 - bbox_loss: 0.0293 - classification_accuracy: 0.8221 - bbox_mse: 0.0584 - val_loss: 0.3908 - val_classification_loss: 0.3781 - val_bbox_loss: 0.0265 - val_classification_accuracy: 0.8342 - val_bbox_mse: 0.0529\n",
      "Epoch 3/60\n",
      "8400/8400 [==============================] - 2s 259us/sample - loss: 0.3583 - classification_loss: 0.3460 - bbox_loss: 0.0256 - classification_accuracy: 0.8579 - bbox_mse: 0.0507 - val_loss: 0.3342 - val_classification_loss: 0.3243 - val_bbox_loss: 0.0234 - val_classification_accuracy: 0.8675 - val_bbox_mse: 0.0476\n",
      "Epoch 4/60\n",
      "8400/8400 [==============================] - 2s 241us/sample - loss: 0.3320 - classification_loss: 0.3198 - bbox_loss: 0.0239 - classification_accuracy: 0.8735 - bbox_mse: 0.0476 - val_loss: 0.3466 - val_classification_loss: 0.3343 - val_bbox_loss: 0.0234 - val_classification_accuracy: 0.8592 - val_bbox_mse: 0.0475\n",
      "Epoch 5/60\n",
      "8400/8400 [==============================] - 2s 185us/sample - loss: 0.3149 - classification_loss: 0.3034 - bbox_loss: 0.0229 - classification_accuracy: 0.8798 - bbox_mse: 0.0455 - val_loss: 0.2941 - val_classification_loss: 0.2825 - val_bbox_loss: 0.0215 - val_classification_accuracy: 0.8858 - val_bbox_mse: 0.0430\n",
      "Epoch 6/60\n",
      "8400/8400 [==============================] - 2s 201us/sample - loss: 0.2932 - classification_loss: 0.2819 - bbox_loss: 0.0216 - classification_accuracy: 0.8851 - bbox_mse: 0.0431 - val_loss: 0.2782 - val_classification_loss: 0.2681 - val_bbox_loss: 0.0205 - val_classification_accuracy: 0.8942 - val_bbox_mse: 0.0410\n",
      "Epoch 7/60\n",
      "8400/8400 [==============================] - 2s 205us/sample - loss: 0.2802 - classification_loss: 0.2688 - bbox_loss: 0.0209 - classification_accuracy: 0.8918 - bbox_mse: 0.0416 - val_loss: 0.2759 - val_classification_loss: 0.2662 - val_bbox_loss: 0.0206 - val_classification_accuracy: 0.9000 - val_bbox_mse: 0.0413\n",
      "Epoch 8/60\n",
      "8400/8400 [==============================] - 2s 193us/sample - loss: 0.2696 - classification_loss: 0.2585 - bbox_loss: 0.0203 - classification_accuracy: 0.8949 - bbox_mse: 0.0405 - val_loss: 0.2639 - val_classification_loss: 0.2544 - val_bbox_loss: 0.0207 - val_classification_accuracy: 0.8942 - val_bbox_mse: 0.0410\n",
      "Epoch 9/60\n",
      "8400/8400 [==============================] - 2s 192us/sample - loss: 0.2496 - classification_loss: 0.2392 - bbox_loss: 0.0195 - classification_accuracy: 0.9040 - bbox_mse: 0.0388 - val_loss: 0.2445 - val_classification_loss: 0.2349 - val_bbox_loss: 0.0200 - val_classification_accuracy: 0.9008 - val_bbox_mse: 0.0399\n",
      "Epoch 10/60\n",
      "8400/8400 [==============================] - 2s 193us/sample - loss: 0.2394 - classification_loss: 0.2311 - bbox_loss: 0.0191 - classification_accuracy: 0.9088 - bbox_mse: 0.0378 - val_loss: 0.2247 - val_classification_loss: 0.2155 - val_bbox_loss: 0.0182 - val_classification_accuracy: 0.9075 - val_bbox_mse: 0.0367\n",
      "Epoch 11/60\n",
      "8400/8400 [==============================] - 1s 177us/sample - loss: 0.2292 - classification_loss: 0.2195 - bbox_loss: 0.0186 - classification_accuracy: 0.9111 - bbox_mse: 0.0371 - val_loss: 0.2320 - val_classification_loss: 0.2212 - val_bbox_loss: 0.0191 - val_classification_accuracy: 0.9125 - val_bbox_mse: 0.0385\n",
      "Epoch 12/60\n",
      "8400/8400 [==============================] - 2s 252us/sample - loss: 0.2159 - classification_loss: 0.2062 - bbox_loss: 0.0179 - classification_accuracy: 0.9163 - bbox_mse: 0.0358 - val_loss: 0.2157 - val_classification_loss: 0.2066 - val_bbox_loss: 0.0184 - val_classification_accuracy: 0.9175 - val_bbox_mse: 0.0371\n",
      "Epoch 13/60\n",
      "8400/8400 [==============================] - 2s 258us/sample - loss: 0.2050 - classification_loss: 0.1969 - bbox_loss: 0.0174 - classification_accuracy: 0.9190 - bbox_mse: 0.0345 - val_loss: 0.2180 - val_classification_loss: 0.2089 - val_bbox_loss: 0.0187 - val_classification_accuracy: 0.9142 - val_bbox_mse: 0.0378\n",
      "Epoch 14/60\n",
      "8400/8400 [==============================] - 2s 203us/sample - loss: 0.1954 - classification_loss: 0.1864 - bbox_loss: 0.0170 - classification_accuracy: 0.9249 - bbox_mse: 0.0340 - val_loss: 0.1912 - val_classification_loss: 0.1839 - val_bbox_loss: 0.0167 - val_classification_accuracy: 0.9283 - val_bbox_mse: 0.0335\n",
      "Epoch 15/60\n",
      "8400/8400 [==============================] - 2s 236us/sample - loss: 0.1917 - classification_loss: 0.1827 - bbox_loss: 0.0170 - classification_accuracy: 0.9276 - bbox_mse: 0.0338 - val_loss: 0.1892 - val_classification_loss: 0.1807 - val_bbox_loss: 0.0164 - val_classification_accuracy: 0.9300 - val_bbox_mse: 0.0334\n",
      "Epoch 16/60\n",
      "8400/8400 [==============================] - 2s 257us/sample - loss: 0.1833 - classification_loss: 0.1751 - bbox_loss: 0.0167 - classification_accuracy: 0.9302 - bbox_mse: 0.0331 - val_loss: 0.1764 - val_classification_loss: 0.1679 - val_bbox_loss: 0.0158 - val_classification_accuracy: 0.9367 - val_bbox_mse: 0.0318\n",
      "Epoch 17/60\n",
      "8400/8400 [==============================] - 2s 272us/sample - loss: 0.1701 - classification_loss: 0.1625 - bbox_loss: 0.0160 - classification_accuracy: 0.9385 - bbox_mse: 0.0317 - val_loss: 0.1771 - val_classification_loss: 0.1688 - val_bbox_loss: 0.0157 - val_classification_accuracy: 0.9350 - val_bbox_mse: 0.0316sification_loss: 0.1641 - bbox_loss: 0.0159 - classification_accuracy: 0.9\n",
      "Epoch 18/60\n",
      "8400/8400 [==============================] - 2s 271us/sample - loss: 0.1685 - classification_loss: 0.1599 - bbox_loss: 0.0157 - classification_accuracy: 0.9376 - bbox_mse: 0.0314 - val_loss: 0.2375 - val_classification_loss: 0.2274 - val_bbox_loss: 0.0193 - val_classification_accuracy: 0.9017 - val_bbox_mse: 0.0391\n",
      "Epoch 19/60\n",
      "8400/8400 [==============================] - 2s 294us/sample - loss: 0.1708 - classification_loss: 0.1622 - bbox_loss: 0.0156 - classification_accuracy: 0.9382 - bbox_mse: 0.0312 - val_loss: 0.1630 - val_classification_loss: 0.1563 - val_bbox_loss: 0.0152 - val_classification_accuracy: 0.9417 - val_bbox_mse: 0.0309\n",
      "Epoch 20/60\n",
      "8400/8400 [==============================] - 2s 293us/sample - loss: 0.1559 - classification_loss: 0.1490 - bbox_loss: 0.0151 - classification_accuracy: 0.9424 - bbox_mse: 0.0300 - val_loss: 0.1673 - val_classification_loss: 0.1591 - val_bbox_loss: 0.0160 - val_classification_accuracy: 0.9433 - val_bbox_mse: 0.0319\n",
      "Epoch 21/60\n",
      "8400/8400 [==============================] - 2s 259us/sample - loss: 0.1445 - classification_loss: 0.1368 - bbox_loss: 0.0143 - classification_accuracy: 0.9482 - bbox_mse: 0.0287 - val_loss: 0.1578 - val_classification_loss: 0.1505 - val_bbox_loss: 0.0156 - val_classification_accuracy: 0.9375 - val_bbox_mse: 0.0313\n",
      "Epoch 22/60\n",
      "8400/8400 [==============================] - 2s 267us/sample - loss: 0.1382 - classification_loss: 0.1314 - bbox_loss: 0.0142 - classification_accuracy: 0.9513 - bbox_mse: 0.0282 - val_loss: 0.1574 - val_classification_loss: 0.1501 - val_bbox_loss: 0.0151 - val_classification_accuracy: 0.9408 - val_bbox_mse: 0.0302\n",
      "Epoch 23/60\n",
      "8400/8400 [==============================] - 3s 298us/sample - loss: 0.1357 - classification_loss: 0.1289 - bbox_loss: 0.0142 - classification_accuracy: 0.9523 - bbox_mse: 0.0280 - val_loss: 0.1396 - val_classification_loss: 0.1328 - val_bbox_loss: 0.0144 - val_classification_accuracy: 0.9508 - val_bbox_mse: 0.0288\n",
      "Epoch 24/60\n",
      "8400/8400 [==============================] - 3s 358us/sample - loss: 0.1335 - classification_loss: 0.1272 - bbox_loss: 0.0138 - classification_accuracy: 0.9526 - bbox_mse: 0.0275 - val_loss: 0.1363 - val_classification_loss: 0.1304 - val_bbox_loss: 0.0142 - val_classification_accuracy: 0.9475 - val_bbox_mse: 0.0284\n",
      "Epoch 25/60\n",
      "8400/8400 [==============================] - 2s 179us/sample - loss: 0.1290 - classification_loss: 0.1218 - bbox_loss: 0.0137 - classification_accuracy: 0.9545 - bbox_mse: 0.0274 - val_loss: 0.1460 - val_classification_loss: 0.1383 - val_bbox_loss: 0.0142 - val_classification_accuracy: 0.9508 - val_bbox_mse: 0.0286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/60\n",
      "8400/8400 [==============================] - 1s 178us/sample - loss: 0.1199 - classification_loss: 0.1132 - bbox_loss: 0.0132 - classification_accuracy: 0.9582 - bbox_mse: 0.0261 - val_loss: 0.1349 - val_classification_loss: 0.1273 - val_bbox_loss: 0.0143 - val_classification_accuracy: 0.9575 - val_bbox_mse: 0.0289\n",
      "Epoch 27/60\n",
      "8400/8400 [==============================] - 1s 147us/sample - loss: 0.1209 - classification_loss: 0.1147 - bbox_loss: 0.0132 - classification_accuracy: 0.9589 - bbox_mse: 0.0262 - val_loss: 0.1374 - val_classification_loss: 0.1299 - val_bbox_loss: 0.0136 - val_classification_accuracy: 0.9542 - val_bbox_mse: 0.0275\n",
      "Epoch 28/60\n",
      "8400/8400 [==============================] - 1s 167us/sample - loss: 0.1098 - classification_loss: 0.1031 - bbox_loss: 0.0128 - classification_accuracy: 0.9639 - bbox_mse: 0.0255 - val_loss: 0.1252 - val_classification_loss: 0.1173 - val_bbox_loss: 0.0133 - val_classification_accuracy: 0.9567 - val_bbox_mse: 0.0266\n",
      "Epoch 29/60\n",
      "8400/8400 [==============================] - 1s 150us/sample - loss: 0.1071 - classification_loss: 0.1008 - bbox_loss: 0.0126 - classification_accuracy: 0.9630 - bbox_mse: 0.0251 - val_loss: 0.1148 - val_classification_loss: 0.1075 - val_bbox_loss: 0.0128 - val_classification_accuracy: 0.9608 - val_bbox_mse: 0.0257\n",
      "Epoch 30/60\n",
      "8400/8400 [==============================] - 1s 161us/sample - loss: 0.1047 - classification_loss: 0.0980 - bbox_loss: 0.0127 - classification_accuracy: 0.9654 - bbox_mse: 0.0252 - val_loss: 0.1270 - val_classification_loss: 0.1200 - val_bbox_loss: 0.0136 - val_classification_accuracy: 0.9558 - val_bbox_mse: 0.0275\n",
      "Epoch 31/60\n",
      "8400/8400 [==============================] - 1s 141us/sample - loss: 0.0969 - classification_loss: 0.0910 - bbox_loss: 0.0122 - classification_accuracy: 0.9700 - bbox_mse: 0.0243 - val_loss: 0.1183 - val_classification_loss: 0.1119 - val_bbox_loss: 0.0126 - val_classification_accuracy: 0.9617 - val_bbox_mse: 0.0258\n",
      "Epoch 32/60\n",
      "8400/8400 [==============================] - 1s 148us/sample - loss: 0.0939 - classification_loss: 0.0899 - bbox_loss: 0.0120 - classification_accuracy: 0.9699 - bbox_mse: 0.0239 - val_loss: 0.1213 - val_classification_loss: 0.1154 - val_bbox_loss: 0.0127 - val_classification_accuracy: 0.9550 - val_bbox_mse: 0.0254\n",
      "Epoch 33/60\n",
      "8400/8400 [==============================] - 1s 162us/sample - loss: 0.0949 - classification_loss: 0.0885 - bbox_loss: 0.0122 - classification_accuracy: 0.9686 - bbox_mse: 0.0244 - val_loss: 0.1088 - val_classification_loss: 0.1026 - val_bbox_loss: 0.0125 - val_classification_accuracy: 0.9650 - val_bbox_mse: 0.0252\n",
      "Epoch 34/60\n",
      "8400/8400 [==============================] - 1s 154us/sample - loss: 0.0930 - classification_loss: 0.0871 - bbox_loss: 0.0119 - classification_accuracy: 0.9718 - bbox_mse: 0.0237 - val_loss: 0.1358 - val_classification_loss: 0.1296 - val_bbox_loss: 0.0133 - val_classification_accuracy: 0.9542 - val_bbox_mse: 0.0267\n",
      "Epoch 35/60\n",
      "8400/8400 [==============================] - 1s 164us/sample - loss: 0.0904 - classification_loss: 0.0846 - bbox_loss: 0.0119 - classification_accuracy: 0.9700 - bbox_mse: 0.0237 - val_loss: 0.1152 - val_classification_loss: 0.1091 - val_bbox_loss: 0.0124 - val_classification_accuracy: 0.9608 - val_bbox_mse: 0.0250\n",
      "Epoch 36/60\n",
      "8400/8400 [==============================] - 1s 145us/sample - loss: 0.0852 - classification_loss: 0.0808 - bbox_loss: 0.0118 - classification_accuracy: 0.9719 - bbox_mse: 0.0234 - val_loss: 0.1120 - val_classification_loss: 0.1058 - val_bbox_loss: 0.0121 - val_classification_accuracy: 0.9658 - val_bbox_mse: 0.0245\n",
      "Epoch 37/60\n",
      "8400/8400 [==============================] - 1s 169us/sample - loss: 0.0804 - classification_loss: 0.0745 - bbox_loss: 0.0116 - classification_accuracy: 0.9749 - bbox_mse: 0.0230 - val_loss: 0.1116 - val_classification_loss: 0.1060 - val_bbox_loss: 0.0120 - val_classification_accuracy: 0.9642 - val_bbox_mse: 0.0241\n",
      "Epoch 38/60\n",
      "8400/8400 [==============================] - 1s 170us/sample - loss: 0.0764 - classification_loss: 0.0705 - bbox_loss: 0.0114 - classification_accuracy: 0.9774 - bbox_mse: 0.0227 - val_loss: 0.1531 - val_classification_loss: 0.1451 - val_bbox_loss: 0.0133 - val_classification_accuracy: 0.9517 - val_bbox_mse: 0.0267\n",
      "Epoch 39/60\n",
      "8400/8400 [==============================] - 2s 182us/sample - loss: 0.0817 - classification_loss: 0.0755 - bbox_loss: 0.0117 - classification_accuracy: 0.9752 - bbox_mse: 0.0232 - val_loss: 0.1348 - val_classification_loss: 0.1276 - val_bbox_loss: 0.0128 - val_classification_accuracy: 0.9525 - val_bbox_mse: 0.0258\n",
      "Epoch 40/60\n",
      "8400/8400 [==============================] - 1s 165us/sample - loss: 0.0735 - classification_loss: 0.0675 - bbox_loss: 0.0114 - classification_accuracy: 0.9774 - bbox_mse: 0.0226 - val_loss: 0.0991 - val_classification_loss: 0.0921 - val_bbox_loss: 0.0120 - val_classification_accuracy: 0.9633 - val_bbox_mse: 0.0240\n",
      "Epoch 41/60\n",
      "8400/8400 [==============================] - 1s 171us/sample - loss: 0.0749 - classification_loss: 0.0701 - bbox_loss: 0.0114 - classification_accuracy: 0.9767 - bbox_mse: 0.0226 - val_loss: 0.1276 - val_classification_loss: 0.1218 - val_bbox_loss: 0.0131 - val_classification_accuracy: 0.9542 - val_bbox_mse: 0.0259\n",
      "Epoch 42/60\n",
      "8400/8400 [==============================] - 1s 160us/sample - loss: 0.0790 - classification_loss: 0.0733 - bbox_loss: 0.0118 - classification_accuracy: 0.9750 - bbox_mse: 0.0233 - val_loss: 0.1345 - val_classification_loss: 0.1272 - val_bbox_loss: 0.0134 - val_classification_accuracy: 0.9542 - val_bbox_mse: 0.0269\n",
      "Epoch 43/60\n",
      "8400/8400 [==============================] - 1s 158us/sample - loss: 0.0690 - classification_loss: 0.0632 - bbox_loss: 0.0112 - classification_accuracy: 0.9785 - bbox_mse: 0.0223 - val_loss: 0.1004 - val_classification_loss: 0.0931 - val_bbox_loss: 0.0121 - val_classification_accuracy: 0.9683 - val_bbox_mse: 0.0247\n",
      "Epoch 44/60\n",
      "8400/8400 [==============================] - 1s 165us/sample - loss: 0.0632 - classification_loss: 0.0574 - bbox_loss: 0.0110 - classification_accuracy: 0.9811 - bbox_mse: 0.0219 - val_loss: 0.1045 - val_classification_loss: 0.0979 - val_bbox_loss: 0.0123 - val_classification_accuracy: 0.9642 - val_bbox_mse: 0.0248\n",
      "Epoch 45/60\n",
      "8400/8400 [==============================] - 1s 156us/sample - loss: 0.0603 - classification_loss: 0.0550 - bbox_loss: 0.0108 - classification_accuracy: 0.9826 - bbox_mse: 0.0216 - val_loss: 0.1000 - val_classification_loss: 0.0938 - val_bbox_loss: 0.0119 - val_classification_accuracy: 0.9683 - val_bbox_mse: 0.0238\n",
      "Epoch 46/60\n",
      "8400/8400 [==============================] - 1s 151us/sample - loss: 0.0593 - classification_loss: 0.0536 - bbox_loss: 0.0108 - classification_accuracy: 0.9817 - bbox_mse: 0.0215 - val_loss: 0.1334 - val_classification_loss: 0.1272 - val_bbox_loss: 0.0131 - val_classification_accuracy: 0.9558 - val_bbox_mse: 0.0263\n",
      "Epoch 47/60\n",
      "8400/8400 [==============================] - 1s 169us/sample - loss: 0.0580 - classification_loss: 0.0549 - bbox_loss: 0.0109 - classification_accuracy: 0.9818 - bbox_mse: 0.0214 - val_loss: 0.1139 - val_classification_loss: 0.1067 - val_bbox_loss: 0.0135 - val_classification_accuracy: 0.9617 - val_bbox_mse: 0.0270\n",
      "Epoch 48/60\n",
      "8400/8400 [==============================] - 1s 168us/sample - loss: 0.0683 - classification_loss: 0.0623 - bbox_loss: 0.0116 - classification_accuracy: 0.9757 - bbox_mse: 0.0230 - val_loss: 0.0901 - val_classification_loss: 0.0844 - val_bbox_loss: 0.0116 - val_classification_accuracy: 0.9717 - val_bbox_mse: 0.0232\n",
      "Epoch 49/60\n",
      "8400/8400 [==============================] - 3s 314us/sample - loss: 0.0532 - classification_loss: 0.0478 - bbox_loss: 0.0109 - classification_accuracy: 0.9840 - bbox_mse: 0.0216 - val_loss: 0.1247 - val_classification_loss: 0.1182 - val_bbox_loss: 0.0126 - val_classification_accuracy: 0.9617 - val_bbox_mse: 0.0255\n",
      "Epoch 50/60\n",
      "8400/8400 [==============================] - 3s 318us/sample - loss: 0.0527 - classification_loss: 0.0471 - bbox_loss: 0.0107 - classification_accuracy: 0.9851 - bbox_mse: 0.0214 - val_loss: 0.1098 - val_classification_loss: 0.1031 - val_bbox_loss: 0.0118 - val_classification_accuracy: 0.9642 - val_bbox_mse: 0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/60\n",
      "8400/8400 [==============================] - 1s 143us/sample - loss: 0.0514 - classification_loss: 0.0462 - bbox_loss: 0.0108 - classification_accuracy: 0.9849 - bbox_mse: 0.0216 - val_loss: 0.1099 - val_classification_loss: 0.1028 - val_bbox_loss: 0.0125 - val_classification_accuracy: 0.9650 - val_bbox_mse: 0.0253\n",
      "Epoch 52/60\n",
      "8400/8400 [==============================] - 2s 199us/sample - loss: 0.0490 - classification_loss: 0.0434 - bbox_loss: 0.0108 - classification_accuracy: 0.9860 - bbox_mse: 0.0216 - val_loss: 0.0883 - val_classification_loss: 0.0817 - val_bbox_loss: 0.0119 - val_classification_accuracy: 0.9675 - val_bbox_mse: 0.0238\n",
      "Epoch 53/60\n",
      "8400/8400 [==============================] - 2s 227us/sample - loss: 0.0459 - classification_loss: 0.0404 - bbox_loss: 0.0108 - classification_accuracy: 0.9871 - bbox_mse: 0.0215 - val_loss: 0.1042 - val_classification_loss: 0.0987 - val_bbox_loss: 0.0120 - val_classification_accuracy: 0.9633 - val_bbox_mse: 0.0241\n",
      "Epoch 54/60\n",
      "8400/8400 [==============================] - 1s 148us/sample - loss: 0.0460 - classification_loss: 0.0418 - bbox_loss: 0.0107 - classification_accuracy: 0.9870 - bbox_mse: 0.0213 - val_loss: 0.1179 - val_classification_loss: 0.1124 - val_bbox_loss: 0.0130 - val_classification_accuracy: 0.9558 - val_bbox_mse: 0.0258\n",
      "Epoch 55/60\n",
      "8400/8400 [==============================] - 1s 150us/sample - loss: 0.0501 - classification_loss: 0.0446 - bbox_loss: 0.0107 - classification_accuracy: 0.9852 - bbox_mse: 0.0215 - val_loss: 0.0970 - val_classification_loss: 0.0918 - val_bbox_loss: 0.0118 - val_classification_accuracy: 0.9700 - val_bbox_mse: 0.0238\n",
      "Epoch 56/60\n",
      "8400/8400 [==============================] - 2s 257us/sample - loss: 0.0378 - classification_loss: 0.0326 - bbox_loss: 0.0104 - classification_accuracy: 0.9902 - bbox_mse: 0.0206 - val_loss: 0.0912 - val_classification_loss: 0.0853 - val_bbox_loss: 0.0117 - val_classification_accuracy: 0.9708 - val_bbox_mse: 0.0235\n",
      "Epoch 57/60\n",
      "8400/8400 [==============================] - 1s 176us/sample - loss: 0.0419 - classification_loss: 0.0365 - bbox_loss: 0.0105 - classification_accuracy: 0.9885 - bbox_mse: 0.0209 - val_loss: 0.0902 - val_classification_loss: 0.0838 - val_bbox_loss: 0.0121 - val_classification_accuracy: 0.9633 - val_bbox_mse: 0.0241\n",
      "Epoch 58/60\n",
      "8400/8400 [==============================] - 2s 224us/sample - loss: 0.0462 - classification_loss: 0.0411 - bbox_loss: 0.0106 - classification_accuracy: 0.9858 - bbox_mse: 0.0212 - val_loss: 0.0946 - val_classification_loss: 0.0879 - val_bbox_loss: 0.0120 - val_classification_accuracy: 0.9667 - val_bbox_mse: 0.0240\n",
      "Epoch 59/60\n",
      "8400/8400 [==============================] - 3s 346us/sample - loss: 0.0381 - classification_loss: 0.0327 - bbox_loss: 0.0104 - classification_accuracy: 0.9895 - bbox_mse: 0.0208 - val_loss: 0.0894 - val_classification_loss: 0.0837 - val_bbox_loss: 0.0115 - val_classification_accuracy: 0.9700 - val_bbox_mse: 0.0233\n",
      "Epoch 60/60\n",
      "8400/8400 [==============================] - 2s 248us/sample - loss: 0.0458 - classification_loss: 0.0402 - bbox_loss: 0.0109 - classification_accuracy: 0.9855 - bbox_mse: 0.0217 - val_loss: 0.1007 - val_classification_loss: 0.0947 - val_bbox_loss: 0.0120 - val_classification_accuracy: 0.9692 - val_bbox_mse: 0.0241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x145af5321c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLU_model.fit(X_train, [y_train[:,:,:,:2],y_train[:,:,:,2:]], batch_size=64, epochs=60,\n",
    "            validation_data=(X_val, [y_val[:,:,:,:2],y_val[:,:,:,2:]]),\n",
    "            callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TanH Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TanH_PNet():\n",
    "    \n",
    "    initializer = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "    # input layer\n",
    "    visible = Input(shape=(12,12,3))\n",
    "    \n",
    "    # CNN Stage 1\n",
    "    conv1 = Conv2D(10, kernel_size=(3,3), activation='tanh')(visible)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "   \n",
    "    #CNN Stage 2\n",
    "    conv2 = Conv2D(16, kernel_size=(3,3), activation='tanh')(pool1)\n",
    "    \n",
    "    # CNN stage 3\n",
    "    conv3 = Conv2D(32, kernel_size=(3,3), activation='tanh')(conv2)\n",
    "    \n",
    "    # output \n",
    "    pred_classification = Conv2D(2, kernel_size=(1,1), activation='softmax', name='classification')(conv3)\n",
    "    pred_bbox = Conv2D(4, kernel_size=(1,1), name='bbox')(conv3)\n",
    "    \n",
    "    model = Model(inputs=visible, outputs=[pred_classification, pred_bbox])\n",
    "                  \n",
    " \n",
    "    #compute the loss function over bounding box \n",
    "    bbox_loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # Define bbox loss : MSE(bounding_bbox) * y_classification[1] (...ignore if no face)\n",
    "    # Actually, \n",
    "    # we could use 'mse' but because bbox error is \"zero\" if \"no face\", we need to multiply 'mse' by \"y_classification\"  \n",
    "    def bbox_loss_fn():\n",
    "            #Create boox loss function \n",
    "        def loss(y_true,y_pred):\n",
    "            return (bbox_loss(pred_bbox, y_bbox) * y_classification[:,:,:,1])\n",
    "        # Return a function\n",
    "        return loss\n",
    "    \n",
    " \n",
    "    # create placeholder for targets\n",
    "    y_classification = tf.keras.backend.placeholder(dtype='float32', shape=pred_classification.shape) # shapes of output1 your target has\n",
    "    y_bbox = tf.keras.backend.placeholder(dtype='float32', shape=pred_bbox.shape) # shapes of output2 your target has\n",
    "    \n",
    "    # Set optimizer\n",
    "    learning_rate = 1e-3\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=adam, \n",
    "                  loss ={'classification': 'binary_crossentropy',\n",
    "                         'bbox': bbox_loss_fn()},\n",
    "                  loss_weights = {'classification': 1.0, \n",
    "                                  'bbox': 0.5},\n",
    "                  target_tensors=[y_classification,y_bbox],\n",
    "                  metrics={'classification': 'accuracy',\n",
    "                           'bbox': 'mse'})\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    # plot graph\n",
    "    plot_model(model, to_file='MTCNN P-Net tanh.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 12, 12, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 10)   280         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 10)     0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 3, 3, 16)     1456        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1, 1, 32)     4640        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classification (Conv2D)         (None, 1, 1, 2)      66          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bbox (Conv2D)                   (None, 1, 1, 4)      132         conv2d_8[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,574\n",
      "Trainable params: 6,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "TanH_model = TanH_PNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=('logs\\\\pnet-benchmark\\\\TanH'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8400 samples, validate on 1200 samples\n",
      "Epoch 1/60\n",
      "8400/8400 [==============================] - 3s 316us/sample - loss: 0.5399 - classification_loss: 0.5171 - bbox_loss: 0.0442 - classification_accuracy: 0.7640 - bbox_mse: 0.0873 - val_loss: 0.4854 - val_classification_loss: 0.4664 - val_bbox_loss: 0.0354 - val_classification_accuracy: 0.8067 - val_bbox_mse: 0.0720\n",
      "Epoch 2/60\n",
      "8400/8400 [==============================] - 1s 155us/sample - loss: 0.4488 - classification_loss: 0.4333 - bbox_loss: 0.0319 - classification_accuracy: 0.8182 - bbox_mse: 0.0638 - val_loss: 0.4435 - val_classification_loss: 0.4277 - val_bbox_loss: 0.0312 - val_classification_accuracy: 0.7950 - val_bbox_mse: 0.0628\n",
      "Epoch 3/60\n",
      "8400/8400 [==============================] - 1s 134us/sample - loss: 0.3942 - classification_loss: 0.3804 - bbox_loss: 0.0281 - classification_accuracy: 0.8470 - bbox_mse: 0.0563 - val_loss: 0.3943 - val_classification_loss: 0.3819 - val_bbox_loss: 0.0279 - val_classification_accuracy: 0.8350 - val_bbox_mse: 0.0564\n",
      "Epoch 4/60\n",
      "8400/8400 [==============================] - 1s 131us/sample - loss: 0.3569 - classification_loss: 0.3437 - bbox_loss: 0.0250 - classification_accuracy: 0.8587 - bbox_mse: 0.0501 - val_loss: 0.3728 - val_classification_loss: 0.3615 - val_bbox_loss: 0.0265 - val_classification_accuracy: 0.8392 - val_bbox_mse: 0.0523\n",
      "Epoch 5/60\n",
      "8400/8400 [==============================] - 1s 131us/sample - loss: 0.3319 - classification_loss: 0.3213 - bbox_loss: 0.0235 - classification_accuracy: 0.8683 - bbox_mse: 0.0467 - val_loss: 0.3359 - val_classification_loss: 0.3247 - val_bbox_loss: 0.0234 - val_classification_accuracy: 0.8658 - val_bbox_mse: 0.0469\n",
      "Epoch 6/60\n",
      "8400/8400 [==============================] - 1s 171us/sample - loss: 0.3185 - classification_loss: 0.3077 - bbox_loss: 0.0228 - classification_accuracy: 0.8757 - bbox_mse: 0.0452 - val_loss: 0.3312 - val_classification_loss: 0.3215 - val_bbox_loss: 0.0236 - val_classification_accuracy: 0.8592 - val_bbox_mse: 0.0472\n",
      "Epoch 7/60\n",
      "8400/8400 [==============================] - 2s 184us/sample - loss: 0.3019 - classification_loss: 0.2900 - bbox_loss: 0.0218 - classification_accuracy: 0.8843 - bbox_mse: 0.0436 - val_loss: 0.3644 - val_classification_loss: 0.3526 - val_bbox_loss: 0.0254 - val_classification_accuracy: 0.8550 - val_bbox_mse: 0.0519\n",
      "Epoch 8/60\n",
      "8400/8400 [==============================] - 1s 176us/sample - loss: 0.2962 - classification_loss: 0.2855 - bbox_loss: 0.0216 - classification_accuracy: 0.8879 - bbox_mse: 0.0430 - val_loss: 0.3247 - val_classification_loss: 0.3112 - val_bbox_loss: 0.0228 - val_classification_accuracy: 0.8642 - val_bbox_mse: 0.0459\n",
      "Epoch 9/60\n",
      "8400/8400 [==============================] - 1s 141us/sample - loss: 0.2856 - classification_loss: 0.2753 - bbox_loss: 0.0210 - classification_accuracy: 0.8880 - bbox_mse: 0.0419 - val_loss: 0.3154 - val_classification_loss: 0.3024 - val_bbox_loss: 0.0224 - val_classification_accuracy: 0.8742 - val_bbox_mse: 0.0450\n",
      "Epoch 10/60\n",
      "8400/8400 [==============================] - 1s 143us/sample - loss: 0.2792 - classification_loss: 0.2692 - bbox_loss: 0.0209 - classification_accuracy: 0.8911 - bbox_mse: 0.0413 - val_loss: 0.2952 - val_classification_loss: 0.2848 - val_bbox_loss: 0.0210 - val_classification_accuracy: 0.8783 - val_bbox_mse: 0.0423\n",
      "Epoch 11/60\n",
      "8400/8400 [==============================] - 1s 135us/sample - loss: 0.2742 - classification_loss: 0.2648 - bbox_loss: 0.0206 - classification_accuracy: 0.8917 - bbox_mse: 0.0409 - val_loss: 0.3067 - val_classification_loss: 0.2945 - val_bbox_loss: 0.0229 - val_classification_accuracy: 0.8833 - val_bbox_mse: 0.0464\n",
      "Epoch 12/60\n",
      "8400/8400 [==============================] - 1s 143us/sample - loss: 0.2708 - classification_loss: 0.2601 - bbox_loss: 0.0206 - classification_accuracy: 0.8951 - bbox_mse: 0.0409 - val_loss: 0.2934 - val_classification_loss: 0.2828 - val_bbox_loss: 0.0212 - val_classification_accuracy: 0.8883 - val_bbox_mse: 0.0425\n",
      "Epoch 13/60\n",
      "8400/8400 [==============================] - 1s 176us/sample - loss: 0.2585 - classification_loss: 0.2495 - bbox_loss: 0.0199 - classification_accuracy: 0.9005 - bbox_mse: 0.0395 - val_loss: 0.2908 - val_classification_loss: 0.2815 - val_bbox_loss: 0.0214 - val_classification_accuracy: 0.8808 - val_bbox_mse: 0.0425\n",
      "Epoch 14/60\n",
      "8400/8400 [==============================] - 2s 190us/sample - loss: 0.2522 - classification_loss: 0.2422 - bbox_loss: 0.0196 - classification_accuracy: 0.9008 - bbox_mse: 0.0391 - val_loss: 0.2899 - val_classification_loss: 0.2786 - val_bbox_loss: 0.0214 - val_classification_accuracy: 0.8808 - val_bbox_mse: 0.0429\n",
      "Epoch 15/60\n",
      "8400/8400 [==============================] - 2s 182us/sample - loss: 0.2467 - classification_loss: 0.2366 - bbox_loss: 0.0193 - classification_accuracy: 0.9021 - bbox_mse: 0.0386 - val_loss: 0.2840 - val_classification_loss: 0.2735 - val_bbox_loss: 0.0203 - val_classification_accuracy: 0.8842 - val_bbox_mse: 0.0411\n",
      "Epoch 16/60\n",
      "8400/8400 [==============================] - 2s 200us/sample - loss: 0.2443 - classification_loss: 0.2344 - bbox_loss: 0.0190 - classification_accuracy: 0.9061 - bbox_mse: 0.0380 - val_loss: 0.2742 - val_classification_loss: 0.2649 - val_bbox_loss: 0.0204 - val_classification_accuracy: 0.8983 - val_bbox_mse: 0.0409\n",
      "Epoch 17/60\n",
      "8400/8400 [==============================] - 2s 187us/sample - loss: 0.2387 - classification_loss: 0.2300 - bbox_loss: 0.0188 - classification_accuracy: 0.9048 - bbox_mse: 0.0375 - val_loss: 0.2880 - val_classification_loss: 0.2778 - val_bbox_loss: 0.0200 - val_classification_accuracy: 0.8917 - val_bbox_mse: 0.0404\n",
      "Epoch 18/60\n",
      "8400/8400 [==============================] - 1s 144us/sample - loss: 0.2286 - classification_loss: 0.2189 - bbox_loss: 0.0183 - classification_accuracy: 0.9086 - bbox_mse: 0.0365 - val_loss: 0.2578 - val_classification_loss: 0.2510 - val_bbox_loss: 0.0193 - val_classification_accuracy: 0.9033 - val_bbox_mse: 0.0384\n",
      "Epoch 19/60\n",
      "8400/8400 [==============================] - 1s 148us/sample - loss: 0.2277 - classification_loss: 0.2190 - bbox_loss: 0.0182 - classification_accuracy: 0.9111 - bbox_mse: 0.0364 - val_loss: 0.2669 - val_classification_loss: 0.2577 - val_bbox_loss: 0.0191 - val_classification_accuracy: 0.8967 - val_bbox_mse: 0.0385\n",
      "Epoch 20/60\n",
      "8400/8400 [==============================] - 1s 148us/sample - loss: 0.2168 - classification_loss: 0.2074 - bbox_loss: 0.0178 - classification_accuracy: 0.9155 - bbox_mse: 0.0355 - val_loss: 0.2559 - val_classification_loss: 0.2448 - val_bbox_loss: 0.0184 - val_classification_accuracy: 0.8975 - val_bbox_mse: 0.0374\n",
      "Epoch 21/60\n",
      "8400/8400 [==============================] - 1s 152us/sample - loss: 0.2169 - classification_loss: 0.2085 - bbox_loss: 0.0178 - classification_accuracy: 0.9174 - bbox_mse: 0.0355 - val_loss: 0.2429 - val_classification_loss: 0.2340 - val_bbox_loss: 0.0183 - val_classification_accuracy: 0.8975 - val_bbox_mse: 0.0369\n",
      "Epoch 22/60\n",
      "8400/8400 [==============================] - 1s 143us/sample - loss: 0.2098 - classification_loss: 0.2005 - bbox_loss: 0.0174 - classification_accuracy: 0.9188 - bbox_mse: 0.0347 - val_loss: 0.2645 - val_classification_loss: 0.2552 - val_bbox_loss: 0.0189 - val_classification_accuracy: 0.9050 - val_bbox_mse: 0.0382\n",
      "Epoch 23/60\n",
      "8400/8400 [==============================] - 1s 146us/sample - loss: 0.2023 - classification_loss: 0.1954 - bbox_loss: 0.0173 - classification_accuracy: 0.9215 - bbox_mse: 0.0345 - val_loss: 0.2443 - val_classification_loss: 0.2342 - val_bbox_loss: 0.0181 - val_classification_accuracy: 0.9050 - val_bbox_mse: 0.0367\n",
      "Epoch 24/60\n",
      "8400/8400 [==============================] - 1s 143us/sample - loss: 0.2072 - classification_loss: 0.1976 - bbox_loss: 0.0173 - classification_accuracy: 0.9148 - bbox_mse: 0.0345 - val_loss: 0.2409 - val_classification_loss: 0.2317 - val_bbox_loss: 0.0177 - val_classification_accuracy: 0.9033 - val_bbox_mse: 0.0357\n",
      "Epoch 25/60\n",
      "8400/8400 [==============================] - 1s 153us/sample - loss: 0.2038 - classification_loss: 0.1953 - bbox_loss: 0.0173 - classification_accuracy: 0.9217 - bbox_mse: 0.0344 - val_loss: 0.2366 - val_classification_loss: 0.2265 - val_bbox_loss: 0.0179 - val_classification_accuracy: 0.9025 - val_bbox_mse: 0.0363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/60\n",
      "8400/8400 [==============================] - 1s 141us/sample - loss: 0.1938 - classification_loss: 0.1855 - bbox_loss: 0.0169 - classification_accuracy: 0.9274 - bbox_mse: 0.0335 - val_loss: 0.2352 - val_classification_loss: 0.2273 - val_bbox_loss: 0.0175 - val_classification_accuracy: 0.9033 - val_bbox_mse: 0.0353\n",
      "Epoch 27/60\n",
      "8400/8400 [==============================] - 1s 149us/sample - loss: 0.1885 - classification_loss: 0.1798 - bbox_loss: 0.0164 - classification_accuracy: 0.9286 - bbox_mse: 0.0327 - val_loss: 0.2323 - val_classification_loss: 0.2240 - val_bbox_loss: 0.0177 - val_classification_accuracy: 0.9117 - val_bbox_mse: 0.0356\n",
      "Epoch 28/60\n",
      "8400/8400 [==============================] - 1s 171us/sample - loss: 0.1837 - classification_loss: 0.1751 - bbox_loss: 0.0162 - classification_accuracy: 0.9306 - bbox_mse: 0.0324 - val_loss: 0.2219 - val_classification_loss: 0.2130 - val_bbox_loss: 0.0176 - val_classification_accuracy: 0.9125 - val_bbox_mse: 0.0352\n",
      "Epoch 29/60\n",
      "8400/8400 [==============================] - 1s 142us/sample - loss: 0.1767 - classification_loss: 0.1697 - bbox_loss: 0.0160 - classification_accuracy: 0.9315 - bbox_mse: 0.0320 - val_loss: 0.2308 - val_classification_loss: 0.2262 - val_bbox_loss: 0.0170 - val_classification_accuracy: 0.9208 - val_bbox_mse: 0.0333\n",
      "Epoch 30/60\n",
      "8400/8400 [==============================] - 1s 133us/sample - loss: 0.1767 - classification_loss: 0.1679 - bbox_loss: 0.0160 - classification_accuracy: 0.9338 - bbox_mse: 0.0320 - val_loss: 0.2367 - val_classification_loss: 0.2269 - val_bbox_loss: 0.0173 - val_classification_accuracy: 0.9133 - val_bbox_mse: 0.0351\n",
      "Epoch 31/60\n",
      "8400/8400 [==============================] - 1s 135us/sample - loss: 0.1676 - classification_loss: 0.1599 - bbox_loss: 0.0157 - classification_accuracy: 0.9382 - bbox_mse: 0.0312 - val_loss: 0.2276 - val_classification_loss: 0.2179 - val_bbox_loss: 0.0176 - val_classification_accuracy: 0.9150 - val_bbox_mse: 0.0354\n",
      "Epoch 32/60\n",
      "8400/8400 [==============================] - 1s 136us/sample - loss: 0.1701 - classification_loss: 0.1613 - bbox_loss: 0.0157 - classification_accuracy: 0.9351 - bbox_mse: 0.0314 - val_loss: 0.2030 - val_classification_loss: 0.1969 - val_bbox_loss: 0.0163 - val_classification_accuracy: 0.9225 - val_bbox_mse: 0.0329\n",
      "Epoch 33/60\n",
      "8400/8400 [==============================] - 1s 165us/sample - loss: 0.1627 - classification_loss: 0.1553 - bbox_loss: 0.0153 - classification_accuracy: 0.9394 - bbox_mse: 0.0307 - val_loss: 0.2033 - val_classification_loss: 0.1944 - val_bbox_loss: 0.0160 - val_classification_accuracy: 0.9258 - val_bbox_mse: 0.0326\n",
      "Epoch 34/60\n",
      "8400/8400 [==============================] - 1s 137us/sample - loss: 0.1580 - classification_loss: 0.1509 - bbox_loss: 0.0152 - classification_accuracy: 0.9438 - bbox_mse: 0.0301 - val_loss: 0.2015 - val_classification_loss: 0.1945 - val_bbox_loss: 0.0165 - val_classification_accuracy: 0.9242 - val_bbox_mse: 0.0330\n",
      "Epoch 35/60\n",
      "8400/8400 [==============================] - 1s 146us/sample - loss: 0.1575 - classification_loss: 0.1502 - bbox_loss: 0.0151 - classification_accuracy: 0.9414 - bbox_mse: 0.0302 - val_loss: 0.2384 - val_classification_loss: 0.2314 - val_bbox_loss: 0.0178 - val_classification_accuracy: 0.9000 - val_bbox_mse: 0.0353\n",
      "Epoch 36/60\n",
      "8400/8400 [==============================] - 1s 134us/sample - loss: 0.1495 - classification_loss: 0.1414 - bbox_loss: 0.0150 - classification_accuracy: 0.9442 - bbox_mse: 0.0298 - val_loss: 0.2069 - val_classification_loss: 0.1997 - val_bbox_loss: 0.0160 - val_classification_accuracy: 0.9233 - val_bbox_mse: 0.0324\n",
      "Epoch 37/60\n",
      "8400/8400 [==============================] - 1s 149us/sample - loss: 0.1501 - classification_loss: 0.1426 - bbox_loss: 0.0150 - classification_accuracy: 0.9476 - bbox_mse: 0.0298 - val_loss: 0.1889 - val_classification_loss: 0.1819 - val_bbox_loss: 0.0160 - val_classification_accuracy: 0.9292 - val_bbox_mse: 0.0319\n",
      "Epoch 38/60\n",
      "8400/8400 [==============================] - 1s 143us/sample - loss: 0.1468 - classification_loss: 0.1390 - bbox_loss: 0.0150 - classification_accuracy: 0.9467 - bbox_mse: 0.0298 - val_loss: 0.1945 - val_classification_loss: 0.1853 - val_bbox_loss: 0.0157 - val_classification_accuracy: 0.9250 - val_bbox_mse: 0.0320\n",
      "Epoch 39/60\n",
      "8400/8400 [==============================] - 1s 143us/sample - loss: 0.1414 - classification_loss: 0.1339 - bbox_loss: 0.0146 - classification_accuracy: 0.9473 - bbox_mse: 0.0292 - val_loss: 0.1994 - val_classification_loss: 0.1914 - val_bbox_loss: 0.0154 - val_classification_accuracy: 0.9283 - val_bbox_mse: 0.0312\n",
      "Epoch 40/60\n",
      "8400/8400 [==============================] - 1s 140us/sample - loss: 0.1361 - classification_loss: 0.1291 - bbox_loss: 0.0142 - classification_accuracy: 0.9511 - bbox_mse: 0.0284 - val_loss: 0.1769 - val_classification_loss: 0.1685 - val_bbox_loss: 0.0157 - val_classification_accuracy: 0.9325 - val_bbox_mse: 0.0315\n",
      "Epoch 41/60\n",
      "8400/8400 [==============================] - 1s 169us/sample - loss: 0.1373 - classification_loss: 0.1298 - bbox_loss: 0.0144 - classification_accuracy: 0.9502 - bbox_mse: 0.0287 - val_loss: 0.1808 - val_classification_loss: 0.1768 - val_bbox_loss: 0.0152 - val_classification_accuracy: 0.9283 - val_bbox_mse: 0.0303\n",
      "Epoch 42/60\n",
      "8400/8400 [==============================] - 2s 202us/sample - loss: 0.1291 - classification_loss: 0.1221 - bbox_loss: 0.0139 - classification_accuracy: 0.9550 - bbox_mse: 0.0277 - val_loss: 0.1765 - val_classification_loss: 0.1678 - val_bbox_loss: 0.0151 - val_classification_accuracy: 0.9350 - val_bbox_mse: 0.0306\n",
      "Epoch 43/60\n",
      "8400/8400 [==============================] - 1s 150us/sample - loss: 0.1272 - classification_loss: 0.1198 - bbox_loss: 0.0139 - classification_accuracy: 0.9582 - bbox_mse: 0.0278 - val_loss: 0.1739 - val_classification_loss: 0.1664 - val_bbox_loss: 0.0150 - val_classification_accuracy: 0.9392 - val_bbox_mse: 0.0304\n",
      "Epoch 44/60\n",
      "8400/8400 [==============================] - 1s 138us/sample - loss: 0.1195 - classification_loss: 0.1123 - bbox_loss: 0.0136 - classification_accuracy: 0.9602 - bbox_mse: 0.0271 - val_loss: 0.1689 - val_classification_loss: 0.1629 - val_bbox_loss: 0.0149 - val_classification_accuracy: 0.9392 - val_bbox_mse: 0.0300\n",
      "Epoch 45/60\n",
      "8400/8400 [==============================] - 1s 159us/sample - loss: 0.1205 - classification_loss: 0.1131 - bbox_loss: 0.0137 - classification_accuracy: 0.9580 - bbox_mse: 0.0274 - val_loss: 0.1784 - val_classification_loss: 0.1701 - val_bbox_loss: 0.0151 - val_classification_accuracy: 0.9358 - val_bbox_mse: 0.0302\n",
      "Epoch 46/60\n",
      "8400/8400 [==============================] - 1s 144us/sample - loss: 0.1156 - classification_loss: 0.1086 - bbox_loss: 0.0136 - classification_accuracy: 0.9587 - bbox_mse: 0.0270 - val_loss: 0.1647 - val_classification_loss: 0.1582 - val_bbox_loss: 0.0146 - val_classification_accuracy: 0.9400 - val_bbox_mse: 0.0293\n",
      "Epoch 47/60\n",
      "8400/8400 [==============================] - 1s 148us/sample - loss: 0.1146 - classification_loss: 0.1074 - bbox_loss: 0.0136 - classification_accuracy: 0.9604 - bbox_mse: 0.0272 - val_loss: 0.1678 - val_classification_loss: 0.1597 - val_bbox_loss: 0.0145 - val_classification_accuracy: 0.9383 - val_bbox_mse: 0.0294\n",
      "Epoch 48/60\n",
      "8400/8400 [==============================] - 1s 167us/sample - loss: 0.1066 - classification_loss: 0.1000 - bbox_loss: 0.0132 - classification_accuracy: 0.9648 - bbox_mse: 0.0264 - val_loss: 0.1638 - val_classification_loss: 0.1587 - val_bbox_loss: 0.0144 - val_classification_accuracy: 0.9375 - val_bbox_mse: 0.0289\n",
      "Epoch 49/60\n",
      "8400/8400 [==============================] - 1s 162us/sample - loss: 0.1032 - classification_loss: 0.0975 - bbox_loss: 0.0131 - classification_accuracy: 0.9664 - bbox_mse: 0.0260 - val_loss: 0.1665 - val_classification_loss: 0.1583 - val_bbox_loss: 0.0143 - val_classification_accuracy: 0.9400 - val_bbox_mse: 0.0293\n",
      "Epoch 50/60\n",
      "8400/8400 [==============================] - 1s 136us/sample - loss: 0.1028 - classification_loss: 0.0959 - bbox_loss: 0.0132 - classification_accuracy: 0.9663 - bbox_mse: 0.0263 - val_loss: 0.1697 - val_classification_loss: 0.1628 - val_bbox_loss: 0.0147 - val_classification_accuracy: 0.9392 - val_bbox_mse: 0.0299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/60\n",
      "8400/8400 [==============================] - 1s 135us/sample - loss: 0.0954 - classification_loss: 0.0902 - bbox_loss: 0.0127 - classification_accuracy: 0.9685 - bbox_mse: 0.0253 - val_loss: 0.1785 - val_classification_loss: 0.1719 - val_bbox_loss: 0.0146 - val_classification_accuracy: 0.9417 - val_bbox_mse: 0.0295\n",
      "Epoch 52/60\n",
      "8400/8400 [==============================] - 1s 136us/sample - loss: 0.0946 - classification_loss: 0.0880 - bbox_loss: 0.0128 - classification_accuracy: 0.9679 - bbox_mse: 0.0255 - val_loss: 0.2209 - val_classification_loss: 0.2128 - val_bbox_loss: 0.0163 - val_classification_accuracy: 0.9250 - val_bbox_mse: 0.0329\n",
      "Epoch 53/60\n",
      "8400/8400 [==============================] - 1s 161us/sample - loss: 0.0896 - classification_loss: 0.0830 - bbox_loss: 0.0124 - classification_accuracy: 0.9713 - bbox_mse: 0.0249 - val_loss: 0.1544 - val_classification_loss: 0.1492 - val_bbox_loss: 0.0143 - val_classification_accuracy: 0.9450 - val_bbox_mse: 0.0286\n",
      "Epoch 54/60\n",
      "8400/8400 [==============================] - 1s 140us/sample - loss: 0.0902 - classification_loss: 0.0835 - bbox_loss: 0.0126 - classification_accuracy: 0.9694 - bbox_mse: 0.0252 - val_loss: 0.1818 - val_classification_loss: 0.1743 - val_bbox_loss: 0.0147 - val_classification_accuracy: 0.9350 - val_bbox_mse: 0.0295\n",
      "Epoch 55/60\n",
      "8400/8400 [==============================] - 1s 134us/sample - loss: 0.0847 - classification_loss: 0.0785 - bbox_loss: 0.0121 - classification_accuracy: 0.9710 - bbox_mse: 0.0243 - val_loss: 0.1588 - val_classification_loss: 0.1512 - val_bbox_loss: 0.0141 - val_classification_accuracy: 0.9475 - val_bbox_mse: 0.0284\n",
      "Epoch 56/60\n",
      "8400/8400 [==============================] - 1s 136us/sample - loss: 0.0819 - classification_loss: 0.0755 - bbox_loss: 0.0121 - classification_accuracy: 0.9723 - bbox_mse: 0.0242 - val_loss: 0.1570 - val_classification_loss: 0.1490 - val_bbox_loss: 0.0137 - val_classification_accuracy: 0.9450 - val_bbox_mse: 0.0277\n",
      "Epoch 57/60\n",
      "8400/8400 [==============================] - 1s 145us/sample - loss: 0.0755 - classification_loss: 0.0699 - bbox_loss: 0.0117 - classification_accuracy: 0.9773 - bbox_mse: 0.0234 - val_loss: 0.1484 - val_classification_loss: 0.1414 - val_bbox_loss: 0.0134 - val_classification_accuracy: 0.9467 - val_bbox_mse: 0.0270\n",
      "Epoch 58/60\n",
      "8400/8400 [==============================] - 1s 145us/sample - loss: 0.0774 - classification_loss: 0.0711 - bbox_loss: 0.0120 - classification_accuracy: 0.9752 - bbox_mse: 0.0240 - val_loss: 0.1500 - val_classification_loss: 0.1446 - val_bbox_loss: 0.0139 - val_classification_accuracy: 0.9442 - val_bbox_mse: 0.0280\n",
      "Epoch 59/60\n",
      "8400/8400 [==============================] - 1s 137us/sample - loss: 0.0695 - classification_loss: 0.0635 - bbox_loss: 0.0115 - classification_accuracy: 0.9794 - bbox_mse: 0.0230 - val_loss: 0.1532 - val_classification_loss: 0.1450 - val_bbox_loss: 0.0133 - val_classification_accuracy: 0.9517 - val_bbox_mse: 0.0269\n",
      "Epoch 60/60\n",
      "8400/8400 [==============================] - 1s 139us/sample - loss: 0.0706 - classification_loss: 0.0647 - bbox_loss: 0.0116 - classification_accuracy: 0.9779 - bbox_mse: 0.0232 - val_loss: 0.1516 - val_classification_loss: 0.1435 - val_bbox_loss: 0.0136 - val_classification_accuracy: 0.9475 - val_bbox_mse: 0.0275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x145b13d9fc8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TanH_model.fit(X_train, [y_train[:,:,:,:2],y_train[:,:,:,2:]], batch_size=64, epochs=60,\n",
    "            validation_data=(X_val, [y_val[:,:,:,:2],y_val[:,:,:,2:]]),\n",
    "            callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sigmoid Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_PNet():\n",
    "    \n",
    "    initializer = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "    # input layer\n",
    "    visible = Input(shape=(12,12,3))\n",
    "    \n",
    "    # CNN Stage 1\n",
    "    conv1 = Conv2D(10, kernel_size=(3,3), activation='sigmoid')(visible)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "   \n",
    "    #CNN Stage 2\n",
    "    conv2 = Conv2D(16, kernel_size=(3,3), activation='sigmoid')(pool1)\n",
    "    \n",
    "    # CNN stage 3\n",
    "    conv3 = Conv2D(32, kernel_size=(3,3), activation='sigmoid')(conv2)\n",
    "    \n",
    "    # output \n",
    "    pred_classification = Conv2D(2, kernel_size=(1,1), activation='softmax', name='classification')(conv3)\n",
    "    pred_bbox = Conv2D(4, kernel_size=(1,1), name='bbox')(conv3)\n",
    "    \n",
    "    model = Model(inputs=visible, outputs=[pred_classification, pred_bbox])\n",
    "                  \n",
    " \n",
    "    #compute the loss function over bounding box \n",
    "    bbox_loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # Define bbox loss : MSE(bounding_bbox) * y_classification[1] (...ignore if no face)\n",
    "    # Actually, \n",
    "    # we could use 'mse' but because bbox error is \"zero\" if \"no face\", we need to multiply 'mse' by \"y_classification\"  \n",
    "    def bbox_loss_fn():\n",
    "            #Create boox loss function \n",
    "        def loss(y_true,y_pred):\n",
    "            return (bbox_loss(pred_bbox, y_bbox) * y_classification[:,:,:,1])\n",
    "        # Return a function\n",
    "        return loss\n",
    "    \n",
    " \n",
    "    # create placeholder for targets\n",
    "    y_classification = tf.keras.backend.placeholder(dtype='float32', shape=pred_classification.shape) # shapes of output1 your target has\n",
    "    y_bbox = tf.keras.backend.placeholder(dtype='float32', shape=pred_bbox.shape) # shapes of output2 your target has\n",
    "    \n",
    "    # Set optimizer\n",
    "    learning_rate = 1e-3\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=adam, \n",
    "                  loss ={'classification': 'binary_crossentropy',\n",
    "                         'bbox': bbox_loss_fn()},\n",
    "                  loss_weights = {'classification': 1.0, \n",
    "                                  'bbox': 0.5},\n",
    "                  target_tensors=[y_classification,y_bbox],\n",
    "                  metrics={'classification': 'accuracy',\n",
    "                           'bbox': 'mse'})\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    # plot graph\n",
    "    plot_model(model, to_file='MTCNN P-Net sigmoid.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 12, 12, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 10, 10, 10)   280         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 10)     0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 3, 3, 16)     1456        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 1, 1, 32)     4640        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification (Conv2D)         (None, 1, 1, 2)      66          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bbox (Conv2D)                   (None, 1, 1, 4)      132         conv2d_11[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,574\n",
      "Trainable params: 6,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sigmoid_model = sigmoid_PNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=('logs\\\\pnet-benchmark\\\\Sigmoid'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8400 samples, validate on 1200 samples\n",
      "Epoch 1/60\n",
      "8400/8400 [==============================] - 3s 313us/sample - loss: 0.7398 - classification_loss: 0.7034 - bbox_loss: 0.0727 - classification_accuracy: 0.5081 - bbox_mse: 0.1451 - val_loss: 0.7168 - val_classification_loss: 0.6916 - val_bbox_loss: 0.0504 - val_classification_accuracy: 0.5733 - val_bbox_mse: 0.1015\n",
      "Epoch 2/60\n",
      "8400/8400 [==============================] - 1s 156us/sample - loss: 0.7161 - classification_loss: 0.6904 - bbox_loss: 0.0513 - classification_accuracy: 0.5240 - bbox_mse: 0.1022 - val_loss: 0.7086 - val_classification_loss: 0.6836 - val_bbox_loss: 0.0498 - val_classification_accuracy: 0.4875 - val_bbox_mse: 0.1003\n",
      "Epoch 3/60\n",
      "8400/8400 [==============================] - 1s 143us/sample - loss: 0.6887 - classification_loss: 0.6631 - bbox_loss: 0.0502 - classification_accuracy: 0.6271 - bbox_mse: 0.1000 - val_loss: 0.6471 - val_classification_loss: 0.6213 - val_bbox_loss: 0.0497 - val_classification_accuracy: 0.6892 - val_bbox_mse: 0.0997\n",
      "Epoch 4/60\n",
      "8400/8400 [==============================] - 1s 158us/sample - loss: 0.6002 - classification_loss: 0.5764 - bbox_loss: 0.0455 - classification_accuracy: 0.7358 - bbox_mse: 0.0906 - val_loss: 0.5609 - val_classification_loss: 0.5416 - val_bbox_loss: 0.0396 - val_classification_accuracy: 0.7692 - val_bbox_mse: 0.0793\n",
      "Epoch 5/60\n",
      "8400/8400 [==============================] - 2s 215us/sample - loss: 0.5479 - classification_loss: 0.5284 - bbox_loss: 0.0380 - classification_accuracy: 0.7688 - bbox_mse: 0.0757 - val_loss: 0.5428 - val_classification_loss: 0.5232 - val_bbox_loss: 0.0372 - val_classification_accuracy: 0.7725 - val_bbox_mse: 0.0748\n",
      "Epoch 6/60\n",
      "8400/8400 [==============================] - 2s 200us/sample - loss: 0.5312 - classification_loss: 0.5125 - bbox_loss: 0.0363 - classification_accuracy: 0.7779 - bbox_mse: 0.0725 - val_loss: 0.5252 - val_classification_loss: 0.5060 - val_bbox_loss: 0.0357 - val_classification_accuracy: 0.7792 - val_bbox_mse: 0.0719\n",
      "Epoch 7/60\n",
      "8400/8400 [==============================] - 2s 195us/sample - loss: 0.5169 - classification_loss: 0.5001 - bbox_loss: 0.0351 - classification_accuracy: 0.7827 - bbox_mse: 0.0701 - val_loss: 0.5124 - val_classification_loss: 0.4941 - val_bbox_loss: 0.0345 - val_classification_accuracy: 0.7900 - val_bbox_mse: 0.0701\n",
      "Epoch 8/60\n",
      "8400/8400 [==============================] - 2s 223us/sample - loss: 0.5030 - classification_loss: 0.4849 - bbox_loss: 0.0339 - classification_accuracy: 0.7912 - bbox_mse: 0.0677 - val_loss: 0.5084 - val_classification_loss: 0.4911 - val_bbox_loss: 0.0341 - val_classification_accuracy: 0.7783 - val_bbox_mse: 0.0693\n",
      "Epoch 9/60\n",
      "8400/8400 [==============================] - 2s 200us/sample - loss: 0.4928 - classification_loss: 0.4767 - bbox_loss: 0.0335 - classification_accuracy: 0.7950 - bbox_mse: 0.0664 - val_loss: 0.4966 - val_classification_loss: 0.4785 - val_bbox_loss: 0.0330 - val_classification_accuracy: 0.7942 - val_bbox_mse: 0.0667\n",
      "Epoch 10/60\n",
      "8400/8400 [==============================] - 1s 175us/sample - loss: 0.4842 - classification_loss: 0.4684 - bbox_loss: 0.0328 - classification_accuracy: 0.7979 - bbox_mse: 0.0653 - val_loss: 0.4864 - val_classification_loss: 0.4697 - val_bbox_loss: 0.0328 - val_classification_accuracy: 0.7933 - val_bbox_mse: 0.0661\n",
      "Epoch 11/60\n",
      "8400/8400 [==============================] - 2s 193us/sample - loss: 0.4759 - classification_loss: 0.4589 - bbox_loss: 0.0320 - classification_accuracy: 0.8001 - bbox_mse: 0.0641 - val_loss: 0.4821 - val_classification_loss: 0.4649 - val_bbox_loss: 0.0321 - val_classification_accuracy: 0.8008 - val_bbox_mse: 0.0652\n",
      "Epoch 12/60\n",
      "8400/8400 [==============================] - 2s 183us/sample - loss: 0.4647 - classification_loss: 0.4480 - bbox_loss: 0.0311 - classification_accuracy: 0.8050 - bbox_mse: 0.0625 - val_loss: 0.4709 - val_classification_loss: 0.4548 - val_bbox_loss: 0.0314 - val_classification_accuracy: 0.7942 - val_bbox_mse: 0.0635\n",
      "Epoch 13/60\n",
      "8400/8400 [==============================] - 2s 179us/sample - loss: 0.4553 - classification_loss: 0.4401 - bbox_loss: 0.0304 - classification_accuracy: 0.8102 - bbox_mse: 0.0607 - val_loss: 0.4577 - val_classification_loss: 0.4428 - val_bbox_loss: 0.0306 - val_classification_accuracy: 0.7958 - val_bbox_mse: 0.0617\n",
      "Epoch 14/60\n",
      "8400/8400 [==============================] - 2s 196us/sample - loss: 0.4456 - classification_loss: 0.4308 - bbox_loss: 0.0296 - classification_accuracy: 0.8108 - bbox_mse: 0.0590 - val_loss: 0.4487 - val_classification_loss: 0.4352 - val_bbox_loss: 0.0297 - val_classification_accuracy: 0.8017 - val_bbox_mse: 0.0598\n",
      "Epoch 15/60\n",
      "8400/8400 [==============================] - 2s 188us/sample - loss: 0.4318 - classification_loss: 0.4161 - bbox_loss: 0.0285 - classification_accuracy: 0.8150 - bbox_mse: 0.0568 - val_loss: 0.4531 - val_classification_loss: 0.4386 - val_bbox_loss: 0.0298 - val_classification_accuracy: 0.8008 - val_bbox_mse: 0.0606\n",
      "Epoch 16/60\n",
      "8400/8400 [==============================] - 2s 180us/sample - loss: 0.4211 - classification_loss: 0.4071 - bbox_loss: 0.0277 - classification_accuracy: 0.8195 - bbox_mse: 0.0553 - val_loss: 0.4247 - val_classification_loss: 0.4101 - val_bbox_loss: 0.0275 - val_classification_accuracy: 0.8058 - val_bbox_mse: 0.0556\n",
      "Epoch 17/60\n",
      "8400/8400 [==============================] - 2s 184us/sample - loss: 0.4100 - classification_loss: 0.3973 - bbox_loss: 0.0271 - classification_accuracy: 0.8239 - bbox_mse: 0.0536 - val_loss: 0.4151 - val_classification_loss: 0.4037 - val_bbox_loss: 0.0269 - val_classification_accuracy: 0.8083 - val_bbox_mse: 0.0544\n",
      "Epoch 18/60\n",
      "8400/8400 [==============================] - 2s 190us/sample - loss: 0.3955 - classification_loss: 0.3827 - bbox_loss: 0.0259 - classification_accuracy: 0.8331 - bbox_mse: 0.0517 - val_loss: 0.3971 - val_classification_loss: 0.3856 - val_bbox_loss: 0.0258 - val_classification_accuracy: 0.8250 - val_bbox_mse: 0.0520\n",
      "Epoch 19/60\n",
      "8400/8400 [==============================] - 2s 184us/sample - loss: 0.3846 - classification_loss: 0.3729 - bbox_loss: 0.0253 - classification_accuracy: 0.8396 - bbox_mse: 0.0502 - val_loss: 0.4063 - val_classification_loss: 0.3928 - val_bbox_loss: 0.0268 - val_classification_accuracy: 0.8292 - val_bbox_mse: 0.0536\n",
      "Epoch 20/60\n",
      "8400/8400 [==============================] - 2s 180us/sample - loss: 0.3770 - classification_loss: 0.3652 - bbox_loss: 0.0249 - classification_accuracy: 0.8457 - bbox_mse: 0.0494 - val_loss: 0.3822 - val_classification_loss: 0.3744 - val_bbox_loss: 0.0250 - val_classification_accuracy: 0.8308 - val_bbox_mse: 0.0499\n",
      "Epoch 21/60\n",
      "8400/8400 [==============================] - 2s 189us/sample - loss: 0.3725 - classification_loss: 0.3604 - bbox_loss: 0.0246 - classification_accuracy: 0.8501 - bbox_mse: 0.0490 - val_loss: 0.3849 - val_classification_loss: 0.3734 - val_bbox_loss: 0.0251 - val_classification_accuracy: 0.8400 - val_bbox_mse: 0.0509\n",
      "Epoch 22/60\n",
      "8400/8400 [==============================] - 2s 243us/sample - loss: 0.3677 - classification_loss: 0.3558 - bbox_loss: 0.0243 - classification_accuracy: 0.8531 - bbox_mse: 0.0484 - val_loss: 0.3724 - val_classification_loss: 0.3599 - val_bbox_loss: 0.0244 - val_classification_accuracy: 0.8417 - val_bbox_mse: 0.0491\n",
      "Epoch 23/60\n",
      "8400/8400 [==============================] - ETA: 0s - loss: 0.3604 - classification_loss: 0.3484 - bbox_loss: 0.0239 - classification_accuracy: 0.8536 - bbox_mse: 0.04 - 2s 208us/sample - loss: 0.3607 - classification_loss: 0.3487 - bbox_loss: 0.0239 - classification_accuracy: 0.8539 - bbox_mse: 0.0476 - val_loss: 0.3651 - val_classification_loss: 0.3530 - val_bbox_loss: 0.0240 - val_classification_accuracy: 0.8542 - val_bbox_mse: 0.0482\n",
      "Epoch 24/60\n",
      "8400/8400 [==============================] - 2s 185us/sample - loss: 0.3631 - classification_loss: 0.3505 - bbox_loss: 0.0242 - classification_accuracy: 0.8518 - bbox_mse: 0.0481 - val_loss: 0.3650 - val_classification_loss: 0.3530 - val_bbox_loss: 0.0237 - val_classification_accuracy: 0.8483 - val_bbox_mse: 0.0478\n",
      "Epoch 25/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 2s 179us/sample - loss: 0.3524 - classification_loss: 0.3415 - bbox_loss: 0.0236 - classification_accuracy: 0.8583 - bbox_mse: 0.0466 - val_loss: 0.3609 - val_classification_loss: 0.3516 - val_bbox_loss: 0.0234 - val_classification_accuracy: 0.8492 - val_bbox_mse: 0.0472\n",
      "Epoch 26/60\n",
      "8400/8400 [==============================] - 2s 182us/sample - loss: 0.3519 - classification_loss: 0.3395 - bbox_loss: 0.0233 - classification_accuracy: 0.8587 - bbox_mse: 0.0467 - val_loss: 0.3731 - val_classification_loss: 0.3603 - val_bbox_loss: 0.0240 - val_classification_accuracy: 0.8450 - val_bbox_mse: 0.0488\n",
      "Epoch 27/60\n",
      "8400/8400 [==============================] - 2s 186us/sample - loss: 0.3518 - classification_loss: 0.3401 - bbox_loss: 0.0234 - classification_accuracy: 0.8575 - bbox_mse: 0.0467 - val_loss: 0.3529 - val_classification_loss: 0.3427 - val_bbox_loss: 0.0231 - val_classification_accuracy: 0.8583 - val_bbox_mse: 0.0466\n",
      "Epoch 28/60\n",
      "8400/8400 [==============================] - 2s 179us/sample - loss: 0.3476 - classification_loss: 0.3352 - bbox_loss: 0.0232 - classification_accuracy: 0.8631 - bbox_mse: 0.0463 - val_loss: 0.3552 - val_classification_loss: 0.3440 - val_bbox_loss: 0.0233 - val_classification_accuracy: 0.8550 - val_bbox_mse: 0.0468\n",
      "Epoch 29/60\n",
      "8400/8400 [==============================] - 2s 182us/sample - loss: 0.3437 - classification_loss: 0.3321 - bbox_loss: 0.0231 - classification_accuracy: 0.8610 - bbox_mse: 0.0459 - val_loss: 0.3518 - val_classification_loss: 0.3403 - val_bbox_loss: 0.0232 - val_classification_accuracy: 0.8608 - val_bbox_mse: 0.0464\n",
      "Epoch 30/60\n",
      "8400/8400 [==============================] - 2s 189us/sample - loss: 0.3473 - classification_loss: 0.3377 - bbox_loss: 0.0233 - classification_accuracy: 0.8629 - bbox_mse: 0.0461 - val_loss: 0.3510 - val_classification_loss: 0.3401 - val_bbox_loss: 0.0230 - val_classification_accuracy: 0.8583 - val_bbox_mse: 0.0463\n",
      "Epoch 31/60\n",
      "8400/8400 [==============================] - 2s 183us/sample - loss: 0.3398 - classification_loss: 0.3283 - bbox_loss: 0.0227 - classification_accuracy: 0.8680 - bbox_mse: 0.0452 - val_loss: 0.3437 - val_classification_loss: 0.3317 - val_bbox_loss: 0.0225 - val_classification_accuracy: 0.8658 - val_bbox_mse: 0.0455\n",
      "Epoch 32/60\n",
      "8400/8400 [==============================] - 2s 181us/sample - loss: 0.3389 - classification_loss: 0.3268 - bbox_loss: 0.0227 - classification_accuracy: 0.8700 - bbox_mse: 0.0453 - val_loss: 0.3418 - val_classification_loss: 0.3310 - val_bbox_loss: 0.0226 - val_classification_accuracy: 0.8650 - val_bbox_mse: 0.0452\n",
      "Epoch 33/60\n",
      "8400/8400 [==============================] - 2s 189us/sample - loss: 0.3348 - classification_loss: 0.3243 - bbox_loss: 0.0224 - classification_accuracy: 0.8670 - bbox_mse: 0.0447 - val_loss: 0.3422 - val_classification_loss: 0.3305 - val_bbox_loss: 0.0225 - val_classification_accuracy: 0.8708 - val_bbox_mse: 0.0453\n",
      "Epoch 34/60\n",
      "8400/8400 [==============================] - 2s 181us/sample - loss: 0.3335 - classification_loss: 0.3218 - bbox_loss: 0.0223 - classification_accuracy: 0.8688 - bbox_mse: 0.0446 - val_loss: 0.3385 - val_classification_loss: 0.3259 - val_bbox_loss: 0.0222 - val_classification_accuracy: 0.8683 - val_bbox_mse: 0.0449\n",
      "Epoch 35/60\n",
      "8400/8400 [==============================] - 2s 182us/sample - loss: 0.3352 - classification_loss: 0.3243 - bbox_loss: 0.0225 - classification_accuracy: 0.8680 - bbox_mse: 0.0449 - val_loss: 0.3595 - val_classification_loss: 0.3489 - val_bbox_loss: 0.0240 - val_classification_accuracy: 0.8533 - val_bbox_mse: 0.0480\n",
      "Epoch 36/60\n",
      "8400/8400 [==============================] - 2s 186us/sample - loss: 0.3321 - classification_loss: 0.3200 - bbox_loss: 0.0222 - classification_accuracy: 0.8683 - bbox_mse: 0.0444 - val_loss: 0.3367 - val_classification_loss: 0.3242 - val_bbox_loss: 0.0222 - val_classification_accuracy: 0.8675 - val_bbox_mse: 0.0446\n",
      "Epoch 37/60\n",
      "8400/8400 [==============================] - 2s 190us/sample - loss: 0.3283 - classification_loss: 0.3172 - bbox_loss: 0.0222 - classification_accuracy: 0.8718 - bbox_mse: 0.0440 - val_loss: 0.3370 - val_classification_loss: 0.3253 - val_bbox_loss: 0.0221 - val_classification_accuracy: 0.8650 - val_bbox_mse: 0.0448\n",
      "Epoch 38/60\n",
      "8400/8400 [==============================] - 2s 194us/sample - loss: 0.3294 - classification_loss: 0.3173 - bbox_loss: 0.0221 - classification_accuracy: 0.8702 - bbox_mse: 0.0441 - val_loss: 0.3465 - val_classification_loss: 0.3354 - val_bbox_loss: 0.0225 - val_classification_accuracy: 0.8625 - val_bbox_mse: 0.0453\n",
      "Epoch 39/60\n",
      "8400/8400 [==============================] - 2s 207us/sample - loss: 0.3256 - classification_loss: 0.3146 - bbox_loss: 0.0218 - classification_accuracy: 0.8733 - bbox_mse: 0.0436 - val_loss: 0.3511 - val_classification_loss: 0.3395 - val_bbox_loss: 0.0230 - val_classification_accuracy: 0.8542 - val_bbox_mse: 0.0460\n",
      "Epoch 40/60\n",
      "8400/8400 [==============================] - 2s 202us/sample - loss: 0.3263 - classification_loss: 0.3149 - bbox_loss: 0.0218 - classification_accuracy: 0.8723 - bbox_mse: 0.0437 - val_loss: 0.3282 - val_classification_loss: 0.3176 - val_bbox_loss: 0.0218 - val_classification_accuracy: 0.8733 - val_bbox_mse: 0.0435\n",
      "Epoch 41/60\n",
      "8400/8400 [==============================] - 2s 236us/sample - loss: 0.3232 - classification_loss: 0.3119 - bbox_loss: 0.0218 - classification_accuracy: 0.8727 - bbox_mse: 0.0435 - val_loss: 0.3284 - val_classification_loss: 0.3184 - val_bbox_loss: 0.0213 - val_classification_accuracy: 0.8717 - val_bbox_mse: 0.0433\n",
      "Epoch 42/60\n",
      "8400/8400 [==============================] - 2s 202us/sample - loss: 0.3246 - classification_loss: 0.3122 - bbox_loss: 0.0218 - classification_accuracy: 0.8723 - bbox_mse: 0.0436 - val_loss: 0.3316 - val_classification_loss: 0.3214 - val_bbox_loss: 0.0217 - val_classification_accuracy: 0.8667 - val_bbox_mse: 0.0438\n",
      "Epoch 43/60\n",
      "8400/8400 [==============================] - 1s 178us/sample - loss: 0.3208 - classification_loss: 0.3116 - bbox_loss: 0.0216 - classification_accuracy: 0.8751 - bbox_mse: 0.0431 - val_loss: 0.3385 - val_classification_loss: 0.3261 - val_bbox_loss: 0.0230 - val_classification_accuracy: 0.8558 - val_bbox_mse: 0.0457\n",
      "Epoch 44/60\n",
      "8400/8400 [==============================] - 2s 188us/sample - loss: 0.3257 - classification_loss: 0.3142 - bbox_loss: 0.0220 - classification_accuracy: 0.8720 - bbox_mse: 0.0438 - val_loss: 0.3293 - val_classification_loss: 0.3173 - val_bbox_loss: 0.0216 - val_classification_accuracy: 0.8650 - val_bbox_mse: 0.0435\n",
      "Epoch 45/60\n",
      "8400/8400 [==============================] - 2s 189us/sample - loss: 0.3165 - classification_loss: 0.3057 - bbox_loss: 0.0213 - classification_accuracy: 0.8762 - bbox_mse: 0.0426 - val_loss: 0.3222 - val_classification_loss: 0.3114 - val_bbox_loss: 0.0210 - val_classification_accuracy: 0.8758 - val_bbox_mse: 0.0427\n",
      "Epoch 46/60\n",
      "8400/8400 [==============================] - 2s 183us/sample - loss: 0.3182 - classification_loss: 0.3078 - bbox_loss: 0.0215 - classification_accuracy: 0.8754 - bbox_mse: 0.0428 - val_loss: 0.3391 - val_classification_loss: 0.3288 - val_bbox_loss: 0.0224 - val_classification_accuracy: 0.8650 - val_bbox_mse: 0.0449\n",
      "Epoch 47/60\n",
      "8400/8400 [==============================] - 2s 179us/sample - loss: 0.3132 - classification_loss: 0.3033 - bbox_loss: 0.0214 - classification_accuracy: 0.8756 - bbox_mse: 0.0423 - val_loss: 0.3210 - val_classification_loss: 0.3109 - val_bbox_loss: 0.0212 - val_classification_accuracy: 0.8750 - val_bbox_mse: 0.0427\n",
      "Epoch 48/60\n",
      "8400/8400 [==============================] - 2s 182us/sample - loss: 0.3147 - classification_loss: 0.3070 - bbox_loss: 0.0216 - classification_accuracy: 0.8761 - bbox_mse: 0.0426 - val_loss: 0.3182 - val_classification_loss: 0.3085 - val_bbox_loss: 0.0209 - val_classification_accuracy: 0.8767 - val_bbox_mse: 0.0423\n",
      "Epoch 49/60\n",
      "8400/8400 [==============================] - 2s 190us/sample - loss: 0.3115 - classification_loss: 0.3017 - bbox_loss: 0.0212 - classification_accuracy: 0.8775 - bbox_mse: 0.0422 - val_loss: 0.3264 - val_classification_loss: 0.3144 - val_bbox_loss: 0.0217 - val_classification_accuracy: 0.8700 - val_bbox_mse: 0.0434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/60\n",
      "8400/8400 [==============================] - 2s 179us/sample - loss: 0.3132 - classification_loss: 0.3026 - bbox_loss: 0.0214 - classification_accuracy: 0.8764 - bbox_mse: 0.0424 - val_loss: 0.3207 - val_classification_loss: 0.3109 - val_bbox_loss: 0.0211 - val_classification_accuracy: 0.8692 - val_bbox_mse: 0.0424\n",
      "Epoch 51/60\n",
      "8400/8400 [==============================] - 2s 181us/sample - loss: 0.3069 - classification_loss: 0.2963 - bbox_loss: 0.0210 - classification_accuracy: 0.8810 - bbox_mse: 0.0417 - val_loss: 0.3150 - val_classification_loss: 0.3057 - val_bbox_loss: 0.0210 - val_classification_accuracy: 0.8742 - val_bbox_mse: 0.0422\n",
      "Epoch 52/60\n",
      "8400/8400 [==============================] - 2s 189us/sample - loss: 0.3112 - classification_loss: 0.3000 - bbox_loss: 0.0213 - classification_accuracy: 0.8754 - bbox_mse: 0.0424 - val_loss: 0.3158 - val_classification_loss: 0.3050 - val_bbox_loss: 0.0209 - val_classification_accuracy: 0.8717 - val_bbox_mse: 0.0422\n",
      "Epoch 53/60\n",
      "8400/8400 [==============================] - 1s 175us/sample - loss: 0.3052 - classification_loss: 0.2942 - bbox_loss: 0.0208 - classification_accuracy: 0.8786 - bbox_mse: 0.0416 - val_loss: 0.3155 - val_classification_loss: 0.3062 - val_bbox_loss: 0.0210 - val_classification_accuracy: 0.8717 - val_bbox_mse: 0.0422\n",
      "Epoch 54/60\n",
      "8400/8400 [==============================] - 1s 175us/sample - loss: 0.3041 - classification_loss: 0.2927 - bbox_loss: 0.0208 - classification_accuracy: 0.8798 - bbox_mse: 0.0414 - val_loss: 0.3187 - val_classification_loss: 0.3072 - val_bbox_loss: 0.0214 - val_classification_accuracy: 0.8700 - val_bbox_mse: 0.0434\n",
      "Epoch 55/60\n",
      "8400/8400 [==============================] - 2s 195us/sample - loss: 0.3031 - classification_loss: 0.2937 - bbox_loss: 0.0208 - classification_accuracy: 0.8788 - bbox_mse: 0.0414 - val_loss: 0.3095 - val_classification_loss: 0.2980 - val_bbox_loss: 0.0207 - val_classification_accuracy: 0.8758 - val_bbox_mse: 0.0417\n",
      "Epoch 56/60\n",
      "8400/8400 [==============================] - 1s 178us/sample - loss: 0.3056 - classification_loss: 0.2955 - bbox_loss: 0.0210 - classification_accuracy: 0.8813 - bbox_mse: 0.0419 - val_loss: 0.3111 - val_classification_loss: 0.3010 - val_bbox_loss: 0.0208 - val_classification_accuracy: 0.8683 - val_bbox_mse: 0.0417\n",
      "Epoch 57/60\n",
      "8400/8400 [==============================] - 1s 175us/sample - loss: 0.2973 - classification_loss: 0.2875 - bbox_loss: 0.0205 - classification_accuracy: 0.8806 - bbox_mse: 0.0408 - val_loss: 0.3101 - val_classification_loss: 0.2995 - val_bbox_loss: 0.0208 - val_classification_accuracy: 0.8750 - val_bbox_mse: 0.0419\n",
      "Epoch 58/60\n",
      "8400/8400 [==============================] - 2s 181us/sample - loss: 0.2962 - classification_loss: 0.2859 - bbox_loss: 0.0204 - classification_accuracy: 0.8837 - bbox_mse: 0.0407 - val_loss: 0.3187 - val_classification_loss: 0.3082 - val_bbox_loss: 0.0210 - val_classification_accuracy: 0.8692 - val_bbox_mse: 0.0424\n",
      "Epoch 59/60\n",
      "8400/8400 [==============================] - 2s 188us/sample - loss: 0.3012 - classification_loss: 0.2909 - bbox_loss: 0.0209 - classification_accuracy: 0.8769 - bbox_mse: 0.0414 - val_loss: 0.3035 - val_classification_loss: 0.2927 - val_bbox_loss: 0.0204 - val_classification_accuracy: 0.8733 - val_bbox_mse: 0.0412\n",
      "Epoch 60/60\n",
      "8400/8400 [==============================] - 1s 178us/sample - loss: 0.2945 - classification_loss: 0.2845 - bbox_loss: 0.0205 - classification_accuracy: 0.8835 - bbox_mse: 0.0406 - val_loss: 0.3087 - val_classification_loss: 0.2967 - val_bbox_loss: 0.0206 - val_classification_accuracy: 0.8775 - val_bbox_mse: 0.0422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x145be74b348>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_model.fit(X_train, [y_train[:,:,:,:2],y_train[:,:,:,2:]], batch_size=64, epochs=60,\n",
    "            validation_data=(X_val, [y_val[:,:,:,:2],y_val[:,:,:,2:]]),\n",
    "            callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the PNet  to ensure that the implementation does not crash and produces outputs of the expected shape.\n",
    "Pnet will output are:\n",
    "1. Face classification,  size (batch,1,1,2) for 2 calss classification, \"Face\", and \"Not face\"\n",
    "2. Bounding box  (batch,1,1,4) for 4 boundind box corrdinates (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_model.save('P-Net-Sig.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(sigmoid_model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[['loss', 'val_loss']].plot(figsize=(8,5))\n",
    "plt.title('P-Net Sigmoid model loss vs. epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[['classification_accuracy', 'val_classification_accuracy']].plot(figsize=(8,5))\n",
    "plt.title('P-Net Sigmoid model accuracy vs. epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sigmoid_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = predictions[0]\n",
    "bbox = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.squeeze(score)\n",
    "bbox = np.squeeze(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_score = np.squeeze(y_test[:,:,:,:2])\n",
    "y_test_bbox = np.squeeze(y_test[:,:,:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_score, np.round(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test_score[:,1:2], np.round(score[:,1:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score[0:10,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_testset(index):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(2, 2))\n",
    "    ax.imshow(X_test[index])\n",
    "    plt.title(score[index,1:])\n",
    "    # Create a Rectangle patch\n",
    "    x = round(12*bbox[index,0])\n",
    "    y = round(12*bbox[index,1])\n",
    "    w = round(12*bbox[index,2]) - x\n",
    "    h = round(12*bbox[index,3]) - y\n",
    "    rect = patches.Rectangle((x,y),w,h,linewidth=1,edgecolor='r',facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_testset(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('20520-P-Net-Relu-test_data_input.npy', 'wb') as f:\n",
    "    np.save(f, np.transpose(X_test, (0,3,1,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction for future use (NN lite)\n",
    "with open('20520-P-Net-Relu-test-data_predictions-classifications.npy', 'wb') as f:\n",
    "    np.save(f, score)\n",
    "\n",
    "with open('20520-P-Net-Relu-test-data_predictions-bbox.npy', 'wb') as f:\n",
    "    np.save(f, bbox)\n",
    "\n",
    "    \n",
    "# Save labels for future use (NN lite)\n",
    "with open('20520-P-Net-Relu-test-data_y_Labels_classifications.npy', 'wb') as f:\n",
    "    np.save(f, y_test_score)\n",
    "\n",
    "    \n",
    "    # Save labels for future use (NN lite)\n",
    "with open('20520-P-Net-Relu-test-data_y_Labels_bbox.npy', 'wb') as f:\n",
    "    np.save(f, y_test_bbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = np.load('20520-P-Net-Relu-test-data_predictions-classifications.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bbox[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
