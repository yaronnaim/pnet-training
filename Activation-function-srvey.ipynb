{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Outputs\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Input, Layer\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "#from keras.layers.wrappers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACES_PATH = '../data/face_detection/faces/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/face_detection/faces/\n"
     ]
    }
   ],
   "source": [
    "print(FACES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 6000\n",
    "\n",
    "def read_pos_images():\n",
    "    #Read positive images:\n",
    "    path, __, filenames = next(os.walk(FACES_PATH+'pos_train/'))\n",
    "    file_count = training_size #len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[0.0,1.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    file = open(FACES_PATH+'coordinates.txt','r')\n",
    "    lines = file.readlines()\n",
    "    lines = [line[:-1] for line in lines]\n",
    "    #idx=[1,0,3,2]\n",
    "    idx=[0,1,2,3]\n",
    "    f_count = 0\n",
    "    for line in lines:\n",
    "        line = line.split(\" \")\n",
    "        line = line[1]\n",
    "        line=line[1:-1]\n",
    "        line = line.split(\",\")\n",
    "        #Transpose coordinates\n",
    "        x=0\n",
    "        nline=[]\n",
    "        for i in idx:\n",
    "            nline.append(line[i])\n",
    "            x=x+1\n",
    "        line=[[[float(c) for c in nline]]]\n",
    "        coordinates.append(line)\n",
    "        f_count = f_count+1\n",
    "        if f_count == file_count:\n",
    "            break\n",
    "    #Return images, probs, and coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "def read_neg_images():\n",
    "    #Read negative images:\n",
    "    path, __, filenames = next(os.walk(FACES_PATH+'neg_train/'))\n",
    "    file_count = training_size #len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[1.0,0.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    for i in range(file_count):\n",
    "        coordinates.append([[[0.0,0.0,0.0,0.0]]])\n",
    "    #Return images, prob, coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "#Read in all images, probabilities, and coordinates\n",
    "pimages, pprob, pcoordinates = read_pos_images()\n",
    "nimages, nprob, ncoordinates = read_neg_images()\n",
    "o_images=np.append(pimages,nimages,axis=0)\n",
    "o_images=np.reshape(o_images,(-1,12,12,3))\n",
    "o_prob=pprob+nprob\n",
    "o_coordinates=pcoordinates+ncoordinates\n",
    "\n",
    "#Shuffle them up using an index\n",
    "idx=np.arange(len(o_prob))\n",
    "np.random.shuffle(idx)\n",
    "images=np.empty_like(o_images)\n",
    "c=0\n",
    "for i in idx:\n",
    "    images[c]=o_images[i]\n",
    "    c=c+1\n",
    "#images=(np.float32)(images-127.5)/128.0\n",
    "images=(np.float32)(images)/255\n",
    "\n",
    "#images = np.transpose(images, (0, 2, 1, 3)) #Transpose images\n",
    "prob=[]\n",
    "for i in idx:\n",
    "    prob.append(o_prob[i])\n",
    "coordinates=[]\n",
    "for i in idx:\n",
    "    coordinates.append(o_coordinates[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train , Image batch shape  (12000, 12, 12, 3)\n",
      "y_train , Classification ground true batch shape  (12000, 1, 1, 2)\n",
      "y_train , Coordinates ground true batch shape  (12000, 1, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('X_train , Image batch shape ', images.shape)\n",
    "print('y_train , Classification ground true batch shape ' ,np.array(prob).shape)\n",
    "print('y_train , Coordinates ground true batch shape ', np.array(coordinates).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X_data for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape (12000, 12, 12, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X_data shape',X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create \"y_data\" for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.concatenate((np.array(prob), np.array(coordinates)), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data shape (12000, 1, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "print('y_data shape',y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data Classification shape (12000, 1, 1, 2)\n",
      "y_data Coordinate shape (12000, 1, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('y_data Classification shape', y_data[:,:,:,:2].shape)\n",
    "print('y_data Coordinate shape',y_data[:,:,:,2:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide dataset to \"train', \"val\" and \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X, y, training_prec = 0.7, val_prec = 0.1, test_prec = 0.2):\n",
    "        data_length = len(X)\n",
    "        num_training = np.int(data_length * training_prec)\n",
    "        num_validation = np.int(data_length * val_prec)\n",
    "        \n",
    "        mask = range(num_training)\n",
    "        X_train = X[mask]\n",
    "        y_train = y[mask]\n",
    "        mask = range(num_training, num_training + num_validation)\n",
    "        X_val = X[mask]\n",
    "        y_val = y[mask]\n",
    "        mask = range(num_training + num_validation, data_length)\n",
    "        X_test = X[mask]\n",
    "        y_test = y[mask]\n",
    "        \n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (8400, 12, 12, 3)\n",
      "Train labels shape:  (8400, 1, 1, 6) float64\n",
      "Validation data shape:  (1200, 12, 12, 3)\n",
      "Validation labels shape:  (1200, 1, 1, 6)\n",
      "Test data shape:  (2400, 12, 12, 3)\n",
      "Test labels shape:  (2400, 1, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data(X_data, y_data)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_base_dir = \"./logs/p-net-benchmark\"\n",
    "os.makedirs(log_base_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./logs/p-net-benchmark\n"
     ]
    }
   ],
   "source": [
    "print(log_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8008 (pid 21680), started 0:14:21 ago. (Use '!kill 21680' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3954383268204e1b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3954383268204e1b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 8008;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_base_dir} --port=8008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build P-Net Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ReLU Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu_PNet():\n",
    "    \n",
    "    initializer = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "    # input layer\n",
    "    visible = Input(shape=(12,12,3))\n",
    "    \n",
    "    # CNN Stage 1\n",
    "    conv1 = Conv2D(10, kernel_size=(3,3), activation='relu')(visible)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "   \n",
    "    #CNN Stage 2\n",
    "    conv2 = Conv2D(16, kernel_size=(3,3), activation='relu')(pool1)\n",
    "    \n",
    "    # CNN stage 3\n",
    "    conv3 = Conv2D(32, kernel_size=(3,3), activation='relu')(conv2)\n",
    "    \n",
    "    # output \n",
    "    pred_classification = Conv2D(2, kernel_size=(1,1), activation='softmax', name='classification')(conv3)\n",
    "    pred_bbox = Conv2D(4, kernel_size=(1,1), name='bbox')(conv3)\n",
    "    \n",
    "    model = Model(inputs=visible, outputs=[pred_classification, pred_bbox])\n",
    "                  \n",
    " \n",
    "    #compute the loss function over bounding box \n",
    "    bbox_loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # Define bbox loss : MSE(bounding_bbox) * y_classification[1] (...ignore if no face)\n",
    "    # Actually, \n",
    "    # we could use 'mse' but because bbox error is \"zero\" if \"no face\", we need to multiply 'mse' by \"y_classification\"  \n",
    "    def bbox_loss_fn():\n",
    "            #Create boox loss function \n",
    "        def loss(y_true,y_pred):\n",
    "            return (bbox_loss(pred_bbox, y_bbox) * y_classification[:,:,:,1])\n",
    "        # Return a function\n",
    "        return loss\n",
    "    \n",
    " \n",
    "    # create placeholder for targets\n",
    "    y_classification = tf.keras.backend.placeholder(dtype='float32', shape=pred_classification.shape) # shapes of output1 your target has\n",
    "    y_bbox = tf.keras.backend.placeholder(dtype='float32', shape=pred_bbox.shape) # shapes of output2 your target has\n",
    "    \n",
    "    # Set optimizer\n",
    "    learning_rate = 1e-3\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=adam, \n",
    "                  loss ={'classification': 'binary_crossentropy',\n",
    "                         'bbox': bbox_loss_fn()},\n",
    "                  loss_weights = {'classification': 1.0, \n",
    "                                  'bbox': 0.5},\n",
    "                  target_tensors=[y_classification,y_bbox],\n",
    "                  metrics={'classification': 'accuracy',\n",
    "                           'bbox': 'mse'})\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    # plot graph\n",
    "    plot_model(model, to_file='MTCNN P-Net relu.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 12, 12, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 10, 10, 10)   280         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 5, 5, 10)     0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 3, 3, 16)     1456        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1, 1, 32)     4640        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classification (Conv2D)         (None, 1, 1, 2)      66          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bbox (Conv2D)                   (None, 1, 1, 4)      132         conv2d_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,574\n",
      "Trainable params: 6,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ReLU_model = Relu_PNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=('logs\\\\p-net-benchmark\\\\ReLU'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8400 samples, validate on 1200 samples\n",
      "Epoch 1/60\n",
      "8400/8400 [==============================] - 4s 468us/sample - loss: 0.5725 - classification_loss: 0.5496 - bbox_loss: 0.0462 - classification_accuracy: 0.7368 - bbox_mse: 0.0921 - val_loss: 0.5165 - val_classification_loss: 0.4976 - val_bbox_loss: 0.0411 - val_classification_accuracy: 0.7450 - val_bbox_mse: 0.0809\n",
      "Epoch 2/60\n",
      "8400/8400 [==============================] - 1s 173us/sample - loss: 0.3882 - classification_loss: 0.3735 - bbox_loss: 0.0292 - classification_accuracy: 0.8443 - bbox_mse: 0.0583 - val_loss: 0.3461 - val_classification_loss: 0.3328 - val_bbox_loss: 0.0272 - val_classification_accuracy: 0.8633 - val_bbox_mse: 0.0541\n",
      "Epoch 3/60\n",
      "8400/8400 [==============================] - 2s 192us/sample - loss: 0.3345 - classification_loss: 0.3218 - bbox_loss: 0.0258 - classification_accuracy: 0.8694 - bbox_mse: 0.0515 - val_loss: 0.3191 - val_classification_loss: 0.3072 - val_bbox_loss: 0.0259 - val_classification_accuracy: 0.8700 - val_bbox_mse: 0.0516\n",
      "Epoch 4/60\n",
      "8400/8400 [==============================] - 2s 215us/sample - loss: 0.3084 - classification_loss: 0.2955 - bbox_loss: 0.0240 - classification_accuracy: 0.8805 - bbox_mse: 0.0477 - val_loss: 0.3038 - val_classification_loss: 0.2912 - val_bbox_loss: 0.0237 - val_classification_accuracy: 0.8700 - val_bbox_mse: 0.0468\n",
      "Epoch 5/60\n",
      "8400/8400 [==============================] - 2s 230us/sample - loss: 0.2809 - classification_loss: 0.2704 - bbox_loss: 0.0223 - classification_accuracy: 0.8896 - bbox_mse: 0.0444 - val_loss: 0.2762 - val_classification_loss: 0.2650 - val_bbox_loss: 0.0214 - val_classification_accuracy: 0.8858 - val_bbox_mse: 0.0427\n",
      "Epoch 6/60\n",
      "8400/8400 [==============================] - 2s 276us/sample - loss: 0.2632 - classification_loss: 0.2525 - bbox_loss: 0.0208 - classification_accuracy: 0.8975 - bbox_mse: 0.0416 - val_loss: 0.2586 - val_classification_loss: 0.2487 - val_bbox_loss: 0.0205 - val_classification_accuracy: 0.9017 - val_bbox_mse: 0.04118 - classification_loss: 0.2602 - bbox_loss: 0.0213 - \n",
      "Epoch 7/60\n",
      "8400/8400 [==============================] - 2s 212us/sample - loss: 0.2527 - classification_loss: 0.2419 - bbox_loss: 0.0204 - classification_accuracy: 0.8995 - bbox_mse: 0.0407 - val_loss: 0.2545 - val_classification_loss: 0.2446 - val_bbox_loss: 0.0203 - val_classification_accuracy: 0.9008 - val_bbox_mse: 0.0403\n",
      "Epoch 8/60\n",
      "8400/8400 [==============================] - 2s 229us/sample - loss: 0.2384 - classification_loss: 0.2286 - bbox_loss: 0.0193 - classification_accuracy: 0.9089 - bbox_mse: 0.0385 - val_loss: 0.2379 - val_classification_loss: 0.2276 - val_bbox_loss: 0.0193 - val_classification_accuracy: 0.9117 - val_bbox_mse: 0.0384\n",
      "Epoch 9/60\n",
      "8400/8400 [==============================] - 1s 156us/sample - loss: 0.2221 - classification_loss: 0.2122 - bbox_loss: 0.0182 - classification_accuracy: 0.9142 - bbox_mse: 0.0366 - val_loss: 0.2344 - val_classification_loss: 0.2244 - val_bbox_loss: 0.0188 - val_classification_accuracy: 0.9067 - val_bbox_mse: 0.0379\n",
      "Epoch 10/60\n",
      "8400/8400 [==============================] - 1s 142us/sample - loss: 0.2105 - classification_loss: 0.2021 - bbox_loss: 0.0173 - classification_accuracy: 0.9192 - bbox_mse: 0.0346 - val_loss: 0.2431 - val_classification_loss: 0.2341 - val_bbox_loss: 0.0187 - val_classification_accuracy: 0.8983 - val_bbox_mse: 0.0374\n",
      "Epoch 11/60\n",
      "8400/8400 [==============================] - 1s 150us/sample - loss: 0.1995 - classification_loss: 0.1909 - bbox_loss: 0.0168 - classification_accuracy: 0.9220 - bbox_mse: 0.0334 - val_loss: 0.2262 - val_classification_loss: 0.2169 - val_bbox_loss: 0.0174 - val_classification_accuracy: 0.9100 - val_bbox_mse: 0.0349\n",
      "Epoch 12/60\n",
      "8400/8400 [==============================] - 1s 165us/sample - loss: 0.1982 - classification_loss: 0.1897 - bbox_loss: 0.0167 - classification_accuracy: 0.9226 - bbox_mse: 0.0333 - val_loss: 0.2196 - val_classification_loss: 0.2112 - val_bbox_loss: 0.0177 - val_classification_accuracy: 0.9117 - val_bbox_mse: 0.0349\n",
      "Epoch 13/60\n",
      "8400/8400 [==============================] - 1s 166us/sample - loss: 0.1934 - classification_loss: 0.1844 - bbox_loss: 0.0164 - classification_accuracy: 0.9252 - bbox_mse: 0.0327 - val_loss: 0.2462 - val_classification_loss: 0.2358 - val_bbox_loss: 0.0180 - val_classification_accuracy: 0.9033 - val_bbox_mse: 0.0365\n",
      "Epoch 14/60\n",
      "8400/8400 [==============================] - 2s 190us/sample - loss: 0.1734 - classification_loss: 0.1653 - bbox_loss: 0.0151 - classification_accuracy: 0.9348 - bbox_mse: 0.0300 - val_loss: 0.2173 - val_classification_loss: 0.2098 - val_bbox_loss: 0.0168 - val_classification_accuracy: 0.9175 - val_bbox_mse: 0.0336\n",
      "Epoch 15/60\n",
      "8400/8400 [==============================] - 2s 208us/sample - loss: 0.1664 - classification_loss: 0.1591 - bbox_loss: 0.0148 - classification_accuracy: 0.9374 - bbox_mse: 0.0295 - val_loss: 0.2100 - val_classification_loss: 0.2007 - val_bbox_loss: 0.0162 - val_classification_accuracy: 0.9175 - val_bbox_mse: 0.0323\n",
      "Epoch 16/60\n",
      "8400/8400 [==============================] - 2s 179us/sample - loss: 0.1590 - classification_loss: 0.1515 - bbox_loss: 0.0142 - classification_accuracy: 0.9405 - bbox_mse: 0.0284 - val_loss: 0.2086 - val_classification_loss: 0.1989 - val_bbox_loss: 0.0163 - val_classification_accuracy: 0.9242 - val_bbox_mse: 0.0326\n",
      "Epoch 17/60\n",
      "8400/8400 [==============================] - 1s 176us/sample - loss: 0.1531 - classification_loss: 0.1456 - bbox_loss: 0.0140 - classification_accuracy: 0.9437 - bbox_mse: 0.0277 - val_loss: 0.1897 - val_classification_loss: 0.1834 - val_bbox_loss: 0.0151 - val_classification_accuracy: 0.9283 - val_bbox_mse: 0.0302\n",
      "Epoch 18/60\n",
      "8400/8400 [==============================] - 1s 161us/sample - loss: 0.1483 - classification_loss: 0.1447 - bbox_loss: 0.0138 - classification_accuracy: 0.9444 - bbox_mse: 0.0273 - val_loss: 0.2045 - val_classification_loss: 0.1964 - val_bbox_loss: 0.0161 - val_classification_accuracy: 0.9250 - val_bbox_mse: 0.0325\n",
      "Epoch 19/60\n",
      "8400/8400 [==============================] - 1s 162us/sample - loss: 0.1471 - classification_loss: 0.1405 - bbox_loss: 0.0138 - classification_accuracy: 0.9452 - bbox_mse: 0.0275 - val_loss: 0.1873 - val_classification_loss: 0.1813 - val_bbox_loss: 0.0152 - val_classification_accuracy: 0.9292 - val_bbox_mse: 0.0302\n",
      "Epoch 20/60\n",
      "8400/8400 [==============================] - 1s 157us/sample - loss: 0.1360 - classification_loss: 0.1296 - bbox_loss: 0.0132 - classification_accuracy: 0.9496 - bbox_mse: 0.0263 - val_loss: 0.1886 - val_classification_loss: 0.1809 - val_bbox_loss: 0.0149 - val_classification_accuracy: 0.9350 - val_bbox_mse: 0.0296\n",
      "Epoch 21/60\n",
      "8400/8400 [==============================] - 2s 191us/sample - loss: 0.1302 - classification_loss: 0.1235 - bbox_loss: 0.0126 - classification_accuracy: 0.9535 - bbox_mse: 0.0254 - val_loss: 0.1865 - val_classification_loss: 0.1784 - val_bbox_loss: 0.0149 - val_classification_accuracy: 0.9342 - val_bbox_mse: 0.0296\n",
      "Epoch 22/60\n",
      "8400/8400 [==============================] - 2s 200us/sample - loss: 0.1239 - classification_loss: 0.1173 - bbox_loss: 0.0124 - classification_accuracy: 0.9529 - bbox_mse: 0.0249 - val_loss: 0.1920 - val_classification_loss: 0.1852 - val_bbox_loss: 0.0145 - val_classification_accuracy: 0.9308 - val_bbox_mse: 0.0290\n",
      "Epoch 23/60\n",
      "8400/8400 [==============================] - 2s 207us/sample - loss: 0.1203 - classification_loss: 0.1139 - bbox_loss: 0.0121 - classification_accuracy: 0.9580 - bbox_mse: 0.0242 - val_loss: 0.1749 - val_classification_loss: 0.1692 - val_bbox_loss: 0.0139 - val_classification_accuracy: 0.9358 - val_bbox_mse: 0.0277\n",
      "Epoch 24/60\n",
      "8400/8400 [==============================] - 2s 229us/sample - loss: 0.1137 - classification_loss: 0.1074 - bbox_loss: 0.0119 - classification_accuracy: 0.9602 - bbox_mse: 0.0239 - val_loss: 0.1784 - val_classification_loss: 0.1709 - val_bbox_loss: 0.0138 - val_classification_accuracy: 0.9417 - val_bbox_mse: 0.0278\n",
      "Epoch 25/60\n",
      "8400/8400 [==============================] - 2s 233us/sample - loss: 0.1090 - classification_loss: 0.1027 - bbox_loss: 0.0117 - classification_accuracy: 0.9615 - bbox_mse: 0.0235 - val_loss: 0.1665 - val_classification_loss: 0.1600 - val_bbox_loss: 0.0134 - val_classification_accuracy: 0.9450 - val_bbox_mse: 0.0268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/60\n",
      "8400/8400 [==============================] - 1s 178us/sample - loss: 0.1143 - classification_loss: 0.1095 - bbox_loss: 0.0122 - classification_accuracy: 0.9574 - bbox_mse: 0.0242 - val_loss: 0.1654 - val_classification_loss: 0.1592 - val_bbox_loss: 0.0139 - val_classification_accuracy: 0.9417 - val_bbox_mse: 0.0277\n",
      "Epoch 27/60\n",
      "8400/8400 [==============================] - 2s 200us/sample - loss: 0.1032 - classification_loss: 0.0973 - bbox_loss: 0.0115 - classification_accuracy: 0.9660 - bbox_mse: 0.0230 - val_loss: 0.1717 - val_classification_loss: 0.1662 - val_bbox_loss: 0.0138 - val_classification_accuracy: 0.9450 - val_bbox_mse: 0.0273\n",
      "Epoch 28/60\n",
      "8400/8400 [==============================] - 2s 222us/sample - loss: 0.1012 - classification_loss: 0.0971 - bbox_loss: 0.0115 - classification_accuracy: 0.9646 - bbox_mse: 0.0229 - val_loss: 0.1874 - val_classification_loss: 0.1805 - val_bbox_loss: 0.0144 - val_classification_accuracy: 0.9408 - val_bbox_mse: 0.0286\n",
      "Epoch 29/60\n",
      "8400/8400 [==============================] - 1s 158us/sample - loss: 0.0923 - classification_loss: 0.0863 - bbox_loss: 0.0110 - classification_accuracy: 0.9689 - bbox_mse: 0.0220 - val_loss: 0.1853 - val_classification_loss: 0.1782 - val_bbox_loss: 0.0143 - val_classification_accuracy: 0.9392 - val_bbox_mse: 0.0282\n",
      "Epoch 30/60\n",
      "8400/8400 [==============================] - 1s 177us/sample - loss: 0.0939 - classification_loss: 0.0886 - bbox_loss: 0.0113 - classification_accuracy: 0.9693 - bbox_mse: 0.0226 - val_loss: 0.1759 - val_classification_loss: 0.1705 - val_bbox_loss: 0.0143 - val_classification_accuracy: 0.9442 - val_bbox_mse: 0.0283\n",
      "Epoch 31/60\n",
      "8400/8400 [==============================] - 2s 179us/sample - loss: 0.0930 - classification_loss: 0.0870 - bbox_loss: 0.0112 - classification_accuracy: 0.9657 - bbox_mse: 0.0224 - val_loss: 0.1675 - val_classification_loss: 0.1627 - val_bbox_loss: 0.0134 - val_classification_accuracy: 0.9525 - val_bbox_mse: 0.0267\n",
      "Epoch 32/60\n",
      "8400/8400 [==============================] - 1s 145us/sample - loss: 0.0812 - classification_loss: 0.0757 - bbox_loss: 0.0104 - classification_accuracy: 0.9738 - bbox_mse: 0.0209 - val_loss: 0.1693 - val_classification_loss: 0.1614 - val_bbox_loss: 0.0131 - val_classification_accuracy: 0.9458 - val_bbox_mse: 0.0263\n",
      "Epoch 33/60\n",
      "8400/8400 [==============================] - 1s 141us/sample - loss: 0.0835 - classification_loss: 0.0784 - bbox_loss: 0.0110 - classification_accuracy: 0.9714 - bbox_mse: 0.0219 - val_loss: 0.1746 - val_classification_loss: 0.1667 - val_bbox_loss: 0.0131 - val_classification_accuracy: 0.9467 - val_bbox_mse: 0.0264\n",
      "Epoch 34/60\n",
      "8400/8400 [==============================] - 2s 287us/sample - loss: 0.0854 - classification_loss: 0.0797 - bbox_loss: 0.0108 - classification_accuracy: 0.9689 - bbox_mse: 0.0216 - val_loss: 0.1653 - val_classification_loss: 0.1597 - val_bbox_loss: 0.0139 - val_classification_accuracy: 0.9442 - val_bbox_mse: 0.0277\n",
      "Epoch 35/60\n",
      "8400/8400 [==============================] - 2s 200us/sample - loss: 0.0792 - classification_loss: 0.0745 - bbox_loss: 0.0105 - classification_accuracy: 0.9739 - bbox_mse: 0.0210 - val_loss: 0.1674 - val_classification_loss: 0.1624 - val_bbox_loss: 0.0130 - val_classification_accuracy: 0.9433 - val_bbox_mse: 0.0257\n",
      "Epoch 36/60\n",
      "8400/8400 [==============================] - 1s 161us/sample - loss: 0.0752 - classification_loss: 0.0705 - bbox_loss: 0.0103 - classification_accuracy: 0.9760 - bbox_mse: 0.0205 - val_loss: 0.1795 - val_classification_loss: 0.1751 - val_bbox_loss: 0.0132 - val_classification_accuracy: 0.9442 - val_bbox_mse: 0.0260\n",
      "Epoch 37/60\n",
      "8400/8400 [==============================] - 3s 309us/sample - loss: 0.0705 - classification_loss: 0.0652 - bbox_loss: 0.0102 - classification_accuracy: 0.9776 - bbox_mse: 0.0203 - val_loss: 0.1796 - val_classification_loss: 0.1717 - val_bbox_loss: 0.0131 - val_classification_accuracy: 0.9425 - val_bbox_mse: 0.0263\n",
      "Epoch 38/60\n",
      "8400/8400 [==============================] - 2s 276us/sample - loss: 0.0739 - classification_loss: 0.0689 - bbox_loss: 0.0104 - classification_accuracy: 0.9743 - bbox_mse: 0.0208 - val_loss: 0.1543 - val_classification_loss: 0.1504 - val_bbox_loss: 0.0128 - val_classification_accuracy: 0.9558 - val_bbox_mse: 0.0255\n",
      "Epoch 39/60\n",
      "8400/8400 [==============================] - 2s 262us/sample - loss: 0.0675 - classification_loss: 0.0622 - bbox_loss: 0.0102 - classification_accuracy: 0.9762 - bbox_mse: 0.0204 - val_loss: 0.1814 - val_classification_loss: 0.1751 - val_bbox_loss: 0.0131 - val_classification_accuracy: 0.9442 - val_bbox_mse: 0.0260\n",
      "Epoch 40/60\n",
      "8400/8400 [==============================] - 2s 230us/sample - loss: 0.0634 - classification_loss: 0.0583 - bbox_loss: 0.0099 - classification_accuracy: 0.9799 - bbox_mse: 0.0198 - val_loss: 0.1624 - val_classification_loss: 0.1552 - val_bbox_loss: 0.0127 - val_classification_accuracy: 0.9467 - val_bbox_mse: 0.0252\n",
      "Epoch 41/60\n",
      "8400/8400 [==============================] - 2s 218us/sample - loss: 0.0700 - classification_loss: 0.0648 - bbox_loss: 0.0102 - classification_accuracy: 0.9764 - bbox_mse: 0.0204 - val_loss: 0.1833 - val_classification_loss: 0.1783 - val_bbox_loss: 0.0128 - val_classification_accuracy: 0.9417 - val_bbox_mse: 0.0256\n",
      "Epoch 42/60\n",
      "8400/8400 [==============================] - 2s 212us/sample - loss: 0.0600 - classification_loss: 0.0549 - bbox_loss: 0.0096 - classification_accuracy: 0.9806 - bbox_mse: 0.0192 - val_loss: 0.2047 - val_classification_loss: 0.1956 - val_bbox_loss: 0.0138 - val_classification_accuracy: 0.9425 - val_bbox_mse: 0.0280\n",
      "Epoch 43/60\n",
      "8400/8400 [==============================] - 2s 211us/sample - loss: 0.0544 - classification_loss: 0.0494 - bbox_loss: 0.0094 - classification_accuracy: 0.9825 - bbox_mse: 0.0187 - val_loss: 0.1782 - val_classification_loss: 0.1738 - val_bbox_loss: 0.0137 - val_classification_accuracy: 0.9542 - val_bbox_mse: 0.0268\n",
      "Epoch 44/60\n",
      "8400/8400 [==============================] - 2s 212us/sample - loss: 0.0506 - classification_loss: 0.0458 - bbox_loss: 0.0093 - classification_accuracy: 0.9837 - bbox_mse: 0.0186 - val_loss: 0.1706 - val_classification_loss: 0.1630 - val_bbox_loss: 0.0128 - val_classification_accuracy: 0.9483 - val_bbox_mse: 0.0252\n",
      "Epoch 45/60\n",
      "8400/8400 [==============================] - 2s 191us/sample - loss: 0.0594 - classification_loss: 0.0543 - bbox_loss: 0.0097 - classification_accuracy: 0.9814 - bbox_mse: 0.0194 - val_loss: 0.1561 - val_classification_loss: 0.1506 - val_bbox_loss: 0.0121 - val_classification_accuracy: 0.9550 - val_bbox_mse: 0.0241\n",
      "Epoch 46/60\n",
      "8400/8400 [==============================] - 2s 184us/sample - loss: 0.0501 - classification_loss: 0.0455 - bbox_loss: 0.0091 - classification_accuracy: 0.9844 - bbox_mse: 0.0182 - val_loss: 0.1590 - val_classification_loss: 0.1514 - val_bbox_loss: 0.0121 - val_classification_accuracy: 0.9500 - val_bbox_mse: 0.0244\n",
      "Epoch 47/60\n",
      "8400/8400 [==============================] - 2s 269us/sample - loss: 0.0480 - classification_loss: 0.0433 - bbox_loss: 0.0091 - classification_accuracy: 0.9846 - bbox_mse: 0.0181 - val_loss: 0.1621 - val_classification_loss: 0.1550 - val_bbox_loss: 0.0119 - val_classification_accuracy: 0.9508 - val_bbox_mse: 0.0239\n",
      "Epoch 48/60\n",
      "8400/8400 [==============================] - 2s 260us/sample - loss: 0.0484 - classification_loss: 0.0436 - bbox_loss: 0.0091 - classification_accuracy: 0.9857 - bbox_mse: 0.0182 - val_loss: 0.2006 - val_classification_loss: 0.1950 - val_bbox_loss: 0.0122 - val_classification_accuracy: 0.9433 - val_bbox_mse: 0.0243\n",
      "Epoch 49/60\n",
      "8400/8400 [==============================] - 2s 269us/sample - loss: 0.0511 - classification_loss: 0.0475 - bbox_loss: 0.0093 - classification_accuracy: 0.9845 - bbox_mse: 0.0186 - val_loss: 0.1639 - val_classification_loss: 0.1585 - val_bbox_loss: 0.0121 - val_classification_accuracy: 0.9500 - val_bbox_mse: 0.0242\n",
      "Epoch 50/60\n",
      "8400/8400 [==============================] - 3s 316us/sample - loss: 0.0499 - classification_loss: 0.0451 - bbox_loss: 0.0092 - classification_accuracy: 0.9865 - bbox_mse: 0.0184 - val_loss: 0.1529 - val_classification_loss: 0.1463 - val_bbox_loss: 0.0118 - val_classification_accuracy: 0.9567 - val_bbox_mse: 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/60\n",
      "8400/8400 [==============================] - 2s 293us/sample - loss: 0.0504 - classification_loss: 0.0457 - bbox_loss: 0.0093 - classification_accuracy: 0.9842 - bbox_mse: 0.0187 - val_loss: 0.1655 - val_classification_loss: 0.1589 - val_bbox_loss: 0.0127 - val_classification_accuracy: 0.9525 - val_bbox_mse: 0.0249\n",
      "Epoch 52/60\n",
      "8400/8400 [==============================] - 2s 285us/sample - loss: 0.0509 - classification_loss: 0.0461 - bbox_loss: 0.0093 - classification_accuracy: 0.9836 - bbox_mse: 0.0186 - val_loss: 0.1701 - val_classification_loss: 0.1621 - val_bbox_loss: 0.0119 - val_classification_accuracy: 0.9525 - val_bbox_mse: 0.0239\n",
      "Epoch 53/60\n",
      "8400/8400 [==============================] - 2s 264us/sample - loss: 0.0393 - classification_loss: 0.0347 - bbox_loss: 0.0087 - classification_accuracy: 0.9893 - bbox_mse: 0.0174 - val_loss: 0.1590 - val_classification_loss: 0.1534 - val_bbox_loss: 0.0120 - val_classification_accuracy: 0.9558 - val_bbox_mse: 0.0238\n",
      "Epoch 54/60\n",
      "8400/8400 [==============================] - 2s 263us/sample - loss: 0.0360 - classification_loss: 0.0316 - bbox_loss: 0.0085 - classification_accuracy: 0.9907 - bbox_mse: 0.0169 - val_loss: 0.1619 - val_classification_loss: 0.1581 - val_bbox_loss: 0.0117 - val_classification_accuracy: 0.9575 - val_bbox_mse: 0.0234\n",
      "Epoch 55/60\n",
      "8400/8400 [==============================] - 2s 228us/sample - loss: 0.0413 - classification_loss: 0.0372 - bbox_loss: 0.0086 - classification_accuracy: 0.9868 - bbox_mse: 0.0171 - val_loss: 0.1663 - val_classification_loss: 0.1621 - val_bbox_loss: 0.0118 - val_classification_accuracy: 0.9517 - val_bbox_mse: 0.0236\n",
      "Epoch 56/60\n",
      "8400/8400 [==============================] - 2s 267us/sample - loss: 0.0340 - classification_loss: 0.0296 - bbox_loss: 0.0085 - classification_accuracy: 0.9913 - bbox_mse: 0.0171 - val_loss: 0.1610 - val_classification_loss: 0.1542 - val_bbox_loss: 0.0117 - val_classification_accuracy: 0.9625 - val_bbox_mse: 0.0234\n",
      "Epoch 57/60\n",
      "8400/8400 [==============================] - 2s 240us/sample - loss: 0.0323 - classification_loss: 0.0280 - bbox_loss: 0.0084 - classification_accuracy: 0.9914 - bbox_mse: 0.0167 - val_loss: 0.1667 - val_classification_loss: 0.1615 - val_bbox_loss: 0.0113 - val_classification_accuracy: 0.9550 - val_bbox_mse: 0.0225\n",
      "Epoch 58/60\n",
      "8400/8400 [==============================] - 2s 198us/sample - loss: 0.0323 - classification_loss: 0.0281 - bbox_loss: 0.0083 - classification_accuracy: 0.9900 - bbox_mse: 0.0167 - val_loss: 0.1651 - val_classification_loss: 0.1592 - val_bbox_loss: 0.0123 - val_classification_accuracy: 0.9533 - val_bbox_mse: 0.0244\n",
      "Epoch 59/60\n",
      "8400/8400 [==============================] - 2s 264us/sample - loss: 0.0319 - classification_loss: 0.0276 - bbox_loss: 0.0082 - classification_accuracy: 0.9912 - bbox_mse: 0.0164 - val_loss: 0.1714 - val_classification_loss: 0.1634 - val_bbox_loss: 0.0120 - val_classification_accuracy: 0.9558 - val_bbox_mse: 0.0241\n",
      "Epoch 60/60\n",
      "8400/8400 [==============================] - 2s 217us/sample - loss: 0.0335 - classification_loss: 0.0299 - bbox_loss: 0.0083 - classification_accuracy: 0.9905 - bbox_mse: 0.0165 - val_loss: 0.1629 - val_classification_loss: 0.1551 - val_bbox_loss: 0.0115 - val_classification_accuracy: 0.9583 - val_bbox_mse: 0.0228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a515b68f48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLU_model.fit(X_train, [y_train[:,:,:,:2],y_train[:,:,:,2:]], batch_size=64, epochs=60,\n",
    "            validation_data=(X_val, [y_val[:,:,:,:2],y_val[:,:,:,2:]]),\n",
    "            callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TanH Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TanH_PNet():\n",
    "    \n",
    "    initializer = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "    # input layer\n",
    "    visible = Input(shape=(12,12,3))\n",
    "    \n",
    "    # CNN Stage 1\n",
    "    conv1 = Conv2D(10, kernel_size=(3,3), activation='tanh')(visible)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "   \n",
    "    #CNN Stage 2\n",
    "    conv2 = Conv2D(16, kernel_size=(3,3), activation='tanh')(pool1)\n",
    "    \n",
    "    # CNN stage 3\n",
    "    conv3 = Conv2D(32, kernel_size=(3,3), activation='tanh')(conv2)\n",
    "    \n",
    "    # output \n",
    "    pred_classification = Conv2D(2, kernel_size=(1,1), activation='softmax', name='classification')(conv3)\n",
    "    pred_bbox = Conv2D(4, kernel_size=(1,1), name='bbox')(conv3)\n",
    "    \n",
    "    model = Model(inputs=visible, outputs=[pred_classification, pred_bbox])\n",
    "                  \n",
    " \n",
    "    #compute the loss function over bounding box \n",
    "    bbox_loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # Define bbox loss : MSE(bounding_bbox) * y_classification[1] (...ignore if no face)\n",
    "    # Actually, \n",
    "    # we could use 'mse' but because bbox error is \"zero\" if \"no face\", we need to multiply 'mse' by \"y_classification\"  \n",
    "    def bbox_loss_fn():\n",
    "            #Create boox loss function \n",
    "        def loss(y_true,y_pred):\n",
    "            return (bbox_loss(pred_bbox, y_bbox) * y_classification[:,:,:,1])\n",
    "        # Return a function\n",
    "        return loss\n",
    "    \n",
    " \n",
    "    # create placeholder for targets\n",
    "    y_classification = tf.keras.backend.placeholder(dtype='float32', shape=pred_classification.shape) # shapes of output1 your target has\n",
    "    y_bbox = tf.keras.backend.placeholder(dtype='float32', shape=pred_bbox.shape) # shapes of output2 your target has\n",
    "    \n",
    "    # Set optimizer\n",
    "    learning_rate = 1e-3\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=adam, \n",
    "                  loss ={'classification': 'binary_crossentropy',\n",
    "                         'bbox': bbox_loss_fn()},\n",
    "                  loss_weights = {'classification': 1.0, \n",
    "                                  'bbox': 0.5},\n",
    "                  target_tensors=[y_classification,y_bbox],\n",
    "                  metrics={'classification': 'accuracy',\n",
    "                           'bbox': 'mse'})\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    # plot graph\n",
    "    plot_model(model, to_file='MTCNN P-Net tanh.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 12, 12, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 10)   280         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 10)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 16)     1456        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 1, 1, 32)     4640        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classification (Conv2D)         (None, 1, 1, 2)      66          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bbox (Conv2D)                   (None, 1, 1, 4)      132         conv2d_5[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,574\n",
      "Trainable params: 6,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "TanH_model = TanH_PNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=('logs\\\\p-net-benchmark\\\\TanH'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8400 samples, validate on 1200 samples\n",
      "Epoch 1/60\n",
      "8400/8400 [==============================] - 4s 534us/sample - loss: 0.5664 - classification_loss: 0.5424 - bbox_loss: 0.0476 - classification_accuracy: 0.7424 - bbox_mse: 0.0956 - val_loss: 0.4873 - val_classification_loss: 0.4687 - val_bbox_loss: 0.0360 - val_classification_accuracy: 0.7758 - val_bbox_mse: 0.0714\n",
      "Epoch 2/60\n",
      "8400/8400 [==============================] - 2s 280us/sample - loss: 0.4534 - classification_loss: 0.4362 - bbox_loss: 0.0317 - classification_accuracy: 0.8125 - bbox_mse: 0.0633 - val_loss: 0.4443 - val_classification_loss: 0.4294 - val_bbox_loss: 0.0299 - val_classification_accuracy: 0.8250 - val_bbox_mse: 0.0600\n",
      "Epoch 3/60\n",
      "8400/8400 [==============================] - 1s 168us/sample - loss: 0.4029 - classification_loss: 0.3885 - bbox_loss: 0.0273 - classification_accuracy: 0.8339 - bbox_mse: 0.0545 - val_loss: 0.3779 - val_classification_loss: 0.3641 - val_bbox_loss: 0.0265 - val_classification_accuracy: 0.8517 - val_bbox_mse: 0.0529\n",
      "Epoch 4/60\n",
      "8400/8400 [==============================] - 2s 181us/sample - loss: 0.3607 - classification_loss: 0.3479 - bbox_loss: 0.0246 - classification_accuracy: 0.8564 - bbox_mse: 0.0493 - val_loss: 0.3368 - val_classification_loss: 0.3274 - val_bbox_loss: 0.0237 - val_classification_accuracy: 0.8717 - val_bbox_mse: 0.0473\n",
      "Epoch 5/60\n",
      "8400/8400 [==============================] - 1s 162us/sample - loss: 0.3291 - classification_loss: 0.3175 - bbox_loss: 0.0228 - classification_accuracy: 0.8706 - bbox_mse: 0.0458 - val_loss: 0.3216 - val_classification_loss: 0.3113 - val_bbox_loss: 0.0235 - val_classification_accuracy: 0.8708 - val_bbox_mse: 0.0468\n",
      "Epoch 6/60\n",
      "8400/8400 [==============================] - 2s 210us/sample - loss: 0.3085 - classification_loss: 0.2979 - bbox_loss: 0.0219 - classification_accuracy: 0.8800 - bbox_mse: 0.0436 - val_loss: 0.2972 - val_classification_loss: 0.2868 - val_bbox_loss: 0.0220 - val_classification_accuracy: 0.8767 - val_bbox_mse: 0.0430\n",
      "Epoch 7/60\n",
      "8400/8400 [==============================] - 2s 262us/sample - loss: 0.2998 - classification_loss: 0.2889 - bbox_loss: 0.0216 - classification_accuracy: 0.8814 - bbox_mse: 0.0430 - val_loss: 0.2948 - val_classification_loss: 0.2826 - val_bbox_loss: 0.0215 - val_classification_accuracy: 0.8783 - val_bbox_mse: 0.0428\n",
      "Epoch 8/60\n",
      "8400/8400 [==============================] - 2s 204us/sample - loss: 0.2902 - classification_loss: 0.2788 - bbox_loss: 0.0209 - classification_accuracy: 0.8865 - bbox_mse: 0.0417 - val_loss: 0.2795 - val_classification_loss: 0.2705 - val_bbox_loss: 0.0207 - val_classification_accuracy: 0.8950 - val_bbox_mse: 0.0410\n",
      "Epoch 9/60\n",
      "8400/8400 [==============================] - 2s 270us/sample - loss: 0.2857 - classification_loss: 0.2747 - bbox_loss: 0.0205 - classification_accuracy: 0.8882 - bbox_mse: 0.0410 - val_loss: 0.2801 - val_classification_loss: 0.2704 - val_bbox_loss: 0.0211 - val_classification_accuracy: 0.8917 - val_bbox_mse: 0.0419s: 0.2767 - bbox_loss: 0.0206 - classification_accuracy: 0.8880 - bbox_mse: \n",
      "Epoch 10/60\n",
      "8400/8400 [==============================] - 2s 189us/sample - loss: 0.2756 - classification_loss: 0.2655 - bbox_loss: 0.0203 - classification_accuracy: 0.8901 - bbox_mse: 0.0403 - val_loss: 0.2759 - val_classification_loss: 0.2662 - val_bbox_loss: 0.0204 - val_classification_accuracy: 0.8925 - val_bbox_mse: 0.0404\n",
      "Epoch 11/60\n",
      "8400/8400 [==============================] - 1s 145us/sample - loss: 0.2722 - classification_loss: 0.2628 - bbox_loss: 0.0201 - classification_accuracy: 0.8945 - bbox_mse: 0.0401 - val_loss: 0.2689 - val_classification_loss: 0.2595 - val_bbox_loss: 0.0207 - val_classification_accuracy: 0.8883 - val_bbox_mse: 0.0409\n",
      "Epoch 12/60\n",
      "8400/8400 [==============================] - 2s 192us/sample - loss: 0.2672 - classification_loss: 0.2571 - bbox_loss: 0.0199 - classification_accuracy: 0.8921 - bbox_mse: 0.0398 - val_loss: 0.2602 - val_classification_loss: 0.2482 - val_bbox_loss: 0.0200 - val_classification_accuracy: 0.8975 - val_bbox_mse: 0.0397\n",
      "Epoch 13/60\n",
      "8400/8400 [==============================] - 2s 188us/sample - loss: 0.2578 - classification_loss: 0.2478 - bbox_loss: 0.0193 - classification_accuracy: 0.9002 - bbox_mse: 0.0387 - val_loss: 0.2653 - val_classification_loss: 0.2548 - val_bbox_loss: 0.0202 - val_classification_accuracy: 0.8942 - val_bbox_mse: 0.0400\n",
      "Epoch 14/60\n",
      "8400/8400 [==============================] - 1s 146us/sample - loss: 0.2590 - classification_loss: 0.2487 - bbox_loss: 0.0195 - classification_accuracy: 0.8975 - bbox_mse: 0.0390 - val_loss: 0.2518 - val_classification_loss: 0.2407 - val_bbox_loss: 0.0194 - val_classification_accuracy: 0.9017 - val_bbox_mse: 0.0386\n",
      "Epoch 15/60\n",
      "8400/8400 [==============================] - 1s 144us/sample - loss: 0.2504 - classification_loss: 0.2404 - bbox_loss: 0.0191 - classification_accuracy: 0.9013 - bbox_mse: 0.0383 - val_loss: 0.2544 - val_classification_loss: 0.2453 - val_bbox_loss: 0.0198 - val_classification_accuracy: 0.9000 - val_bbox_mse: 0.0394\n",
      "Epoch 16/60\n",
      "8400/8400 [==============================] - 2s 216us/sample - loss: 0.2441 - classification_loss: 0.2346 - bbox_loss: 0.0189 - classification_accuracy: 0.9052 - bbox_mse: 0.0378 - val_loss: 0.3009 - val_classification_loss: 0.2897 - val_bbox_loss: 0.0216 - val_classification_accuracy: 0.8800 - val_bbox_mse: 0.0430\n",
      "Epoch 17/60\n",
      "8400/8400 [==============================] - 1s 172us/sample - loss: 0.2416 - classification_loss: 0.2317 - bbox_loss: 0.0188 - classification_accuracy: 0.9046 - bbox_mse: 0.0376 - val_loss: 0.2488 - val_classification_loss: 0.2400 - val_bbox_loss: 0.0192 - val_classification_accuracy: 0.9025 - val_bbox_mse: 0.0381\n",
      "Epoch 18/60\n",
      "8400/8400 [==============================] - 1s 174us/sample - loss: 0.2360 - classification_loss: 0.2269 - bbox_loss: 0.0185 - classification_accuracy: 0.9099 - bbox_mse: 0.0369 - val_loss: 0.2509 - val_classification_loss: 0.2391 - val_bbox_loss: 0.0197 - val_classification_accuracy: 0.8983 - val_bbox_mse: 0.0393\n",
      "Epoch 19/60\n",
      "8400/8400 [==============================] - 1s 178us/sample - loss: 0.2345 - classification_loss: 0.2261 - bbox_loss: 0.0185 - classification_accuracy: 0.9090 - bbox_mse: 0.0369 - val_loss: 0.2635 - val_classification_loss: 0.2545 - val_bbox_loss: 0.0202 - val_classification_accuracy: 0.8942 - val_bbox_mse: 0.0405\n",
      "Epoch 20/60\n",
      "8400/8400 [==============================] - 1s 172us/sample - loss: 0.2287 - classification_loss: 0.2195 - bbox_loss: 0.0183 - classification_accuracy: 0.9113 - bbox_mse: 0.0366 - val_loss: 0.2324 - val_classification_loss: 0.2231 - val_bbox_loss: 0.0187 - val_classification_accuracy: 0.9092 - val_bbox_mse: 0.0371\n",
      "Epoch 21/60\n",
      "8400/8400 [==============================] - 2s 193us/sample - loss: 0.2239 - classification_loss: 0.2149 - bbox_loss: 0.0181 - classification_accuracy: 0.9118 - bbox_mse: 0.0360 - val_loss: 0.2299 - val_classification_loss: 0.2229 - val_bbox_loss: 0.0191 - val_classification_accuracy: 0.9142 - val_bbox_mse: 0.0373\n",
      "Epoch 22/60\n",
      "8400/8400 [==============================] - 1s 174us/sample - loss: 0.2211 - classification_loss: 0.2113 - bbox_loss: 0.0179 - classification_accuracy: 0.9142 - bbox_mse: 0.0360 - val_loss: 0.2258 - val_classification_loss: 0.2166 - val_bbox_loss: 0.0180 - val_classification_accuracy: 0.9100 - val_bbox_mse: 0.0362\n",
      "Epoch 23/60\n",
      "8400/8400 [==============================] - 1s 163us/sample - loss: 0.2153 - classification_loss: 0.2065 - bbox_loss: 0.0176 - classification_accuracy: 0.9183 - bbox_mse: 0.0352 - val_loss: 0.2273 - val_classification_loss: 0.2187 - val_bbox_loss: 0.0187 - val_classification_accuracy: 0.9075 - val_bbox_mse: 0.0369\n",
      "Epoch 24/60\n",
      "8400/8400 [==============================] - 2s 200us/sample - loss: 0.2143 - classification_loss: 0.2052 - bbox_loss: 0.0175 - classification_accuracy: 0.9152 - bbox_mse: 0.0350 - val_loss: 0.2312 - val_classification_loss: 0.2226 - val_bbox_loss: 0.0185 - val_classification_accuracy: 0.9100 - val_bbox_mse: 0.0367\n",
      "Epoch 25/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 2s 262us/sample - loss: 0.2036 - classification_loss: 0.1954 - bbox_loss: 0.0171 - classification_accuracy: 0.9227 - bbox_mse: 0.0341 - val_loss: 0.2301 - val_classification_loss: 0.2204 - val_bbox_loss: 0.0185 - val_classification_accuracy: 0.8992 - val_bbox_mse: 0.0367classification_loss: 0.1927 - bbox_loss: 0.0170 - classification_accuracy: 0.9239 - bbox\n",
      "Epoch 26/60\n",
      "8400/8400 [==============================] - 2s 253us/sample - loss: 0.2037 - classification_loss: 0.1953 - bbox_loss: 0.0172 - classification_accuracy: 0.9217 - bbox_mse: 0.0342 - val_loss: 0.2408 - val_classification_loss: 0.2323 - val_bbox_loss: 0.0187 - val_classification_accuracy: 0.9050 - val_bbox_mse: 0.0375\n",
      "Epoch 27/60\n",
      "8400/8400 [==============================] - 2s 205us/sample - loss: 0.2033 - classification_loss: 0.1950 - bbox_loss: 0.0173 - classification_accuracy: 0.9211 - bbox_mse: 0.0345 - val_loss: 0.2311 - val_classification_loss: 0.2216 - val_bbox_loss: 0.0183 - val_classification_accuracy: 0.9050 - val_bbox_mse: 0.0363\n",
      "Epoch 28/60\n",
      "8400/8400 [==============================] - 1s 172us/sample - loss: 0.1940 - classification_loss: 0.1865 - bbox_loss: 0.0167 - classification_accuracy: 0.9263 - bbox_mse: 0.0335 - val_loss: 0.2130 - val_classification_loss: 0.2051 - val_bbox_loss: 0.0178 - val_classification_accuracy: 0.9150 - val_bbox_mse: 0.0353\n",
      "Epoch 29/60\n",
      "8400/8400 [==============================] - 1s 154us/sample - loss: 0.1870 - classification_loss: 0.1781 - bbox_loss: 0.0164 - classification_accuracy: 0.9290 - bbox_mse: 0.0329 - val_loss: 0.2134 - val_classification_loss: 0.2035 - val_bbox_loss: 0.0174 - val_classification_accuracy: 0.9150 - val_bbox_mse: 0.0345\n",
      "Epoch 30/60\n",
      "8400/8400 [==============================] - 1s 174us/sample - loss: 0.1832 - classification_loss: 0.1751 - bbox_loss: 0.0163 - classification_accuracy: 0.9312 - bbox_mse: 0.0327 - val_loss: 0.2061 - val_classification_loss: 0.1969 - val_bbox_loss: 0.0177 - val_classification_accuracy: 0.9175 - val_bbox_mse: 0.0354\n",
      "Epoch 31/60\n",
      "8400/8400 [==============================] - 1s 143us/sample - loss: 0.1811 - classification_loss: 0.1739 - bbox_loss: 0.0163 - classification_accuracy: 0.9295 - bbox_mse: 0.0326 - val_loss: 0.2070 - val_classification_loss: 0.2014 - val_bbox_loss: 0.0171 - val_classification_accuracy: 0.9183 - val_bbox_mse: 0.0342\n",
      "Epoch 32/60\n",
      "8400/8400 [==============================] - 1s 156us/sample - loss: 0.1789 - classification_loss: 0.1710 - bbox_loss: 0.0164 - classification_accuracy: 0.9346 - bbox_mse: 0.0326 - val_loss: 0.1966 - val_classification_loss: 0.1906 - val_bbox_loss: 0.0170 - val_classification_accuracy: 0.9292 - val_bbox_mse: 0.0338\n",
      "Epoch 33/60\n",
      "8400/8400 [==============================] - 1s 176us/sample - loss: 0.1718 - classification_loss: 0.1632 - bbox_loss: 0.0160 - classification_accuracy: 0.9365 - bbox_mse: 0.0321 - val_loss: 0.2147 - val_classification_loss: 0.2052 - val_bbox_loss: 0.0172 - val_classification_accuracy: 0.9192 - val_bbox_mse: 0.0346\n",
      "Epoch 34/60\n",
      "8400/8400 [==============================] - 1s 147us/sample - loss: 0.1704 - classification_loss: 0.1625 - bbox_loss: 0.0159 - classification_accuracy: 0.9379 - bbox_mse: 0.0317 - val_loss: 0.2011 - val_classification_loss: 0.1918 - val_bbox_loss: 0.0173 - val_classification_accuracy: 0.9233 - val_bbox_mse: 0.0342\n",
      "Epoch 35/60\n",
      "8400/8400 [==============================] - 1s 149us/sample - loss: 0.1621 - classification_loss: 0.1538 - bbox_loss: 0.0154 - classification_accuracy: 0.9382 - bbox_mse: 0.0310 - val_loss: 0.2285 - val_classification_loss: 0.2194 - val_bbox_loss: 0.0186 - val_classification_accuracy: 0.9075 - val_bbox_mse: 0.0371\n",
      "Epoch 36/60\n",
      "8400/8400 [==============================] - 1s 174us/sample - loss: 0.1595 - classification_loss: 0.1513 - bbox_loss: 0.0154 - classification_accuracy: 0.9431 - bbox_mse: 0.0309 - val_loss: 0.1964 - val_classification_loss: 0.1871 - val_bbox_loss: 0.0167 - val_classification_accuracy: 0.9225 - val_bbox_mse: 0.0333\n",
      "Epoch 37/60\n",
      "8400/8400 [==============================] - 1s 159us/sample - loss: 0.1531 - classification_loss: 0.1465 - bbox_loss: 0.0153 - classification_accuracy: 0.9430 - bbox_mse: 0.0304 - val_loss: 0.1850 - val_classification_loss: 0.1758 - val_bbox_loss: 0.0163 - val_classification_accuracy: 0.9342 - val_bbox_mse: 0.0327\n",
      "Epoch 38/60\n",
      "8400/8400 [==============================] - 1s 139us/sample - loss: 0.1457 - classification_loss: 0.1384 - bbox_loss: 0.0146 - classification_accuracy: 0.9476 - bbox_mse: 0.0292 - val_loss: 0.1935 - val_classification_loss: 0.1844 - val_bbox_loss: 0.0166 - val_classification_accuracy: 0.9283 - val_bbox_mse: 0.0333\n",
      "Epoch 39/60\n",
      "8400/8400 [==============================] - 1s 151us/sample - loss: 0.1431 - classification_loss: 0.1354 - bbox_loss: 0.0146 - classification_accuracy: 0.9476 - bbox_mse: 0.0293 - val_loss: 0.2015 - val_classification_loss: 0.1924 - val_bbox_loss: 0.0171 - val_classification_accuracy: 0.9183 - val_bbox_mse: 0.0343\n",
      "Epoch 40/60\n",
      "8400/8400 [==============================] - 1s 150us/sample - loss: 0.1390 - classification_loss: 0.1326 - bbox_loss: 0.0145 - classification_accuracy: 0.9507 - bbox_mse: 0.0290 - val_loss: 0.2068 - val_classification_loss: 0.1983 - val_bbox_loss: 0.0168 - val_classification_accuracy: 0.9183 - val_bbox_mse: 0.0339\n",
      "Epoch 41/60\n",
      "8400/8400 [==============================] - 1s 145us/sample - loss: 0.1380 - classification_loss: 0.1309 - bbox_loss: 0.0145 - classification_accuracy: 0.9501 - bbox_mse: 0.0287 - val_loss: 0.1897 - val_classification_loss: 0.1820 - val_bbox_loss: 0.0170 - val_classification_accuracy: 0.9267 - val_bbox_mse: 0.0340\n",
      "Epoch 42/60\n",
      "8400/8400 [==============================] - 1s 150us/sample - loss: 0.1321 - classification_loss: 0.1248 - bbox_loss: 0.0142 - classification_accuracy: 0.9542 - bbox_mse: 0.0284 - val_loss: 0.1966 - val_classification_loss: 0.1879 - val_bbox_loss: 0.0172 - val_classification_accuracy: 0.9292 - val_bbox_mse: 0.0346\n",
      "Epoch 43/60\n",
      "8400/8400 [==============================] - 1s 156us/sample - loss: 0.1266 - classification_loss: 0.1199 - bbox_loss: 0.0139 - classification_accuracy: 0.9574 - bbox_mse: 0.0277 - val_loss: 0.2118 - val_classification_loss: 0.2021 - val_bbox_loss: 0.0175 - val_classification_accuracy: 0.9217 - val_bbox_mse: 0.0349\n",
      "Epoch 44/60\n",
      "8400/8400 [==============================] - 2s 226us/sample - loss: 0.1203 - classification_loss: 0.1131 - bbox_loss: 0.0136 - classification_accuracy: 0.9588 - bbox_mse: 0.0273 - val_loss: 0.1802 - val_classification_loss: 0.1730 - val_bbox_loss: 0.0159 - val_classification_accuracy: 0.9317 - val_bbox_mse: 0.0319\n",
      "Epoch 45/60\n",
      "8400/8400 [==============================] - 1s 176us/sample - loss: 0.1179 - classification_loss: 0.1106 - bbox_loss: 0.0135 - classification_accuracy: 0.9583 - bbox_mse: 0.0272 - val_loss: 0.1704 - val_classification_loss: 0.1622 - val_bbox_loss: 0.0159 - val_classification_accuracy: 0.9342 - val_bbox_mse: 0.0315\n",
      "Epoch 46/60\n",
      "8400/8400 [==============================] - 2s 184us/sample - loss: 0.1170 - classification_loss: 0.1098 - bbox_loss: 0.0135 - classification_accuracy: 0.9582 - bbox_mse: 0.0269 - val_loss: 0.1622 - val_classification_loss: 0.1543 - val_bbox_loss: 0.0154 - val_classification_accuracy: 0.9392 - val_bbox_mse: 0.0307\n",
      "Epoch 47/60\n",
      "8400/8400 [==============================] - 2s 195us/sample - loss: 0.1088 - classification_loss: 0.1021 - bbox_loss: 0.0131 - classification_accuracy: 0.9635 - bbox_mse: 0.0262 - val_loss: 0.1708 - val_classification_loss: 0.1618 - val_bbox_loss: 0.0156 - val_classification_accuracy: 0.9317 - val_bbox_mse: 0.0311\n",
      "Epoch 48/60\n",
      "8400/8400 [==============================] - 1s 171us/sample - loss: 0.1049 - classification_loss: 0.0979 - bbox_loss: 0.0128 - classification_accuracy: 0.9649 - bbox_mse: 0.0259 - val_loss: 0.1661 - val_classification_loss: 0.1595 - val_bbox_loss: 0.0152 - val_classification_accuracy: 0.9400 - val_bbox_mse: 0.0304\n",
      "Epoch 49/60\n",
      "8400/8400 [==============================] - 1s 170us/sample - loss: 0.0975 - classification_loss: 0.0909 - bbox_loss: 0.0125 - classification_accuracy: 0.9677 - bbox_mse: 0.0249 - val_loss: 0.1662 - val_classification_loss: 0.1581 - val_bbox_loss: 0.0150 - val_classification_accuracy: 0.9408 - val_bbox_mse: 0.0303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/60\n",
      "8400/8400 [==============================] - 1s 161us/sample - loss: 0.0981 - classification_loss: 0.0915 - bbox_loss: 0.0126 - classification_accuracy: 0.9685 - bbox_mse: 0.0252 - val_loss: 0.1595 - val_classification_loss: 0.1527 - val_bbox_loss: 0.0152 - val_classification_accuracy: 0.9425 - val_bbox_mse: 0.0304\n",
      "Epoch 51/60\n",
      "8400/8400 [==============================] - 1s 165us/sample - loss: 0.0936 - classification_loss: 0.0871 - bbox_loss: 0.0123 - classification_accuracy: 0.9700 - bbox_mse: 0.0247 - val_loss: 0.1505 - val_classification_loss: 0.1426 - val_bbox_loss: 0.0147 - val_classification_accuracy: 0.9458 - val_bbox_mse: 0.0293\n",
      "Epoch 52/60\n",
      "8400/8400 [==============================] - 1s 173us/sample - loss: 0.0882 - classification_loss: 0.0819 - bbox_loss: 0.0120 - classification_accuracy: 0.9736 - bbox_mse: 0.0240 - val_loss: 0.1500 - val_classification_loss: 0.1425 - val_bbox_loss: 0.0146 - val_classification_accuracy: 0.9483 - val_bbox_mse: 0.0291\n",
      "Epoch 53/60\n",
      "8400/8400 [==============================] - 1s 177us/sample - loss: 0.0855 - classification_loss: 0.0792 - bbox_loss: 0.0121 - classification_accuracy: 0.9718 - bbox_mse: 0.0240 - val_loss: 0.1481 - val_classification_loss: 0.1404 - val_bbox_loss: 0.0145 - val_classification_accuracy: 0.9475 - val_bbox_mse: 0.0287\n",
      "Epoch 54/60\n",
      "8400/8400 [==============================] - 1s 166us/sample - loss: 0.0829 - classification_loss: 0.0773 - bbox_loss: 0.0121 - classification_accuracy: 0.9742 - bbox_mse: 0.0241 - val_loss: 0.1452 - val_classification_loss: 0.1380 - val_bbox_loss: 0.0142 - val_classification_accuracy: 0.9467 - val_bbox_mse: 0.0284\n",
      "Epoch 55/60\n",
      "8400/8400 [==============================] - 1s 155us/sample - loss: 0.0807 - classification_loss: 0.0747 - bbox_loss: 0.0120 - classification_accuracy: 0.9752 - bbox_mse: 0.0238 - val_loss: 0.1477 - val_classification_loss: 0.1394 - val_bbox_loss: 0.0142 - val_classification_accuracy: 0.9442 - val_bbox_mse: 0.0283\n",
      "Epoch 56/60\n",
      "8400/8400 [==============================] - 1s 178us/sample - loss: 0.0782 - classification_loss: 0.0728 - bbox_loss: 0.0118 - classification_accuracy: 0.9760 - bbox_mse: 0.0236 - val_loss: 0.1401 - val_classification_loss: 0.1319 - val_bbox_loss: 0.0139 - val_classification_accuracy: 0.9500 - val_bbox_mse: 0.0278\n",
      "Epoch 57/60\n",
      "8400/8400 [==============================] - 2s 208us/sample - loss: 0.0746 - classification_loss: 0.0686 - bbox_loss: 0.0116 - classification_accuracy: 0.9777 - bbox_mse: 0.0234 - val_loss: 0.1373 - val_classification_loss: 0.1290 - val_bbox_loss: 0.0143 - val_classification_accuracy: 0.9533 - val_bbox_mse: 0.0283\n",
      "Epoch 58/60\n",
      "8400/8400 [==============================] - 1s 158us/sample - loss: 0.0705 - classification_loss: 0.0654 - bbox_loss: 0.0115 - classification_accuracy: 0.9804 - bbox_mse: 0.0230 - val_loss: 0.1354 - val_classification_loss: 0.1276 - val_bbox_loss: 0.0137 - val_classification_accuracy: 0.9558 - val_bbox_mse: 0.0274\n",
      "Epoch 59/60\n",
      "8400/8400 [==============================] - 2s 193us/sample - loss: 0.0687 - classification_loss: 0.0632 - bbox_loss: 0.0115 - classification_accuracy: 0.9801 - bbox_mse: 0.0230 - val_loss: 0.1367 - val_classification_loss: 0.1286 - val_bbox_loss: 0.0142 - val_classification_accuracy: 0.9500 - val_bbox_mse: 0.0283\n",
      "Epoch 60/60\n",
      "8400/8400 [==============================] - 2s 189us/sample - loss: 0.0650 - classification_loss: 0.0590 - bbox_loss: 0.0113 - classification_accuracy: 0.9826 - bbox_mse: 0.0227 - val_loss: 0.1334 - val_classification_loss: 0.1266 - val_bbox_loss: 0.0137 - val_classification_accuracy: 0.9567 - val_bbox_mse: 0.0274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a518bf4dc8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TanH_model.fit(X_train, [y_train[:,:,:,:2],y_train[:,:,:,2:]], batch_size=64, epochs=60,\n",
    "            validation_data=(X_val, [y_val[:,:,:,:2],y_val[:,:,:,2:]]),\n",
    "            callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sigmoid Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_PNet():\n",
    "    \n",
    "    initializer = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "    # input layer\n",
    "    visible = Input(shape=(12,12,3))\n",
    "    \n",
    "    # CNN Stage 1\n",
    "    conv1 = Conv2D(10, kernel_size=(3,3), activation='sigmoid')(visible)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "   \n",
    "    #CNN Stage 2\n",
    "    conv2 = Conv2D(16, kernel_size=(3,3), activation='sigmoid')(pool1)\n",
    "    \n",
    "    # CNN stage 3\n",
    "    conv3 = Conv2D(32, kernel_size=(3,3), activation='sigmoid')(conv2)\n",
    "    \n",
    "    # output \n",
    "    pred_classification = Conv2D(2, kernel_size=(1,1), activation='softmax', name='classification')(conv3)\n",
    "    pred_bbox = Conv2D(4, kernel_size=(1,1), name='bbox')(conv3)\n",
    "    \n",
    "    model = Model(inputs=visible, outputs=[pred_classification, pred_bbox])\n",
    "                  \n",
    " \n",
    "    #compute the loss function over bounding box \n",
    "    bbox_loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # Define bbox loss : MSE(bounding_bbox) * y_classification[1] (...ignore if no face)\n",
    "    # Actually, \n",
    "    # we could use 'mse' but because bbox error is \"zero\" if \"no face\", we need to multiply 'mse' by \"y_classification\"  \n",
    "    def bbox_loss_fn():\n",
    "            #Create boox loss function \n",
    "        def loss(y_true,y_pred):\n",
    "            return (bbox_loss(pred_bbox, y_bbox) * y_classification[:,:,:,1])\n",
    "        # Return a function\n",
    "        return loss\n",
    "    \n",
    " \n",
    "    # create placeholder for targets\n",
    "    y_classification = tf.keras.backend.placeholder(dtype='float32', shape=pred_classification.shape) # shapes of output1 your target has\n",
    "    y_bbox = tf.keras.backend.placeholder(dtype='float32', shape=pred_bbox.shape) # shapes of output2 your target has\n",
    "    \n",
    "    # Set optimizer\n",
    "    learning_rate = 1e-3\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=adam, \n",
    "                  loss ={'classification': 'binary_crossentropy',\n",
    "                         'bbox': bbox_loss_fn()},\n",
    "                  loss_weights = {'classification': 1.0, \n",
    "                                  'bbox': 0.5},\n",
    "                  target_tensors=[y_classification,y_bbox],\n",
    "                  metrics={'classification': 'accuracy',\n",
    "                           'bbox': 'mse'})\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    # plot graph\n",
    "    plot_model(model, to_file='MTCNN P-Net sigmoid.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 12, 12, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 10)   280         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 10)     0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 3, 3, 16)     1456        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1, 1, 32)     4640        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classification (Conv2D)         (None, 1, 1, 2)      66          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bbox (Conv2D)                   (None, 1, 1, 4)      132         conv2d_8[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,574\n",
      "Trainable params: 6,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sigmoid_model = sigmoid_PNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=('logs\\\\p-net-benchmark\\\\Sigmoid'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8400 samples, validate on 1200 samples\n",
      "Epoch 1/60\n",
      "8400/8400 [==============================] - 4s 488us/sample - loss: 0.7316 - classification_loss: 0.6963 - bbox_loss: 0.0702 - classification_accuracy: 0.5017 - bbox_mse: 0.1422 - val_loss: 0.7183 - val_classification_loss: 0.6926 - val_bbox_loss: 0.0514 - val_classification_accuracy: 0.4975 - val_bbox_mse: 0.1021\n",
      "Epoch 2/60\n",
      "8400/8400 [==============================] - 1s 171us/sample - loss: 0.7178 - classification_loss: 0.6925 - bbox_loss: 0.0507 - classification_accuracy: 0.5077 - bbox_mse: 0.1013 - val_loss: 0.7139 - val_classification_loss: 0.6885 - val_bbox_loss: 0.0511 - val_classification_accuracy: 0.5008 - val_bbox_mse: 0.1010\n",
      "Epoch 3/60\n",
      "8400/8400 [==============================] - 1s 171us/sample - loss: 0.7030 - classification_loss: 0.6785 - bbox_loss: 0.0494 - classification_accuracy: 0.5865 - bbox_mse: 0.0981 - val_loss: 0.6796 - val_classification_loss: 0.6552 - val_bbox_loss: 0.0481 - val_classification_accuracy: 0.6692 - val_bbox_mse: 0.0960\n",
      "Epoch 4/60\n",
      "8400/8400 [==============================] - 1s 166us/sample - loss: 0.6217 - classification_loss: 0.5994 - bbox_loss: 0.0447 - classification_accuracy: 0.7114 - bbox_mse: 0.0896 - val_loss: 0.5775 - val_classification_loss: 0.5570 - val_bbox_loss: 0.0421 - val_classification_accuracy: 0.7500 - val_bbox_mse: 0.0838\n",
      "Epoch 5/60\n",
      "8400/8400 [==============================] - 2s 186us/sample - loss: 0.5450 - classification_loss: 0.5256 - bbox_loss: 0.0381 - classification_accuracy: 0.7682 - bbox_mse: 0.0766 - val_loss: 0.5496 - val_classification_loss: 0.5323 - val_bbox_loss: 0.0385 - val_classification_accuracy: 0.7567 - val_bbox_mse: 0.0763\n",
      "Epoch 6/60\n",
      "8400/8400 [==============================] - 2s 192us/sample - loss: 0.5216 - classification_loss: 0.5043 - bbox_loss: 0.0361 - classification_accuracy: 0.7814 - bbox_mse: 0.0721 - val_loss: 0.5375 - val_classification_loss: 0.5182 - val_bbox_loss: 0.0375 - val_classification_accuracy: 0.7733 - val_bbox_mse: 0.0749\n",
      "Epoch 7/60\n",
      "8400/8400 [==============================] - 2s 191us/sample - loss: 0.5081 - classification_loss: 0.4910 - bbox_loss: 0.0349 - classification_accuracy: 0.7876 - bbox_mse: 0.0698 - val_loss: 0.5495 - val_classification_loss: 0.5293 - val_bbox_loss: 0.0385 - val_classification_accuracy: 0.7583 - val_bbox_mse: 0.0773\n",
      "Epoch 8/60\n",
      "8400/8400 [==============================] - 1s 163us/sample - loss: 0.4999 - classification_loss: 0.4824 - bbox_loss: 0.0341 - classification_accuracy: 0.7900 - bbox_mse: 0.0685 - val_loss: 0.5076 - val_classification_loss: 0.4904 - val_bbox_loss: 0.0349 - val_classification_accuracy: 0.7950 - val_bbox_mse: 0.0699\n",
      "Epoch 9/60\n",
      "8400/8400 [==============================] - 2s 182us/sample - loss: 0.4885 - classification_loss: 0.4706 - bbox_loss: 0.0331 - classification_accuracy: 0.7981 - bbox_mse: 0.0665 - val_loss: 0.5010 - val_classification_loss: 0.4829 - val_bbox_loss: 0.0344 - val_classification_accuracy: 0.8008 - val_bbox_mse: 0.0685\n",
      "Epoch 10/60\n",
      "8400/8400 [==============================] - 1s 169us/sample - loss: 0.4812 - classification_loss: 0.4661 - bbox_loss: 0.0326 - classification_accuracy: 0.8015 - bbox_mse: 0.0652 - val_loss: 0.4915 - val_classification_loss: 0.4742 - val_bbox_loss: 0.0334 - val_classification_accuracy: 0.7867 - val_bbox_mse: 0.0667\n",
      "Epoch 11/60\n",
      "8400/8400 [==============================] - 1s 169us/sample - loss: 0.4745 - classification_loss: 0.4592 - bbox_loss: 0.0319 - classification_accuracy: 0.8062 - bbox_mse: 0.0640 - val_loss: 0.4808 - val_classification_loss: 0.4660 - val_bbox_loss: 0.0326 - val_classification_accuracy: 0.7950 - val_bbox_mse: 0.0647\n",
      "Epoch 12/60\n",
      "8400/8400 [==============================] - 2s 191us/sample - loss: 0.4665 - classification_loss: 0.4502 - bbox_loss: 0.0314 - classification_accuracy: 0.8098 - bbox_mse: 0.0628 - val_loss: 0.4716 - val_classification_loss: 0.4553 - val_bbox_loss: 0.0321 - val_classification_accuracy: 0.8033 - val_bbox_mse: 0.0640\n",
      "Epoch 13/60\n",
      "8400/8400 [==============================] - 1s 177us/sample - loss: 0.4577 - classification_loss: 0.4432 - bbox_loss: 0.0306 - classification_accuracy: 0.8132 - bbox_mse: 0.0612 - val_loss: 0.4671 - val_classification_loss: 0.4520 - val_bbox_loss: 0.0312 - val_classification_accuracy: 0.8067 - val_bbox_mse: 0.0622\n",
      "Epoch 14/60\n",
      "8400/8400 [==============================] - 2s 220us/sample - loss: 0.4479 - classification_loss: 0.4326 - bbox_loss: 0.0297 - classification_accuracy: 0.8160 - bbox_mse: 0.0595 - val_loss: 0.4513 - val_classification_loss: 0.4358 - val_bbox_loss: 0.0302 - val_classification_accuracy: 0.8067 - val_bbox_mse: 0.0601\n",
      "Epoch 15/60\n",
      "8400/8400 [==============================] - 2s 289us/sample - loss: 0.4384 - classification_loss: 0.4241 - bbox_loss: 0.0290 - classification_accuracy: 0.8188 - bbox_mse: 0.0578 - val_loss: 0.4518 - val_classification_loss: 0.4368 - val_bbox_loss: 0.0308 - val_classification_accuracy: 0.7967 - val_bbox_mse: 0.0605\n",
      "Epoch 16/60\n",
      "8400/8400 [==============================] - 1s 173us/sample - loss: 0.4307 - classification_loss: 0.4177 - bbox_loss: 0.0285 - classification_accuracy: 0.8205 - bbox_mse: 0.0568 - val_loss: 0.4257 - val_classification_loss: 0.4122 - val_bbox_loss: 0.0278 - val_classification_accuracy: 0.8175 - val_bbox_mse: 0.0553\n",
      "Epoch 17/60\n",
      "8400/8400 [==============================] - 2s 234us/sample - loss: 0.4183 - classification_loss: 0.4054 - bbox_loss: 0.0272 - classification_accuracy: 0.8249 - bbox_mse: 0.0542 - val_loss: 0.4477 - val_classification_loss: 0.4335 - val_bbox_loss: 0.0300 - val_classification_accuracy: 0.8058 - val_bbox_mse: 0.0601\n",
      "Epoch 18/60\n",
      "8400/8400 [==============================] - 2s 198us/sample - loss: 0.4013 - classification_loss: 0.3878 - bbox_loss: 0.0259 - classification_accuracy: 0.8345 - bbox_mse: 0.0517 - val_loss: 0.3931 - val_classification_loss: 0.3825 - val_bbox_loss: 0.0255 - val_classification_accuracy: 0.8392 - val_bbox_mse: 0.0510\n",
      "Epoch 19/60\n",
      "8400/8400 [==============================] - 1s 176us/sample - loss: 0.3882 - classification_loss: 0.3756 - bbox_loss: 0.0251 - classification_accuracy: 0.8412 - bbox_mse: 0.0502 - val_loss: 0.3893 - val_classification_loss: 0.3755 - val_bbox_loss: 0.0262 - val_classification_accuracy: 0.8325 - val_bbox_mse: 0.0520\n",
      "Epoch 20/60\n",
      "8400/8400 [==============================] - 1s 176us/sample - loss: 0.3808 - classification_loss: 0.3674 - bbox_loss: 0.0248 - classification_accuracy: 0.8467 - bbox_mse: 0.0496 - val_loss: 0.3755 - val_classification_loss: 0.3633 - val_bbox_loss: 0.0248 - val_classification_accuracy: 0.8500 - val_bbox_mse: 0.0493\n",
      "Epoch 21/60\n",
      "8400/8400 [==============================] - 2s 179us/sample - loss: 0.3797 - classification_loss: 0.3675 - bbox_loss: 0.0252 - classification_accuracy: 0.8442 - bbox_mse: 0.0499 - val_loss: 0.3699 - val_classification_loss: 0.3570 - val_bbox_loss: 0.0249 - val_classification_accuracy: 0.8458 - val_bbox_mse: 0.0493\n",
      "Epoch 22/60\n",
      "8400/8400 [==============================] - 2s 194us/sample - loss: 0.3740 - classification_loss: 0.3601 - bbox_loss: 0.0245 - classification_accuracy: 0.8494 - bbox_mse: 0.0492 - val_loss: 0.3640 - val_classification_loss: 0.3521 - val_bbox_loss: 0.0242 - val_classification_accuracy: 0.8508 - val_bbox_mse: 0.0486\n",
      "Epoch 23/60\n",
      "8400/8400 [==============================] - 2s 222us/sample - loss: 0.3675 - classification_loss: 0.3544 - bbox_loss: 0.0241 - classification_accuracy: 0.8519 - bbox_mse: 0.0482 - val_loss: 0.3581 - val_classification_loss: 0.3475 - val_bbox_loss: 0.0242 - val_classification_accuracy: 0.8575 - val_bbox_mse: 0.0477\n",
      "Epoch 24/60\n",
      "8400/8400 [==============================] - 2s 204us/sample - loss: 0.3630 - classification_loss: 0.3514 - bbox_loss: 0.0240 - classification_accuracy: 0.8554 - bbox_mse: 0.0477 - val_loss: 0.3548 - val_classification_loss: 0.3418 - val_bbox_loss: 0.0238 - val_classification_accuracy: 0.8608 - val_bbox_mse: 0.0473\n",
      "Epoch 25/60\n",
      "8400/8400 [==============================] - 2s 187us/sample - loss: 0.3645 - classification_loss: 0.3528 - bbox_loss: 0.0240 - classification_accuracy: 0.8500 - bbox_mse: 0.0481 - val_loss: 0.3556 - val_classification_loss: 0.3436 - val_bbox_loss: 0.0239 - val_classification_accuracy: 0.8533 - val_bbox_mse: 0.0475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/60\n",
      "8400/8400 [==============================] - 1s 155us/sample - loss: 0.3602 - classification_loss: 0.3481 - bbox_loss: 0.0240 - classification_accuracy: 0.8579 - bbox_mse: 0.0477 - val_loss: 0.3471 - val_classification_loss: 0.3358 - val_bbox_loss: 0.0233 - val_classification_accuracy: 0.8625 - val_bbox_mse: 0.0465\n",
      "Epoch 27/60\n",
      "8400/8400 [==============================] - 2s 206us/sample - loss: 0.3552 - classification_loss: 0.3425 - bbox_loss: 0.0235 - classification_accuracy: 0.8586 - bbox_mse: 0.0469 - val_loss: 0.3503 - val_classification_loss: 0.3389 - val_bbox_loss: 0.0239 - val_classification_accuracy: 0.8617 - val_bbox_mse: 0.0470\n",
      "Epoch 28/60\n",
      "8400/8400 [==============================] - 1s 178us/sample - loss: 0.3568 - classification_loss: 0.3446 - bbox_loss: 0.0236 - classification_accuracy: 0.8583 - bbox_mse: 0.0471 - val_loss: 0.3425 - val_classification_loss: 0.3305 - val_bbox_loss: 0.0234 - val_classification_accuracy: 0.8642 - val_bbox_mse: 0.0464\n",
      "Epoch 29/60\n",
      "8400/8400 [==============================] - 2s 209us/sample - loss: 0.3526 - classification_loss: 0.3402 - bbox_loss: 0.0232 - classification_accuracy: 0.8614 - bbox_mse: 0.0466 - val_loss: 0.3384 - val_classification_loss: 0.3273 - val_bbox_loss: 0.0230 - val_classification_accuracy: 0.8658 - val_bbox_mse: 0.0457\n",
      "Epoch 30/60\n",
      "8400/8400 [==============================] - 2s 193us/sample - loss: 0.3491 - classification_loss: 0.3373 - bbox_loss: 0.0231 - classification_accuracy: 0.8590 - bbox_mse: 0.0461 - val_loss: 0.3419 - val_classification_loss: 0.3296 - val_bbox_loss: 0.0237 - val_classification_accuracy: 0.8700 - val_bbox_mse: 0.0468\n",
      "Epoch 31/60\n",
      "8400/8400 [==============================] - 2s 180us/sample - loss: 0.3481 - classification_loss: 0.3371 - bbox_loss: 0.0231 - classification_accuracy: 0.8632 - bbox_mse: 0.0459 - val_loss: 0.3327 - val_classification_loss: 0.3209 - val_bbox_loss: 0.0228 - val_classification_accuracy: 0.8708 - val_bbox_mse: 0.0451\n",
      "Epoch 32/60\n",
      "8400/8400 [==============================] - 2s 204us/sample - loss: 0.3448 - classification_loss: 0.3326 - bbox_loss: 0.0228 - classification_accuracy: 0.8668 - bbox_mse: 0.0456 - val_loss: 0.3303 - val_classification_loss: 0.3187 - val_bbox_loss: 0.0227 - val_classification_accuracy: 0.8725 - val_bbox_mse: 0.0447\n",
      "Epoch 33/60\n",
      "8400/8400 [==============================] - 2s 228us/sample - loss: 0.3424 - classification_loss: 0.3303 - bbox_loss: 0.0228 - classification_accuracy: 0.8670 - bbox_mse: 0.0454 - val_loss: 0.3247 - val_classification_loss: 0.3117 - val_bbox_loss: 0.0221 - val_classification_accuracy: 0.8767 - val_bbox_mse: 0.0438\n",
      "Epoch 34/60\n",
      "8400/8400 [==============================] - 2s 196us/sample - loss: 0.3377 - classification_loss: 0.3265 - bbox_loss: 0.0224 - classification_accuracy: 0.8685 - bbox_mse: 0.0446 - val_loss: 0.3222 - val_classification_loss: 0.3092 - val_bbox_loss: 0.0218 - val_classification_accuracy: 0.8742 - val_bbox_mse: 0.0435\n",
      "Epoch 35/60\n",
      "8400/8400 [==============================] - 2s 214us/sample - loss: 0.3384 - classification_loss: 0.3260 - bbox_loss: 0.0225 - classification_accuracy: 0.8668 - bbox_mse: 0.0449 - val_loss: 0.3206 - val_classification_loss: 0.3099 - val_bbox_loss: 0.0218 - val_classification_accuracy: 0.8758 - val_bbox_mse: 0.0434\n",
      "Epoch 36/60\n",
      "8400/8400 [==============================] - 2s 186us/sample - loss: 0.3386 - classification_loss: 0.3283 - bbox_loss: 0.0225 - classification_accuracy: 0.8676 - bbox_mse: 0.0449 - val_loss: 0.3217 - val_classification_loss: 0.3096 - val_bbox_loss: 0.0219 - val_classification_accuracy: 0.8783 - val_bbox_mse: 0.0435\n",
      "Epoch 37/60\n",
      "8400/8400 [==============================] - 2s 200us/sample - loss: 0.3374 - classification_loss: 0.3250 - bbox_loss: 0.0224 - classification_accuracy: 0.8682 - bbox_mse: 0.0447 - val_loss: 0.3377 - val_classification_loss: 0.3255 - val_bbox_loss: 0.0227 - val_classification_accuracy: 0.8500 - val_bbox_mse: 0.0452\n",
      "Epoch 38/60\n",
      "8400/8400 [==============================] - 2s 187us/sample - loss: 0.3350 - classification_loss: 0.3243 - bbox_loss: 0.0223 - classification_accuracy: 0.8688 - bbox_mse: 0.0445 - val_loss: 0.3167 - val_classification_loss: 0.3058 - val_bbox_loss: 0.0216 - val_classification_accuracy: 0.8767 - val_bbox_mse: 0.0429\n",
      "Epoch 39/60\n",
      "8400/8400 [==============================] - 2s 227us/sample - loss: 0.3313 - classification_loss: 0.3197 - bbox_loss: 0.0221 - classification_accuracy: 0.8708 - bbox_mse: 0.0440 - val_loss: 0.3165 - val_classification_loss: 0.3068 - val_bbox_loss: 0.0217 - val_classification_accuracy: 0.8775 - val_bbox_mse: 0.0434\n",
      "Epoch 40/60\n",
      "8400/8400 [==============================] - 2s 207us/sample - loss: 0.3302 - classification_loss: 0.3194 - bbox_loss: 0.0219 - classification_accuracy: 0.8740 - bbox_mse: 0.0438 - val_loss: 0.3097 - val_classification_loss: 0.2994 - val_bbox_loss: 0.0212 - val_classification_accuracy: 0.8825 - val_bbox_mse: 0.0417\n",
      "Epoch 41/60\n",
      "8400/8400 [==============================] - 2s 207us/sample - loss: 0.3278 - classification_loss: 0.3184 - bbox_loss: 0.0220 - classification_accuracy: 0.8737 - bbox_mse: 0.0435 - val_loss: 0.3151 - val_classification_loss: 0.3045 - val_bbox_loss: 0.0210 - val_classification_accuracy: 0.8708 - val_bbox_mse: 0.0417\n",
      "Epoch 42/60\n",
      "8400/8400 [==============================] - 2s 245us/sample - loss: 0.3282 - classification_loss: 0.3180 - bbox_loss: 0.0218 - classification_accuracy: 0.8706 - bbox_mse: 0.0436 - val_loss: 0.3109 - val_classification_loss: 0.2998 - val_bbox_loss: 0.0212 - val_classification_accuracy: 0.8817 - val_bbox_mse: 0.0421\n",
      "Epoch 43/60\n",
      "8400/8400 [==============================] - 2s 247us/sample - loss: 0.3267 - classification_loss: 0.3163 - bbox_loss: 0.0218 - classification_accuracy: 0.8702 - bbox_mse: 0.0435 - val_loss: 0.3059 - val_classification_loss: 0.2959 - val_bbox_loss: 0.0211 - val_classification_accuracy: 0.8842 - val_bbox_mse: 0.0412\n",
      "Epoch 44/60\n",
      "8400/8400 [==============================] - 2s 254us/sample - loss: 0.3303 - classification_loss: 0.3191 - bbox_loss: 0.0219 - classification_accuracy: 0.8696 - bbox_mse: 0.0437 - val_loss: 0.3088 - val_classification_loss: 0.2975 - val_bbox_loss: 0.0212 - val_classification_accuracy: 0.8842 - val_bbox_mse: 0.0423\n",
      "Epoch 45/60\n",
      "8400/8400 [==============================] - 2s 237us/sample - loss: 0.3235 - classification_loss: 0.3136 - bbox_loss: 0.0214 - classification_accuracy: 0.8758 - bbox_mse: 0.0429 - val_loss: 0.3074 - val_classification_loss: 0.2978 - val_bbox_loss: 0.0206 - val_classification_accuracy: 0.8767 - val_bbox_mse: 0.0410\n",
      "Epoch 46/60\n",
      "8400/8400 [==============================] - 2s 257us/sample - loss: 0.3178 - classification_loss: 0.3072 - bbox_loss: 0.0212 - classification_accuracy: 0.8768 - bbox_mse: 0.0421 - val_loss: 0.3017 - val_classification_loss: 0.2899 - val_bbox_loss: 0.0204 - val_classification_accuracy: 0.8842 - val_bbox_mse: 0.0408s: 0.3056 - bbox_loss: 0.0211 - classification_accuracy: 0.8774 - bbox_mse:  - ETA: 0s - loss: 0.3146 - classification_loss: 0.3041 - bbox_loss: 0.0210 - classification_accuracy: 0.8781 - bbox\n",
      "Epoch 47/60\n",
      "8400/8400 [==============================] - 2s 258us/sample - loss: 0.3205 - classification_loss: 0.3104 - bbox_loss: 0.0214 - classification_accuracy: 0.8730 - bbox_mse: 0.0426 - val_loss: 0.2973 - val_classification_loss: 0.2875 - val_bbox_loss: 0.0204 - val_classification_accuracy: 0.8883 - val_bbox_mse: 0.0403\n",
      "Epoch 48/60\n",
      "8400/8400 [==============================] - 2s 196us/sample - loss: 0.3192 - classification_loss: 0.3079 - bbox_loss: 0.0212 - classification_accuracy: 0.8730 - bbox_mse: 0.0424 - val_loss: 0.3100 - val_classification_loss: 0.2987 - val_bbox_loss: 0.0212 - val_classification_accuracy: 0.8792 - val_bbox_mse: 0.0422\n",
      "Epoch 49/60\n",
      "8400/8400 [==============================] - 2s 217us/sample - loss: 0.3164 - classification_loss: 0.3066 - bbox_loss: 0.0212 - classification_accuracy: 0.8757 - bbox_mse: 0.0420 - val_loss: 0.2953 - val_classification_loss: 0.2860 - val_bbox_loss: 0.0200 - val_classification_accuracy: 0.8883 - val_bbox_mse: 0.0398\n",
      "Epoch 50/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400/8400 [==============================] - 3s 299us/sample - loss: 0.3137 - classification_loss: 0.3049 - bbox_loss: 0.0210 - classification_accuracy: 0.8768 - bbox_mse: 0.0418 - val_loss: 0.2997 - val_classification_loss: 0.2889 - val_bbox_loss: 0.0202 - val_classification_accuracy: 0.8783 - val_bbox_mse: 0.0405\n",
      "Epoch 51/60\n",
      "8400/8400 [==============================] - 2s 294us/sample - loss: 0.3095 - classification_loss: 0.2999 - bbox_loss: 0.0206 - classification_accuracy: 0.8798 - bbox_mse: 0.0413 - val_loss: 0.3028 - val_classification_loss: 0.2927 - val_bbox_loss: 0.0209 - val_classification_accuracy: 0.8817 - val_bbox_mse: 0.0412\n",
      "Epoch 52/60\n",
      "8400/8400 [==============================] - 2s 285us/sample - loss: 0.3133 - classification_loss: 0.3022 - bbox_loss: 0.0209 - classification_accuracy: 0.8769 - bbox_mse: 0.0419 - val_loss: 0.2893 - val_classification_loss: 0.2786 - val_bbox_loss: 0.0196 - val_classification_accuracy: 0.8883 - val_bbox_mse: 0.0394\n",
      "Epoch 53/60\n",
      "8400/8400 [==============================] - 3s 302us/sample - loss: 0.3085 - classification_loss: 0.2983 - bbox_loss: 0.0208 - classification_accuracy: 0.8780 - bbox_mse: 0.0414 - val_loss: 0.2889 - val_classification_loss: 0.2780 - val_bbox_loss: 0.0196 - val_classification_accuracy: 0.8842 - val_bbox_mse: 0.0392\n",
      "Epoch 54/60\n",
      "8400/8400 [==============================] - 2s 225us/sample - loss: 0.3038 - classification_loss: 0.2939 - bbox_loss: 0.0204 - classification_accuracy: 0.8793 - bbox_mse: 0.0407 - val_loss: 0.2859 - val_classification_loss: 0.2751 - val_bbox_loss: 0.0197 - val_classification_accuracy: 0.8867 - val_bbox_mse: 0.0392\n",
      "Epoch 55/60\n",
      "8400/8400 [==============================] - 2s 213us/sample - loss: 0.3044 - classification_loss: 0.2935 - bbox_loss: 0.0205 - classification_accuracy: 0.8798 - bbox_mse: 0.0410 - val_loss: 0.2897 - val_classification_loss: 0.2805 - val_bbox_loss: 0.0204 - val_classification_accuracy: 0.8867 - val_bbox_mse: 0.0401- bbox_loss: 0.0205 - classification_accuracy: 0.8803 - bbox_mse: \n",
      "Epoch 56/60\n",
      "8400/8400 [==============================] - 2s 244us/sample - loss: 0.3020 - classification_loss: 0.2911 - bbox_loss: 0.0203 - classification_accuracy: 0.8824 - bbox_mse: 0.0408 - val_loss: 0.2821 - val_classification_loss: 0.2725 - val_bbox_loss: 0.0195 - val_classification_accuracy: 0.8917 - val_bbox_mse: 0.03896 - classification_loss: 0.2875 - bbox_loss: 0.0202 - classification_accur\n",
      "Epoch 57/60\n",
      "8400/8400 [==============================] - 3s 356us/sample - loss: 0.2993 - classification_loss: 0.2891 - bbox_loss: 0.0203 - classification_accuracy: 0.8842 - bbox_mse: 0.0403 - val_loss: 0.2839 - val_classification_loss: 0.2762 - val_bbox_loss: 0.0201 - val_classification_accuracy: 0.8892 - val_bbox_mse: 0.0393\n",
      "Epoch 58/60\n",
      "8400/8400 [==============================] - 2s 224us/sample - loss: 0.2994 - classification_loss: 0.2888 - bbox_loss: 0.0201 - classification_accuracy: 0.8808 - bbox_mse: 0.0404 - val_loss: 0.2932 - val_classification_loss: 0.2822 - val_bbox_loss: 0.0208 - val_classification_accuracy: 0.8892 - val_bbox_mse: 0.0409assification_loss: 0.2800 - bbox_loss: 0.0191 - classifica\n",
      "Epoch 59/60\n",
      "8400/8400 [==============================] - 1s 176us/sample - loss: 0.3008 - classification_loss: 0.2903 - bbox_loss: 0.0203 - classification_accuracy: 0.8807 - bbox_mse: 0.0406 - val_loss: 0.2779 - val_classification_loss: 0.2680 - val_bbox_loss: 0.0191 - val_classification_accuracy: 0.8858 - val_bbox_mse: 0.0383\n",
      "Epoch 60/60\n",
      "8400/8400 [==============================] - 1s 163us/sample - loss: 0.2985 - classification_loss: 0.2895 - bbox_loss: 0.0202 - classification_accuracy: 0.8818 - bbox_mse: 0.0405 - val_loss: 0.2846 - val_classification_loss: 0.2757 - val_bbox_loss: 0.0198 - val_classification_accuracy: 0.8867 - val_bbox_mse: 0.0393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a51f33f448>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_model.fit(X_train, [y_train[:,:,:,:2],y_train[:,:,:,2:]], batch_size=64, epochs=60,\n",
    "            validation_data=(X_val, [y_val[:,:,:,:2],y_val[:,:,:,2:]]),\n",
    "            callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the PNet  to ensure that the implementation does not crash and produces outputs of the expected shape.\n",
    "Pnet will output are:\n",
    "1. Face classification,  size (batch,1,1,2) for 2 calss classification, \"Face\", and \"Not face\"\n",
    "2. Bounding box  (batch,1,1,4) for 4 boundind box corrdinates (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('P-Net-relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[['loss', 'val_loss']].plot(figsize=(8,5))\n",
    "plt.title('P-Net model loss vs. epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[['classification_accuracy', 'val_classification_accuracy']].plot(figsize=(8,5))\n",
    "plt.title('P-Net model accuracy vs. epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = predictions[0]\n",
    "bbox = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.squeeze(score)\n",
    "bbox = np.squeeze(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_score = np.squeeze(y_test[:,:,:,:2])\n",
    "y_test_bbox = np.squeeze(y_test[:,:,:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_score, np.round(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_score, np.round(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test_score[:,1:2], np.round(score[:,1:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score[0:10,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_testset(index):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(2, 2))\n",
    "    ax.imshow(X_test[index])\n",
    "    plt.title(score[index,1:])\n",
    "    # Create a Rectangle patch\n",
    "    x = round(12*bbox[index,0])\n",
    "    y = round(12*bbox[index,1])\n",
    "    w = round(12*bbox[index,2]) - x\n",
    "    h = round(12*bbox[index,3]) - y\n",
    "    rect = patches.Rectangle((x,y),w,h,linewidth=1,edgecolor='r',facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_testset(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('P-Net-Relu-test_data_input.npy', 'wb') as f:\n",
    "    np.save(f, np.transpose(X_test[0], (2,0,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction for future use (NN lite)\n",
    "with open('P-Net-Relu-test-data_predictions-classifications.npy', 'wb') as f:\n",
    "    np.save(f, score[0,:])\n",
    "\n",
    "with open('P-Net-Relu-test-data_predictions-bbox.npy', 'wb') as f:\n",
    "    np.save(f, bbox[0,:])\n",
    "\n",
    "    \n",
    "# Save labels for future use (NN lite)\n",
    "with open('P-Net-Relu-test-data_y_Labels_classifications.npy', 'wb') as f:\n",
    "    np.save(f, y_test_score[0,:])\n",
    "\n",
    "    \n",
    "    # Save labels for future use (NN lite)\n",
    "with open('P-Net-Relu-test-data_y_Labels_bbox.npy', 'wb') as f:\n",
    "    np.save(f, y_test_bbox[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = np.load('P-Net-Relu-test_data_input.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
