{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pkg_resources\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "import os\n",
    "\n",
    "FACES_PATH = '../data/face_detection/faces/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "import datetime\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(PNet, self).__init__(name=\"PNet\")\n",
    "        # Define layers here.\n",
    "        self.conv1 = tf.keras.layers.Conv2D(10, (3, 3), name=\"conv1\")\n",
    "        self.prelu1 = tf.keras.layers.PReLU(tf.constant_initializer(0.25), shared_axes=[1, 2], name=\"prelu1\")\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool1\")\n",
    "        self.conv2 = tf.keras.layers.Conv2D(16, (3, 3), name=\"conv2\")\n",
    "        self.prelu2 = tf.keras.layers.PReLU(tf.constant_initializer(0.25), shared_axes=[1, 2], name=\"prelu2\")\n",
    "        self.conv3 = tf.keras.layers.Conv2D(32, (3, 3), name=\"conv3\")\n",
    "        self.prelu3 = tf.keras.layers.PReLU(tf.constant_initializer(0.25), shared_axes=[1, 2], name=\"prelu3\")\n",
    "        self.cls_output = tf.keras.layers.Conv2D(2, (1, 1), activation=\"softmax\", name=\"conv4-1\")\n",
    "        self.bbox_pred = tf.keras.layers.Conv2D(4, (1, 1), name=\"conv4-2\")\n",
    "        #self.landmark_pred = keras.layers.Conv2D(10, (1, 1), name=\"conv4_3\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define your forward pass here,\n",
    "        # using layers you previously defined (in `__init__`).\n",
    "        scores = None\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.prelu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.prelu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.prelu3(x)\n",
    "        scores = [self.cls_output(x), self.bbox_pred(x)]#, self.landmark_pred(x)]\n",
    "        \n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset iterable engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  /cpu:0\n"
     ]
    }
   ],
   "source": [
    "# Set up some global variables\n",
    "USE_GPU = False\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the PNet  to ensure that the implementation does not crash and produces outputs of the expected shape.\n",
    "Pnet will output are:\n",
    "1. Face classification,  size (batch,1,1,2) for 2 calss classification, \"Face\", and \"Not face\"\n",
    "2. Bounding box  (batch,1,1,4) for 4 boundind box corrdinates (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               multiple                  280       \n",
      "_________________________________________________________________\n",
      "prelu1 (PReLU)               multiple                  10        \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               multiple                  1456      \n",
      "_________________________________________________________________\n",
      "prelu2 (PReLU)               multiple                  16        \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               multiple                  4640      \n",
      "_________________________________________________________________\n",
      "prelu3 (PReLU)               multiple                  32        \n",
      "_________________________________________________________________\n",
      "conv4-1 (Conv2D)             multiple                  66        \n",
      "_________________________________________________________________\n",
      "conv4-2 (Conv2D)             multiple                  132       \n",
      "=================================================================\n",
      "Total params: 6,632\n",
      "Trainable params: 6,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "P-Net output size testing: \n",
      "classificatin score output (32, 1, 1, 2) \n",
      "bounsing box score output (32, 1, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "def test_PNet(batch=64):    \n",
    "    model = PNet()\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((batch, 12, 12, 3))\n",
    "        classification_scores, bbox_score = model(x)\n",
    "        print(model.summary())\n",
    "        print('\\nP-Net output size testing: \\nclassificatin score output', classification_scores.shape,\n",
    "              '\\nbounsing box score output', bbox_score.shape)\n",
    "\n",
    "batch_test = 32\n",
    "test_PNet(batch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 6000\n",
    "\n",
    "def read_pos_images():\n",
    "    #Read positive images:\n",
    "    path, __, filenames = next(os.walk(FACES_PATH+'pos_train/'))\n",
    "    file_count = training_size #len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[0.0,1.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    file = open(FACES_PATH+'coordinates.txt','r')\n",
    "    lines = file.readlines()\n",
    "    lines = [line[:-1] for line in lines]\n",
    "    #idx=[1,0,3,2]\n",
    "    idx=[0,1,2,3]\n",
    "    f_count = 0\n",
    "    for line in lines:\n",
    "        line = line.split(\" \")\n",
    "        line = line[1]\n",
    "        line=line[1:-1]\n",
    "        line = line.split(\",\")\n",
    "        #Transpose coordinates\n",
    "        x=0\n",
    "        nline=[]\n",
    "        for i in idx:\n",
    "            nline.append(line[i])\n",
    "            x=x+1\n",
    "        line=[[[float(c) for c in nline]]]\n",
    "        coordinates.append(line)\n",
    "        f_count = f_count+1\n",
    "        if f_count == file_count:\n",
    "            break\n",
    "    #Return images, probs, and coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "def read_neg_images():\n",
    "    #Read negative images:\n",
    "    path, __, filenames = next(os.walk(FACES_PATH+'neg_train/'))\n",
    "    file_count = training_size #len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[1.0,0.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    for i in range(file_count):\n",
    "        coordinates.append([[[0.0,0.0,0.0,0.0]]])\n",
    "    #Return images, prob, coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "#Read in all images, probabilities, and coordinates\n",
    "pimages, pprob, pcoordinates = read_pos_images()\n",
    "nimages, nprob, ncoordinates = read_neg_images()\n",
    "o_images=np.append(pimages,nimages,axis=0)\n",
    "o_images=np.reshape(o_images,(-1,12,12,3))\n",
    "o_prob=pprob+nprob\n",
    "o_coordinates=pcoordinates+ncoordinates\n",
    "\n",
    "#Shuffle them up using an index\n",
    "idx=np.arange(len(o_prob))\n",
    "np.random.shuffle(idx)\n",
    "images=np.empty_like(o_images)\n",
    "c=0\n",
    "for i in idx:\n",
    "    images[c]=o_images[i]\n",
    "    c=c+1\n",
    "#images=(np.float32)(images-127.5)/128.0\n",
    "images=(np.float32)(images)/255\n",
    "\n",
    "#images = np.transpose(images, (0, 2, 1, 3)) #Transpose images\n",
    "prob=[]\n",
    "for i in idx:\n",
    "    prob.append(o_prob[i])\n",
    "coordinates=[]\n",
    "for i in idx:\n",
    "    coordinates.append(o_coordinates[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data , Image data shape  (12000, 12, 12, 3)\n",
      "y_classification_data , Classification ground true data shape  (12000, 1, 1, 2)\n",
      "y_bbox_data , Coordinates ground true data shape  (12000, 1, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('X_data , Image data shape ', images.shape)\n",
    "print('y_classification_data , Classification ground true data shape ' ,np.array(prob).shape)\n",
    "print('y_bbox_data , Coordinates ground true data shape ', np.array(coordinates).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X_data for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pcoordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape (12000, 12, 12, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X_data shape',X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create \"y_data\" for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.concatenate((np.array(prob), np.array(coordinates)), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data shape (12000, 1, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "print('y_data shape',y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data Classification shape (12000, 1, 1, 2)\n",
      "y_data Coordinate shape (12000, 1, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('y_data Classification shape', y_data[:,:,:,:2].shape)\n",
    "print('y_data Coordinate shape',y_data[:,:,:,2:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide dataset to \"train', \"val\" and \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X, y, training_prec = 0.7, val_prec = 0.1, test_prec = 0.2):\n",
    "        data_length = len(X)\n",
    "        num_training = np.int(data_length * training_prec)\n",
    "        num_validation = np.int(data_length * val_prec)\n",
    "        \n",
    "        mask = range(num_training)\n",
    "        X_train = X[mask]\n",
    "        y_train = y[mask]\n",
    "        mask = range(num_training, num_training + num_validation)\n",
    "        X_val = X[mask]\n",
    "        y_val = y[mask]\n",
    "        mask = range(num_training + num_validation, data_length)\n",
    "        X_test = X[mask]\n",
    "        y_test = y[mask]\n",
    "        \n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (8400, 12, 12, 3)\n",
      "Train labels shape:  (8400, 1, 1, 6) float64\n",
      "Validation data shape:  (1200, 12, 12, 3)\n",
      "Validation labels shape:  (1200, 1, 1, 6)\n",
      "Test data shape:  (2400, 12, 12, 3)\n",
      "Test labels shape:  (2400, 1, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data(X_data, y_data)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets test a single batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_init_fn():\n",
    "    learning_rate = 1e-3\n",
    "    return tf.keras.optimizers.Adam(learning_rate) \n",
    "    #return tf.keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PNet()\n",
    "optimizer = optimizer_init_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "bbox_loss = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.BinaryCrossentropy(name='train_classification_loss')\n",
    "train_bbox_loss = tf.keras.metrics.MeanSquaredError(name='train_bbox_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification loss tf.Tensor(0.6877527, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23161797, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8035617, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X_train_batch = X_train[:32,:,:,:]\n",
    "y_train_batch = y_train[:32,:,:,:]\n",
    "\n",
    "# Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "train_loss.reset_states()\n",
    "train_accuracy.reset_states()\n",
    "\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    classification_scores, bbox_scores = model(X_train_batch , training=True)\n",
    "    prediction_loss = classification_loss(y_train_batch[:,:,:,:2], classification_scores)\n",
    "    coordinate_loss = bbox_loss(y_train_batch[:,:,:,2:], bbox_scores)\n",
    "    loss = prediction_loss + 0.5 * coordinate_loss\n",
    "    # Print loss \n",
    "    print('Classification loss',prediction_loss)\n",
    "    print(coordinate_loss)\n",
    "    print(loss)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Update the metrics\n",
    "    train_loss.update_state(y_train_batch[:,:,:,:2], classification_scores)\n",
    "    train_bbox_loss.update_state(y_train_batch[:,:,:,2:], bbox_scores)\n",
    "    train_accuracy.update_state(y_train_batch[:,:,:,:2], classification_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6877527236938477, Accuracy: 59.375\n"
     ]
    }
   ],
   "source": [
    "template = 'Loss: {}, Accuracy: {}'\n",
    "print (template.format(train_loss.result(),\n",
    "                       train_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on  training set and periodically checks\n",
    "    accuracy on the validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"    \n",
    "    with tf.device(device):\n",
    "        \n",
    "        #Set up summary writers to write the summaries to disk in a different logs directory:\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "        test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "        train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "        test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "        \n",
    "        #compute the loss function over the classification and ovr bounding box \n",
    "        classification_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "        bbox_loss = tf.keras.losses.MeanSquaredError()        \n",
    "        \n",
    "        model = model_init_fn()\n",
    "        optimizer = optimizer_init_fn()\n",
    "        \n",
    "        train_loss = tf.keras.metrics.BinaryCrossentropy(name='train_classification_loss')\n",
    "        train_bbox_loss = tf.keras.metrics.MeanSquaredError(name='train_bbox_loss')\n",
    "        \n",
    "        train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "            \n",
    "        #val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        val_loss = tf.keras.metrics.BinaryCrossentropy(name='val_classification_loss')\n",
    "        val_bbox_loss = tf.keras.metrics.MeanSquaredError(name='val_bbox_loss')\n",
    "\n",
    "        val_accuracy = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')\n",
    "        \n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "            train_loss.reset_states()\n",
    "            train_bbox_loss.reset_states()\n",
    "            \n",
    "            train_accuracy.reset_states()\n",
    "            \n",
    "            for x_np, y_np in train_dset:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    \n",
    "                    # Use the model function to build the forward pass.\n",
    "                    classification_scores, bbox_scores = model(x_np, training=True)\n",
    "                    prediction_loss = classification_loss(y_np[:,:,:,:2], classification_scores)\n",
    "                    coordinate_loss = bbox_loss(y_np[:,:,:,2:], bbox_scores)\n",
    "                    loss = prediction_loss + 0.5 * coordinate_loss * y_np[:,:,:,1]\n",
    "                    # Print loss \n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "                    # Update the metrics\n",
    "                    train_loss.update_state(y_np[:,:,:,:2], classification_scores)\n",
    "                    train_bbox_loss.update_state(y_np[:,:,:,2:], bbox_scores*y_np[:,:,:,1] )\n",
    "                    train_accuracy.update_state(y_np[:,:,:,:2], classification_scores)\n",
    "                    \n",
    "                    with train_summary_writer.as_default():\n",
    "                        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "                        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "\n",
    "                    if t % print_every == 0:\n",
    "                        val_loss.reset_states()\n",
    "                        val_bbox_loss.reset_states()\n",
    "                        val_accuracy.reset_states()\n",
    "                        for test_x, test_y in val_dset:\n",
    "                            # During validation at end of epoch, training set to False\n",
    "                            classification_scores, bbox_scores = model(test_x, training=False)\n",
    "                            t_prediction_loss = classification_loss(test_y[:,:,:,:2], classification_scores)\n",
    "                            t_coordinate_loss = bbox_loss(test_y[:,:,:,2:], bbox_scores)\n",
    "                            t_loss = t_prediction_loss + 0.5 * t_coordinate_loss * test_y[:,:,:,1]\n",
    "\n",
    "                            val_loss.update_state(test_y[:,:,:,:2], classification_scores)\n",
    "                            val_bbox_loss.update_state(test_y[:,:,:,2:], bbox_scores*test_y[:,:,:,1])\n",
    "                            val_accuracy.update_state(test_y[:,:,:,:2], classification_scores)\n",
    "                            \n",
    "                            with test_summary_writer.as_default():\n",
    "                                tf.summary.scalar('loss', val_loss.result(), step=epoch)\n",
    "                                tf.summary.scalar('accuracy', val_accuracy.result(), step=epoch)\n",
    "\n",
    "                        \n",
    "                        template = 'Iteration {}, Epoch {}, \\nLoss: {}, Bbox loss: {}, Accuracy: {},\\nVal Loss: {}, Val Bbox Loss: {}, Val Accuracy: {}'\n",
    "                        print (template.format(t, epoch+1,\n",
    "                                             train_loss.result(),\n",
    "                                             train_bbox_loss.result(),\n",
    "                                             train_accuracy.result()*100,\n",
    "                                             val_loss.result(),\n",
    "                                             val_bbox_loss.result(),  \n",
    "                                             val_accuracy.result()*100))\n",
    "                    t += 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = '/device:GPU:0'   # Change this to a CPU/GPU as you wish!\n",
    "#device = '/cpu:0'        # Change this to a CPU/GPU as you wish!\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 50\n",
    "num_epochs = 50\n",
    "\n",
    "#model = PNet()\n",
    "\n",
    "def model_init_fn():\n",
    "    return PNet()\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    learning_rate = 1e-3\n",
    "    return tf.keras.optimizers.Adam(learning_rate) \n",
    "    #return tf.keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 30180), started 0:01:07 ago. (Use '!kill 30180' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ba3f181b2da87d97\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ba3f181b2da87d97\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logs_base_dir = \"./logs/gradient_tape\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, \n",
      "Loss: 0.6861038208007812, Bbox loss: 0.15497726202011108, Accuracy: 59.375,\n",
      "Val Loss: 0.6925285458564758, Val Bbox Loss: 0.19234471023082733, Val Accuracy: 49.83333206176758\n",
      "Iteration 50, Epoch 1, \n",
      "Loss: 0.6520605087280273, Bbox loss: 0.16084203124046326, Accuracy: 61.09068298339844,\n",
      "Val Loss: 0.574312150478363, Val Bbox Loss: 0.15377368032932281, Val Accuracy: 69.75\n",
      "Iteration 100, Epoch 1, \n",
      "Loss: 0.5884343385696411, Bbox loss: 0.1492147296667099, Accuracy: 67.82178497314453,\n",
      "Val Loss: 0.4888328015804291, Val Bbox Loss: 0.13528156280517578, Val Accuracy: 78.58333587646484\n",
      "Iteration 150, Epoch 2, \n",
      "Loss: 0.4377756714820862, Bbox loss: 0.12810289859771729, Accuracy: 80.75658416748047,\n",
      "Val Loss: 0.42043137550354004, Val Bbox Loss: 0.12940195202827454, Val Accuracy: 82.83332824707031\n",
      "Iteration 200, Epoch 2, \n",
      "Loss: 0.43884772062301636, Bbox loss: 0.12894324958324432, Accuracy: 81.06884002685547,\n",
      "Val Loss: 0.42011669278144836, Val Bbox Loss: 0.12856724858283997, Val Accuracy: 82.41666412353516\n",
      "Iteration 250, Epoch 2, \n",
      "Loss: 0.4416970908641815, Bbox loss: 0.12862899899482727, Accuracy: 80.86922454833984,\n",
      "Val Loss: 0.3905080556869507, Val Bbox Loss: 0.12640255689620972, Val Accuracy: 84.66667175292969\n",
      "Iteration 300, Epoch 3, \n",
      "Loss: 0.37332683801651, Bbox loss: 0.12317925691604614, Accuracy: 84.03716278076172,\n",
      "Val Loss: 0.3684748709201813, Val Bbox Loss: 0.1253199428319931, Val Accuracy: 84.75\n",
      "Iteration 350, Epoch 3, \n",
      "Loss: 0.3828295171260834, Bbox loss: 0.12482419610023499, Accuracy: 83.36925506591797,\n",
      "Val Loss: 0.3510008156299591, Val Bbox Loss: 0.12454528361558914, Val Accuracy: 84.75\n",
      "Iteration 400, Epoch 4, \n",
      "Loss: 0.33078533411026, Bbox loss: 0.11885426193475723, Accuracy: 85.3125,\n",
      "Val Loss: 0.33427175879478455, Val Bbox Loss: 0.12327519059181213, Val Accuracy: 86.25\n",
      "Iteration 450, Epoch 4, \n",
      "Loss: 0.34036269783973694, Bbox loss: 0.12240655720233917, Accuracy: 85.51136016845703,\n",
      "Val Loss: 0.3208741545677185, Val Bbox Loss: 0.12237878888845444, Val Accuracy: 86.91666412353516\n",
      "Iteration 500, Epoch 4, \n",
      "Loss: 0.3404568135738373, Bbox loss: 0.12233569473028183, Accuracy: 85.81845092773438,\n",
      "Val Loss: 0.30416426062583923, Val Bbox Loss: 0.1221470832824707, Val Accuracy: 87.58333587646484\n",
      "Iteration 550, Epoch 5, \n",
      "Loss: 0.2823217809200287, Bbox loss: 0.11721865087747574, Accuracy: 88.45108795166016,\n",
      "Val Loss: 0.30100134015083313, Val Bbox Loss: 0.12217570841312408, Val Accuracy: 87.58333587646484\n",
      "Iteration 600, Epoch 5, \n",
      "Loss: 0.3076252341270447, Bbox loss: 0.11999229341745377, Accuracy: 87.15753173828125,\n",
      "Val Loss: 0.2915295660495758, Val Bbox Loss: 0.1206069216132164, Val Accuracy: 87.16666412353516\n",
      "Iteration 650, Epoch 5, \n",
      "Loss: 0.3136611878871918, Bbox loss: 0.12016245722770691, Accuracy: 87.18241882324219,\n",
      "Val Loss: 0.2715611755847931, Val Bbox Loss: 0.11954058706760406, Val Accuracy: 89.16666412353516\n",
      "Iteration 700, Epoch 6, \n",
      "Loss: 0.27171194553375244, Bbox loss: 0.11806546151638031, Accuracy: 88.75762176513672,\n",
      "Val Loss: 0.26714783906936646, Val Bbox Loss: 0.11911626160144806, Val Accuracy: 89.33332824707031\n",
      "Iteration 750, Epoch 6, \n",
      "Loss: 0.2847779095172882, Bbox loss: 0.11863025277853012, Accuracy: 88.49588012695312,\n",
      "Val Loss: 0.26085445284843445, Val Bbox Loss: 0.11881665885448456, Val Accuracy: 89.41666412353516\n",
      "Iteration 800, Epoch 7, \n",
      "Loss: 0.25032442808151245, Bbox loss: 0.11338171362876892, Accuracy: 88.71527862548828,\n",
      "Val Loss: 0.29004284739494324, Val Bbox Loss: 0.12041522562503815, Val Accuracy: 89.08332824707031\n",
      "Iteration 850, Epoch 7, \n",
      "Loss: 0.2575649917125702, Bbox loss: 0.11708399653434753, Accuracy: 89.40678405761719,\n",
      "Val Loss: 0.3085235059261322, Val Bbox Loss: 0.12185683101415634, Val Accuracy: 87.91666412353516\n",
      "Iteration 900, Epoch 7, \n",
      "Loss: 0.2688713073730469, Bbox loss: 0.11731527745723724, Accuracy: 89.03382873535156,\n",
      "Val Loss: 0.24666933715343475, Val Bbox Loss: 0.1178511381149292, Val Accuracy: 89.16666412353516\n",
      "Iteration 950, Epoch 8, \n",
      "Loss: 0.2343938648700714, Bbox loss: 0.11539093405008316, Accuracy: 90.4513931274414,\n",
      "Val Loss: 0.23866988718509674, Val Bbox Loss: 0.11728233844041824, Val Accuracy: 89.66666412353516\n",
      "Iteration 1000, Epoch 8, \n",
      "Loss: 0.24701723456382751, Bbox loss: 0.11634551733732224, Accuracy: 89.81330871582031,\n",
      "Val Loss: 0.2357882708311081, Val Bbox Loss: 0.11749851703643799, Val Accuracy: 90.25\n",
      "Iteration 1050, Epoch 8, \n",
      "Loss: 0.2533765137195587, Bbox loss: 0.11654502898454666, Accuracy: 89.6407470703125,\n",
      "Val Loss: 0.22040359675884247, Val Bbox Loss: 0.11701004952192307, Val Accuracy: 90.75\n",
      "Iteration 1100, Epoch 9, \n",
      "Loss: 0.21902881562709808, Bbox loss: 0.11554130911827087, Accuracy: 90.86805725097656,\n",
      "Val Loss: 0.22076375782489777, Val Bbox Loss: 0.11689575761556625, Val Accuracy: 90.5\n",
      "Iteration 1150, Epoch 9, \n",
      "Loss: 0.2304568886756897, Bbox loss: 0.11552032828330994, Accuracy: 90.5098648071289,\n",
      "Val Loss: 0.2207106500864029, Val Bbox Loss: 0.11690878123044968, Val Accuracy: 90.5\n",
      "Iteration 1200, Epoch 10, \n",
      "Loss: 0.20870916545391083, Bbox loss: 0.11357060819864273, Accuracy: 91.46634674072266,\n",
      "Val Loss: 0.21561765670776367, Val Bbox Loss: 0.11725053936243057, Val Accuracy: 91.08333587646484\n",
      "Iteration 1250, Epoch 10, \n",
      "Loss: 0.21238400042057037, Bbox loss: 0.11464720964431763, Accuracy: 91.54266357421875,\n",
      "Val Loss: 0.20162604749202728, Val Bbox Loss: 0.11563312262296677, Val Accuracy: 92.08333587646484\n",
      "Iteration 1300, Epoch 10, \n",
      "Loss: 0.22094914317131042, Bbox loss: 0.11475615203380585, Accuracy: 90.99833679199219,\n",
      "Val Loss: 0.22069261968135834, Val Bbox Loss: 0.12050282210111618, Val Accuracy: 90.66667175292969\n",
      "Iteration 1350, Epoch 11, \n",
      "Loss: 0.19632035493850708, Bbox loss: 0.11328379809856415, Accuracy: 92.13710021972656,\n",
      "Val Loss: 0.21602080762386322, Val Bbox Loss: 0.11718960851430893, Val Accuracy: 91.33333587646484\n",
      "Iteration 1400, Epoch 11, \n",
      "Loss: 0.20002181828022003, Bbox loss: 0.11384840309619904, Accuracy: 91.91743469238281,\n",
      "Val Loss: 0.1915683150291443, Val Bbox Loss: 0.11515909433364868, Val Accuracy: 92.25\n",
      "Iteration 1450, Epoch 11, \n",
      "Loss: 0.20539958775043488, Bbox loss: 0.11396554112434387, Accuracy: 91.6030502319336,\n",
      "Val Loss: 0.18530985713005066, Val Bbox Loss: 0.1153225526213646, Val Accuracy: 92.5\n",
      "Iteration 1500, Epoch 12, \n",
      "Loss: 0.1812281757593155, Bbox loss: 0.11346571147441864, Accuracy: 92.53826904296875,\n",
      "Val Loss: 0.19098632037639618, Val Bbox Loss: 0.11506049335002899, Val Accuracy: 92.08333587646484\n",
      "Iteration 1550, Epoch 12, \n",
      "Loss: 0.19129645824432373, Bbox loss: 0.11337652057409286, Accuracy: 92.32954406738281,\n",
      "Val Loss: 0.19727684557437897, Val Bbox Loss: 0.11512404680252075, Val Accuracy: 92.33333587646484\n",
      "Iteration 1600, Epoch 13, \n",
      "Loss: 0.17840397357940674, Bbox loss: 0.11237858980894089, Accuracy: 92.83088684082031,\n",
      "Val Loss: 0.20975925028324127, Val Bbox Loss: 0.1157541498541832, Val Accuracy: 91.58333587646484\n",
      "Iteration 1650, Epoch 13, \n",
      "Loss: 0.17967861890792847, Bbox loss: 0.11241192370653152, Accuracy: 93.00373077392578,\n",
      "Val Loss: 0.18061935901641846, Val Bbox Loss: 0.11437013745307922, Val Accuracy: 92.83333587646484\n",
      "Iteration 1700, Epoch 13, \n",
      "Loss: 0.18935179710388184, Bbox loss: 0.1129690557718277, Accuracy: 92.3878173828125,\n",
      "Val Loss: 0.1852649450302124, Val Bbox Loss: 0.11568868160247803, Val Accuracy: 92.75\n",
      "Iteration 1750, Epoch 14, \n",
      "Loss: 0.16554825007915497, Bbox loss: 0.11173931509256363, Accuracy: 93.25892639160156,\n",
      "Val Loss: 0.17784734070301056, Val Bbox Loss: 0.11463876813650131, Val Accuracy: 92.66666412353516\n",
      "Iteration 1800, Epoch 14, \n",
      "Loss: 0.1730676144361496, Bbox loss: 0.112263523042202, Accuracy: 92.95955657958984,\n",
      "Val Loss: 0.17654924094676971, Val Bbox Loss: 0.1149587631225586, Val Accuracy: 92.0\n",
      "Iteration 1850, Epoch 15, \n",
      "Loss: 0.14377902448177338, Bbox loss: 0.11100897938013077, Accuracy: 93.22917175292969,\n",
      "Val Loss: 0.1910191774368286, Val Bbox Loss: 0.11516177654266357, Val Accuracy: 92.33333587646484\n",
      "Iteration 1900, Epoch 15, \n",
      "Loss: 0.16363917291164398, Bbox loss: 0.11228539049625397, Accuracy: 93.72052001953125,\n",
      "Val Loss: 0.17619217932224274, Val Bbox Loss: 0.1141263023018837, Val Accuracy: 92.41667175292969\n",
      "Iteration 1950, Epoch 15, \n",
      "Loss: 0.17045341432094574, Bbox loss: 0.11221786588430405, Accuracy: 93.34041595458984,\n",
      "Val Loss: 0.1753343641757965, Val Bbox Loss: 0.11420312523841858, Val Accuracy: 93.41666412353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000, Epoch 16, \n",
      "Loss: 0.1506187617778778, Bbox loss: 0.11074385046958923, Accuracy: 94.19642639160156,\n",
      "Val Loss: 0.1880979686975479, Val Bbox Loss: 0.1143994852900505, Val Accuracy: 92.5\n",
      "Iteration 2050, Epoch 16, \n",
      "Loss: 0.1618334949016571, Bbox loss: 0.11153340339660645, Accuracy: 93.66197204589844,\n",
      "Val Loss: 0.16445216536521912, Val Bbox Loss: 0.11354044079780579, Val Accuracy: 93.41666412353516\n",
      "Iteration 2100, Epoch 16, \n",
      "Loss: 0.16520732641220093, Bbox loss: 0.11170683056116104, Accuracy: 93.42716979980469,\n",
      "Val Loss: 0.1838395595550537, Val Bbox Loss: 0.11382992565631866, Val Accuracy: 92.75\n",
      "Iteration 2150, Epoch 17, \n",
      "Loss: 0.1458612084388733, Bbox loss: 0.11098338663578033, Accuracy: 94.23077392578125,\n",
      "Val Loss: 0.17033255100250244, Val Bbox Loss: 0.11413994431495667, Val Accuracy: 92.91666412353516\n",
      "Iteration 2200, Epoch 17, \n",
      "Loss: 0.15340544283390045, Bbox loss: 0.11131443828344345, Accuracy: 93.9606704711914,\n",
      "Val Loss: 0.16520348191261292, Val Bbox Loss: 0.11446765810251236, Val Accuracy: 92.66666412353516\n",
      "Iteration 2250, Epoch 18, \n",
      "Loss: 0.1379302591085434, Bbox loss: 0.10854589194059372, Accuracy: 94.41963958740234,\n",
      "Val Loss: 0.16109493374824524, Val Bbox Loss: 0.11356654018163681, Val Accuracy: 93.08333587646484\n",
      "Iteration 2300, Epoch 18, \n",
      "Loss: 0.14558438956737518, Bbox loss: 0.11114127188920975, Accuracy: 94.435302734375,\n",
      "Val Loss: 0.16643910109996796, Val Bbox Loss: 0.11355528235435486, Val Accuracy: 92.91666412353516\n",
      "Iteration 2350, Epoch 18, \n",
      "Loss: 0.1503712236881256, Bbox loss: 0.11091409623622894, Accuracy: 94.08586883544922,\n",
      "Val Loss: 0.16183409094810486, Val Bbox Loss: 0.11355196684598923, Val Accuracy: 92.91666412353516\n",
      "Iteration 2400, Epoch 19, \n",
      "Loss: 0.13563375174999237, Bbox loss: 0.10995171219110489, Accuracy: 94.5,\n",
      "Val Loss: 0.18886832892894745, Val Bbox Loss: 0.11543284356594086, Val Accuracy: 92.75\n",
      "Iteration 2450, Epoch 19, \n",
      "Loss: 0.14511926472187042, Bbox loss: 0.11066080629825592, Accuracy: 94.5,\n",
      "Val Loss: 0.15151531994342804, Val Bbox Loss: 0.11336646974086761, Val Accuracy: 93.58333587646484\n",
      "Iteration 2500, Epoch 19, \n",
      "Loss: 0.14646770060062408, Bbox loss: 0.11081701517105103, Accuracy: 94.38750457763672,\n",
      "Val Loss: 0.15713614225387573, Val Bbox Loss: 0.11227599531412125, Val Accuracy: 93.66666412353516\n",
      "Iteration 2550, Epoch 20, \n",
      "Loss: 0.12816748023033142, Bbox loss: 0.11035241931676865, Accuracy: 95.09447479248047,\n",
      "Val Loss: 0.1546323150396347, Val Bbox Loss: 0.1125258356332779, Val Accuracy: 93.91666412353516\n",
      "Iteration 2600, Epoch 20, \n",
      "Loss: 0.13923455774784088, Bbox loss: 0.11059076339006424, Accuracy: 94.79167175292969,\n",
      "Val Loss: 0.14903460443019867, Val Bbox Loss: 0.11268823593854904, Val Accuracy: 94.16666412353516\n",
      "Iteration 2650, Epoch 21, \n",
      "Loss: 0.1262587606906891, Bbox loss: 0.10772477835416794, Accuracy: 94.17613983154297,\n",
      "Val Loss: 0.18760676681995392, Val Bbox Loss: 0.11408890038728714, Val Accuracy: 92.33333587646484\n",
      "Iteration 2700, Epoch 21, \n",
      "Loss: 0.13386154174804688, Bbox loss: 0.10990581661462784, Accuracy: 94.97950744628906,\n",
      "Val Loss: 0.15615756809711456, Val Bbox Loss: 0.11291457712650299, Val Accuracy: 93.83333587646484\n",
      "Iteration 2750, Epoch 21, \n",
      "Loss: 0.13554106652736664, Bbox loss: 0.11001401394605637, Accuracy: 94.777587890625,\n",
      "Val Loss: 0.15345211327075958, Val Bbox Loss: 0.11244510114192963, Val Accuracy: 93.08333587646484\n",
      "Iteration 2800, Epoch 22, \n",
      "Loss: 0.12855853140354156, Bbox loss: 0.10938797891139984, Accuracy: 95.09698486328125,\n",
      "Val Loss: 0.16055746376514435, Val Bbox Loss: 0.11313527822494507, Val Accuracy: 93.25\n",
      "Iteration 2850, Epoch 22, \n",
      "Loss: 0.12790507078170776, Bbox loss: 0.10955309867858887, Accuracy: 95.332275390625,\n",
      "Val Loss: 0.1431061178445816, Val Bbox Loss: 0.11235541850328445, Val Accuracy: 94.16666412353516\n",
      "Iteration 2900, Epoch 22, \n",
      "Loss: 0.13021700084209442, Bbox loss: 0.1096794456243515, Accuracy: 95.0339126586914,\n",
      "Val Loss: 0.1499195396900177, Val Bbox Loss: 0.11216812580823898, Val Accuracy: 93.75\n",
      "Iteration 2950, Epoch 23, \n",
      "Loss: 0.1182461604475975, Bbox loss: 0.10961414128541946, Accuracy: 95.74468231201172,\n",
      "Val Loss: 0.14728394150733948, Val Bbox Loss: 0.11156491935253143, Val Accuracy: 94.08333587646484\n",
      "Iteration 3000, Epoch 23, \n",
      "Loss: 0.1244107112288475, Bbox loss: 0.10951503366231918, Accuracy: 95.47357940673828,\n",
      "Val Loss: 0.1420127898454666, Val Bbox Loss: 0.11144904047250748, Val Accuracy: 94.66666412353516\n",
      "Iteration 3050, Epoch 24, \n",
      "Loss: 0.11563039571046829, Bbox loss: 0.10757238417863846, Accuracy: 95.3125,\n",
      "Val Loss: 0.16242863237857819, Val Bbox Loss: 0.11202263087034225, Val Accuracy: 93.41666412353516\n",
      "Iteration 3100, Epoch 24, \n",
      "Loss: 0.11894752830266953, Bbox loss: 0.10869291424751282, Accuracy: 95.74519348144531,\n",
      "Val Loss: 0.14448745548725128, Val Bbox Loss: 0.11111285537481308, Val Accuracy: 94.0\n",
      "Iteration 3150, Epoch 24, \n",
      "Loss: 0.12020952254533768, Bbox loss: 0.10884041339159012, Accuracy: 95.46195983886719,\n",
      "Val Loss: 0.16833409667015076, Val Bbox Loss: 0.1135464683175087, Val Accuracy: 93.33333587646484\n",
      "Iteration 3200, Epoch 25, \n",
      "Loss: 0.11054135113954544, Bbox loss: 0.10815978795289993, Accuracy: 95.73863983154297,\n",
      "Val Loss: 0.1477241963148117, Val Bbox Loss: 0.11126747727394104, Val Accuracy: 94.16666412353516\n",
      "Iteration 3250, Epoch 25, \n",
      "Loss: 0.11443666368722916, Bbox loss: 0.10851018130779266, Accuracy: 95.85842895507812,\n",
      "Val Loss: 0.13831616938114166, Val Bbox Loss: 0.11161406338214874, Val Accuracy: 94.16666412353516\n",
      "Iteration 3300, Epoch 26, \n",
      "Loss: 0.06840568035840988, Bbox loss: 0.09586657583713531, Accuracy: 96.875,\n",
      "Val Loss: 0.14199678599834442, Val Bbox Loss: 0.11113379150629044, Val Accuracy: 93.83333587646484\n",
      "Iteration 3350, Epoch 26, \n",
      "Loss: 0.10458506643772125, Bbox loss: 0.10829753428697586, Accuracy: 96.47671508789062,\n",
      "Val Loss: 0.13898643851280212, Val Bbox Loss: 0.11065477132797241, Val Accuracy: 94.08333587646484\n",
      "Iteration 3400, Epoch 26, \n",
      "Loss: 0.11035711318254471, Bbox loss: 0.10834016650915146, Accuracy: 96.16336822509766,\n",
      "Val Loss: 0.13733211159706116, Val Bbox Loss: 0.11084172874689102, Val Accuracy: 94.16666412353516\n",
      "Iteration 3450, Epoch 27, \n",
      "Loss: 0.09717721492052078, Bbox loss: 0.10679421573877335, Accuracy: 96.46381378173828,\n",
      "Val Loss: 0.2196633219718933, Val Bbox Loss: 0.11301714926958084, Val Accuracy: 91.91667175292969\n",
      "Iteration 3500, Epoch 27, \n",
      "Loss: 0.10728821158409119, Bbox loss: 0.10765587538480759, Accuracy: 96.37681579589844,\n",
      "Val Loss: 0.1278819441795349, Val Bbox Loss: 0.11021304130554199, Val Accuracy: 95.0\n",
      "Iteration 3550, Epoch 27, \n",
      "Loss: 0.1100643202662468, Bbox loss: 0.10800649225711823, Accuracy: 95.9690170288086,\n",
      "Val Loss: 0.1548401117324829, Val Bbox Loss: 0.11147792637348175, Val Accuracy: 94.0\n",
      "Iteration 3600, Epoch 28, \n",
      "Loss: 0.09575281292200089, Bbox loss: 0.10700280964374542, Accuracy: 96.66384887695312,\n",
      "Val Loss: 0.13858728110790253, Val Bbox Loss: 0.11035958677530289, Val Accuracy: 94.75\n",
      "Iteration 3650, Epoch 28, \n",
      "Loss: 0.10369624942541122, Bbox loss: 0.10781417787075043, Accuracy: 96.2823257446289,\n",
      "Val Loss: 0.13506115972995758, Val Bbox Loss: 0.11082607507705688, Val Accuracy: 94.33333587646484\n",
      "Iteration 3700, Epoch 29, \n",
      "Loss: 0.1025509461760521, Bbox loss: 0.10633252561092377, Accuracy: 96.875,\n",
      "Val Loss: 0.13880467414855957, Val Bbox Loss: 0.11013580858707428, Val Accuracy: 95.0\n",
      "Iteration 3750, Epoch 29, \n",
      "Loss: 0.09830619394779205, Bbox loss: 0.10744092613458633, Accuracy: 96.5625,\n",
      "Val Loss: 0.14366742968559265, Val Bbox Loss: 0.11056500673294067, Val Accuracy: 94.0\n",
      "Iteration 3800, Epoch 29, \n",
      "Loss: 0.10123318433761597, Bbox loss: 0.10750927776098251, Accuracy: 96.2797622680664,\n",
      "Val Loss: 0.1351005733013153, Val Bbox Loss: 0.11045115441083908, Val Accuracy: 94.0\n",
      "Iteration 3850, Epoch 30, \n",
      "Loss: 0.08642426878213882, Bbox loss: 0.10567204654216766, Accuracy: 96.875,\n",
      "Val Loss: 0.15383099019527435, Val Bbox Loss: 0.11049208045005798, Val Accuracy: 93.75\n",
      "Iteration 3900, Epoch 30, \n",
      "Loss: 0.09707450866699219, Bbox loss: 0.10699529200792313, Accuracy: 96.48973083496094,\n",
      "Val Loss: 0.12813323736190796, Val Bbox Loss: 0.10978773236274719, Val Accuracy: 94.66666412353516\n",
      "Iteration 3950, Epoch 30, \n",
      "Loss: 0.09717348217964172, Bbox loss: 0.10722273588180542, Accuracy: 96.45579528808594,\n",
      "Val Loss: 0.13092191517353058, Val Bbox Loss: 0.10978128761053085, Val Accuracy: 94.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4000, Epoch 31, \n",
      "Loss: 0.08500190079212189, Bbox loss: 0.10671057552099228, Accuracy: 96.95122528076172,\n",
      "Val Loss: 0.14238578081130981, Val Bbox Loss: 0.11067082732915878, Val Accuracy: 94.41666412353516\n",
      "Iteration 4050, Epoch 31, \n",
      "Loss: 0.09261471033096313, Bbox loss: 0.10701925307512283, Accuracy: 96.61743927001953,\n",
      "Val Loss: 0.13600298762321472, Val Bbox Loss: 0.1106797531247139, Val Accuracy: 94.0\n",
      "Iteration 4100, Epoch 32, \n",
      "Loss: 0.0862443819642067, Bbox loss: 0.10373154282569885, Accuracy: 96.52777862548828,\n",
      "Val Loss: 0.11833979189395905, Val Bbox Loss: 0.10936193913221359, Val Accuracy: 95.33332824707031\n",
      "Iteration 4150, Epoch 32, \n",
      "Loss: 0.08948935568332672, Bbox loss: 0.10662893205881119, Accuracy: 96.84851837158203,\n",
      "Val Loss: 0.14936251938343048, Val Bbox Loss: 0.11097956448793411, Val Accuracy: 94.0\n",
      "Iteration 4200, Epoch 32, \n",
      "Loss: 0.09035372734069824, Bbox loss: 0.1065431460738182, Accuracy: 96.61697387695312,\n",
      "Val Loss: 0.1265881508588791, Val Bbox Loss: 0.10970012098550797, Val Accuracy: 94.41666412353516\n",
      "Iteration 4250, Epoch 33, \n",
      "Loss: 0.08372228592634201, Bbox loss: 0.10570047795772552, Accuracy: 96.875,\n",
      "Val Loss: 0.178265780210495, Val Bbox Loss: 0.11260516196489334, Val Accuracy: 92.91666412353516\n",
      "Iteration 4300, Epoch 33, \n",
      "Loss: 0.08781059086322784, Bbox loss: 0.10648396611213684, Accuracy: 96.61119842529297,\n",
      "Val Loss: 0.12192418426275253, Val Bbox Loss: 0.10963528603315353, Val Accuracy: 95.33332824707031\n",
      "Iteration 4350, Epoch 33, \n",
      "Loss: 0.08807118237018585, Bbox loss: 0.10657131671905518, Accuracy: 96.6535415649414,\n",
      "Val Loss: 0.1717807650566101, Val Bbox Loss: 0.11157414317131042, Val Accuracy: 93.66666412353516\n",
      "Iteration 4400, Epoch 34, \n",
      "Loss: 0.07772279530763626, Bbox loss: 0.10629970580339432, Accuracy: 97.0486068725586,\n",
      "Val Loss: 0.15265285968780518, Val Bbox Loss: 0.11122021079063416, Val Accuracy: 94.41666412353516\n",
      "Iteration 4450, Epoch 34, \n",
      "Loss: 0.08442354947328568, Bbox loss: 0.10655512660741806, Accuracy: 96.67762756347656,\n",
      "Val Loss: 0.12359466403722763, Val Bbox Loss: 0.10951923578977585, Val Accuracy: 95.16666412353516\n",
      "Iteration 4500, Epoch 35, \n",
      "Loss: 0.07433892786502838, Bbox loss: 0.10428755730390549, Accuracy: 97.23558044433594,\n",
      "Val Loss: 0.12240487337112427, Val Bbox Loss: 0.10934318602085114, Val Accuracy: 95.25\n",
      "Iteration 4550, Epoch 35, \n",
      "Loss: 0.08125285804271698, Bbox loss: 0.10623782128095627, Accuracy: 96.8501968383789,\n",
      "Val Loss: 0.1299101859331131, Val Bbox Loss: 0.11009111255407333, Val Accuracy: 94.91666412353516\n",
      "Iteration 4600, Epoch 35, \n",
      "Loss: 0.07919172942638397, Bbox loss: 0.10612419247627258, Accuracy: 96.9856185913086,\n",
      "Val Loss: 0.1358036994934082, Val Bbox Loss: 0.10995440930128098, Val Accuracy: 94.25\n",
      "Iteration 4650, Epoch 36, \n",
      "Loss: 0.0726085752248764, Bbox loss: 0.10510281473398209, Accuracy: 97.17742156982422,\n",
      "Val Loss: 0.15136870741844177, Val Bbox Loss: 0.11060727387666702, Val Accuracy: 94.58333587646484\n",
      "Iteration 4700, Epoch 36, \n",
      "Loss: 0.07674261182546616, Bbox loss: 0.10603611916303635, Accuracy: 97.0293197631836,\n",
      "Val Loss: 0.1198003739118576, Val Bbox Loss: 0.10936648398637772, Val Accuracy: 95.16666412353516\n",
      "Iteration 4750, Epoch 36, \n",
      "Loss: 0.07697681337594986, Bbox loss: 0.10604523867368698, Accuracy: 97.13740539550781,\n",
      "Val Loss: 0.1557634025812149, Val Bbox Loss: 0.11047292500734329, Val Accuracy: 94.41666412353516\n",
      "Iteration 4800, Epoch 37, \n",
      "Loss: 0.07009637355804443, Bbox loss: 0.105873242020607, Accuracy: 97.44898223876953,\n",
      "Val Loss: 0.12848784029483795, Val Bbox Loss: 0.10948756337165833, Val Accuracy: 95.41666412353516\n",
      "Iteration 4850, Epoch 37, \n",
      "Loss: 0.07484576851129532, Bbox loss: 0.10600510239601135, Accuracy: 97.33270263671875,\n",
      "Val Loss: 0.11474436521530151, Val Bbox Loss: 0.10887552052736282, Val Accuracy: 96.0\n",
      "Iteration 4900, Epoch 38, \n",
      "Loss: 0.06831568479537964, Bbox loss: 0.104310043156147, Accuracy: 97.70220184326172,\n",
      "Val Loss: 0.147899329662323, Val Bbox Loss: 0.11059793829917908, Val Accuracy: 94.66666412353516\n",
      "Iteration 4950, Epoch 38, \n",
      "Loss: 0.07502942532300949, Bbox loss: 0.1056484654545784, Accuracy: 97.10820770263672,\n",
      "Val Loss: 0.12141624093055725, Val Bbox Loss: 0.10916469991207123, Val Accuracy: 95.16666412353516\n",
      "Iteration 5000, Epoch 38, \n",
      "Loss: 0.0740104541182518, Bbox loss: 0.10585162043571472, Accuracy: 97.30235290527344,\n",
      "Val Loss: 0.12444732338190079, Val Bbox Loss: 0.10975609719753265, Val Accuracy: 95.58332824707031\n",
      "Iteration 5050, Epoch 39, \n",
      "Loss: 0.066375732421875, Bbox loss: 0.1050911396741867, Accuracy: 97.5,\n",
      "Val Loss: 0.13457675278186798, Val Bbox Loss: 0.10942606627941132, Val Accuracy: 95.58332824707031\n",
      "Iteration 5100, Epoch 39, \n",
      "Loss: 0.07122253626585007, Bbox loss: 0.10576139390468597, Accuracy: 97.48162078857422,\n",
      "Val Loss: 0.11678279936313629, Val Bbox Loss: 0.10927648842334747, Val Accuracy: 95.41666412353516\n",
      "Iteration 5150, Epoch 40, \n",
      "Loss: 0.07730245590209961, Bbox loss: 0.10516193509101868, Accuracy: 97.39582824707031,\n",
      "Val Loss: 0.14233770966529846, Val Bbox Loss: 0.10982564836740494, Val Accuracy: 95.0\n",
      "Iteration 5200, Epoch 40, \n",
      "Loss: 0.06783724576234818, Bbox loss: 0.1057078167796135, Accuracy: 97.55307006835938,\n",
      "Val Loss: 0.1318400353193283, Val Bbox Loss: 0.1094031035900116, Val Accuracy: 95.5\n",
      "Iteration 5250, Epoch 40, \n",
      "Loss: 0.06839995831251144, Bbox loss: 0.10577584058046341, Accuracy: 97.6486587524414,\n",
      "Val Loss: 0.10595037043094635, Val Bbox Loss: 0.10882508009672165, Val Accuracy: 96.0\n",
      "Iteration 5300, Epoch 41, \n",
      "Loss: 0.055824000388383865, Bbox loss: 0.10412662476301193, Accuracy: 98.06547546386719,\n",
      "Val Loss: 0.1804559975862503, Val Bbox Loss: 0.1110360398888588, Val Accuracy: 94.0\n",
      "Iteration 5350, Epoch 41, \n",
      "Loss: 0.06720428168773651, Bbox loss: 0.10541719198226929, Accuracy: 97.55722045898438,\n",
      "Val Loss: 0.10975466668605804, Val Bbox Loss: 0.10868088901042938, Val Accuracy: 95.75\n",
      "Iteration 5400, Epoch 41, \n",
      "Loss: 0.06348250806331635, Bbox loss: 0.1054421216249466, Accuracy: 97.84349060058594,\n",
      "Val Loss: 0.13189393281936646, Val Bbox Loss: 0.11005508154630661, Val Accuracy: 95.33332824707031\n",
      "Iteration 5450, Epoch 42, \n",
      "Loss: 0.0551573745906353, Bbox loss: 0.10485180467367172, Accuracy: 98.2371826171875,\n",
      "Val Loss: 0.1547861397266388, Val Bbox Loss: 0.1100081354379654, Val Accuracy: 94.75\n",
      "Iteration 5500, Epoch 42, \n",
      "Loss: 0.062506765127182, Bbox loss: 0.1055397316813469, Accuracy: 97.96348571777344,\n",
      "Val Loss: 0.11448156833648682, Val Bbox Loss: 0.10903992503881454, Val Accuracy: 95.91666412353516\n",
      "Iteration 5550, Epoch 43, \n",
      "Loss: 0.06705363094806671, Bbox loss: 0.10307935625314713, Accuracy: 97.32142639160156,\n",
      "Val Loss: 0.13398204743862152, Val Bbox Loss: 0.10969200730323792, Val Accuracy: 95.16666412353516\n",
      "Iteration 5600, Epoch 43, \n",
      "Loss: 0.06265557557344437, Bbox loss: 0.10565601289272308, Accuracy: 97.77960968017578,\n",
      "Val Loss: 0.1303885132074356, Val Bbox Loss: 0.10959412157535553, Val Accuracy: 95.58332824707031\n",
      "Iteration 5650, Epoch 43, \n",
      "Loss: 0.06083618476986885, Bbox loss: 0.10540647059679031, Accuracy: 97.99942016601562,\n",
      "Val Loss: 0.10207489877939224, Val Bbox Loss: 0.1087203398346901, Val Accuracy: 96.5\n",
      "Iteration 5700, Epoch 44, \n",
      "Loss: 0.04842274636030197, Bbox loss: 0.1043328270316124, Accuracy: 98.3125,\n",
      "Val Loss: 0.12634654343128204, Val Bbox Loss: 0.1096167117357254, Val Accuracy: 95.75\n",
      "Iteration 5750, Epoch 44, \n",
      "Loss: 0.05936563387513161, Bbox loss: 0.10535707324743271, Accuracy: 98.0,\n",
      "Val Loss: 0.11995306611061096, Val Bbox Loss: 0.1090933158993721, Val Accuracy: 95.91666412353516\n",
      "Iteration 5800, Epoch 44, \n",
      "Loss: 0.056561727076768875, Bbox loss: 0.10542559623718262, Accuracy: 98.0999984741211,\n",
      "Val Loss: 0.11433594673871994, Val Bbox Loss: 0.10929027944803238, Val Accuracy: 95.83332824707031\n",
      "Iteration 5850, Epoch 45, \n",
      "Loss: 0.04639967530965805, Bbox loss: 0.10497397929430008, Accuracy: 98.51017761230469,\n",
      "Val Loss: 0.1417822539806366, Val Bbox Loss: 0.10938388854265213, Val Accuracy: 95.41666412353516\n",
      "Iteration 5900, Epoch 45, \n",
      "Loss: 0.057675253599882126, Bbox loss: 0.1057175025343895, Accuracy: 98.18548583984375,\n",
      "Val Loss: 0.10869085788726807, Val Bbox Loss: 0.10924609750509262, Val Accuracy: 96.33332824707031\n",
      "Iteration 5950, Epoch 46, \n",
      "Loss: 0.04800482094287872, Bbox loss: 0.10295424610376358, Accuracy: 98.29545593261719,\n",
      "Val Loss: 0.1352252960205078, Val Bbox Loss: 0.1098308265209198, Val Accuracy: 95.41666412353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6000, Epoch 46, \n",
      "Loss: 0.055208347737789154, Bbox loss: 0.10522408783435822, Accuracy: 98.05327606201172,\n",
      "Val Loss: 0.1297939419746399, Val Bbox Loss: 0.10984379798173904, Val Accuracy: 95.16666412353516\n",
      "Iteration 6050, Epoch 46, \n",
      "Loss: 0.053453873842954636, Bbox loss: 0.10530669242143631, Accuracy: 98.28266143798828,\n",
      "Val Loss: 0.09989511221647263, Val Bbox Loss: 0.10868560522794724, Val Accuracy: 96.66666412353516\n",
      "Iteration 6100, Epoch 47, \n",
      "Loss: 0.04173148795962334, Bbox loss: 0.10407020896673203, Accuracy: 98.59913635253906,\n",
      "Val Loss: 0.15562623739242554, Val Bbox Loss: 0.11157460510730743, Val Accuracy: 95.08332824707031\n",
      "Iteration 6150, Epoch 47, \n",
      "Loss: 0.054010286927223206, Bbox loss: 0.10530155152082443, Accuracy: 98.33860778808594,\n",
      "Val Loss: 0.12350188940763474, Val Bbox Loss: 0.10944396257400513, Val Accuracy: 95.91666412353516\n",
      "Iteration 6200, Epoch 47, \n",
      "Loss: 0.051265548914670944, Bbox loss: 0.10545526444911957, Accuracy: 98.31637573242188,\n",
      "Val Loss: 0.1301700621843338, Val Bbox Loss: 0.10943878442049026, Val Accuracy: 95.0\n",
      "Iteration 6250, Epoch 48, \n",
      "Loss: 0.046138662844896317, Bbox loss: 0.10535965859889984, Accuracy: 98.53723907470703,\n",
      "Val Loss: 0.1767638921737671, Val Bbox Loss: 0.11301839351654053, Val Accuracy: 93.08333587646484\n",
      "Iteration 6300, Epoch 48, \n",
      "Loss: 0.05405363067984581, Bbox loss: 0.1058032438158989, Accuracy: 98.19587707519531,\n",
      "Val Loss: 0.10779810696840286, Val Bbox Loss: 0.10968347638845444, Val Accuracy: 96.41666412353516\n",
      "Iteration 6350, Epoch 49, \n",
      "Loss: 0.04885641857981682, Bbox loss: 0.10380879044532776, Accuracy: 98.125,\n",
      "Val Loss: 0.11778239160776138, Val Bbox Loss: 0.10901815444231033, Val Accuracy: 96.33332824707031\n",
      "Iteration 6400, Epoch 49, \n",
      "Loss: 0.05073988810181618, Bbox loss: 0.1052415743470192, Accuracy: 98.29326629638672,\n",
      "Val Loss: 0.1837364286184311, Val Bbox Loss: 0.11161655187606812, Val Accuracy: 93.83333587646484\n",
      "Iteration 6450, Epoch 49, \n",
      "Loss: 0.052023567259311676, Bbox loss: 0.10556607693433762, Accuracy: 98.16576385498047,\n",
      "Val Loss: 0.10075252503156662, Val Bbox Loss: 0.10890202969312668, Val Accuracy: 96.83332824707031\n",
      "Iteration 6500, Epoch 50, \n",
      "Loss: 0.03888610377907753, Bbox loss: 0.10445606708526611, Accuracy: 98.62689208984375,\n",
      "Val Loss: 0.16323627531528473, Val Bbox Loss: 0.11124258488416672, Val Accuracy: 95.33332824707031\n",
      "Iteration 6550, Epoch 50, \n",
      "Loss: 0.05501727759838104, Bbox loss: 0.10572725534439087, Accuracy: 97.98568725585938,\n",
      "Val Loss: 0.1550033688545227, Val Bbox Loss: 0.11055352538824081, Val Accuracy: 94.25\n"
     ]
    }
   ],
   "source": [
    "model = train(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.squeeze(score)\n",
    "bbox = np.squeeze(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_score = np.squeeze(y_test[:,:,:,:2])\n",
    "y_test_bbox = np.squeeze(y_test[:,:,:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      1181\n",
      "           1       0.93      0.98      0.96      1219\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2400\n",
      "   macro avg       0.96      0.95      0.95      2400\n",
      "weighted avg       0.95      0.95      0.95      2400\n",
      " samples avg       0.95      0.95      0.95      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_score, np.round(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1094   87]\n",
      " [  24 1195]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_score[:,1:2], np.round(score[:,1:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5034582e-03],\n",
       "       [9.9999881e-01],\n",
       "       [9.9942529e-01],\n",
       "       [6.9643342e-05],\n",
       "       [9.9997509e-01],\n",
       "       [5.9466606e-06],\n",
       "       [9.9910057e-01],\n",
       "       [9.9999404e-01],\n",
       "       [4.3008304e-09],\n",
       "       [9.4043756e-01]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[100:110,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_score[100:110,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaron\\AppData\\Local\\Continuum\\anaconda3\\envs\\TF_20_env\\lib\\site-packages\\matplotlib\\text.py:1150: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '[4.3008304e-09]')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(2,3)\n",
    "test_face = X_test[101]\n",
    "plt.subplot(231)\n",
    "plt.imshow(test_face)\n",
    "plt.title(score[101,1:])\n",
    "test_face = X_test[102]\n",
    "plt.subplot(232)\n",
    "plt.imshow(test_face)\n",
    "plt.title(score[102,1:])\n",
    "test_face = X_test[109]\n",
    "plt.subplot(233)\n",
    "plt.imshow(test_face)\n",
    "plt.title(score[109,1:])\n",
    "\n",
    "test_face = X_test[100]\n",
    "plt.subplot(234)\n",
    "plt.imshow(test_face)\n",
    "plt.title(score[100,1:])\n",
    "test_face = X_test[103]\n",
    "plt.subplot(235)\n",
    "plt.imshow(test_face)\n",
    "plt.title(score[103,1:])\n",
    "test_face = X_test[108]\n",
    "plt.subplot(236)\n",
    "plt.imshow(test_face)\n",
    "plt.title(score[108,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_testset(index):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(2, 2))\n",
    "    ax.imshow(X_test[index])\n",
    "    plt.title(score[index,1:])\n",
    "    # Create a Rectangle patch\n",
    "    x = round(12*bbox[index,0])\n",
    "    y = round(12*bbox[index,1])\n",
    "    w = round(12*bbox[index,2]) - x\n",
    "    h = round(12*bbox[index,3]) - y\n",
    "    rect = patches.Rectangle((x,y),w,h,linewidth=1,edgecolor='r',facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJgAAACcCAYAAACDU2I3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAPCUlEQVR4nO2da5BcxXmGn3evknZ1QVeulpBQZAMFIsayCVCGUBbCoYxDApEqjlUOLudGBRKSKoeKwcFOgsup2KFMOeVgGeyyMQ4OsX4ARgHskBgHkIy5XwSSQAgjVhK67Yq9fflxetHR2bPTszvb7Ozu91RNzZzur/v0nHmnu0+f/rplZjhOKhrGugDOxMYF5iTFBeYkxQXmJMUF5iTFBeYkxQXmJGVCC0ySSToo6e/Huiz1gqS/C9fEJDUlP6GZTdgXYMBJhbDlwEagM7wvr5D+fcADwF5gM/DbhfhPh/ADwL3Asbm4WcBtwM7w+nwh7W8AjwD7gSeAc3Jx14Y8B15dQD8wN8TfCnQXbBpDXAtwJ7A1fP/zSr7XohDXlPw3GGsRvJsCCxd/G/AXQCvw5+G4pSRtE/AC8JdAI/CbwEHg10L8h4NwTgn5fh34aS79t4B/B6aFH/Ql4FMhbjbQAVwW8v4EsAc4aojv8XnggdzxrcAXh7BtAa4GzgFed4G9uwJbCbwGKBf2CrCqJO2poWbI294HfCF8/ifg5lzcseF8S8JxB/CBXPy1wEPh88XA04XzvQBcUVIOBXGurUZghbTbx1pgE7oPVsIpwBMWrnLgiRBeREOEnZr7rEIcufhiHpXSFuPznAssAH5YCP9TSbslbZT0OyXp6oLJJrB2sv5Unr3A9BLb58iawL+W1CxpJVmzOC3E3w1cLuk0SVOB68hqhYH4e4HPSpou6STgD3NxPwOOlbQm5L0WWJKLz7MWuNPMDuTCbgKWAvOBzwG3Sjq7ukvw7jLZBHYAmFEIm0HW0T4CM+sBPg78FvAr4BrgB2TNDmZ2P3A9Wc2yjaxTvX8gnqx/1wW8CPwIuD2XdhdwCVn/7g1gFfBfubQABOFeRnazkC/bJjPbZWa9ZnY38F3g0uFciHeLySawp4HTJOWbp9NC+CDM7Akz+7CZzTGzC4HFZHd+A/E3m9lSM5tPJrQm4KkQt9vMft/MjjazU8iudT7tT83sA2Y2G/gDYFk+PnApsBv4SeR7GeVN+tgz1h3xlC+Gvou8iuwu8kqGuIsM9qcBU8iarr8CtgCtIW4KWZ9JwHvIRPAPubRLgDlkd4kXkXX6T8nFnwE0k9WgXwX+t+T89wE3lIT/Lllz30B247KfXGc+fLcpZDXiyvA5f7OyCL+LHH2B5X7YjWTN1ybgjFzctcA9ueMvkw0fHADuKYh1FtkNwkGyJvQfCWNRIf5yYAfZeNvjwIWFctxO1v/bC9wBzC/EHwf0Fssf4h4K6fYBvwRWF+K3hu+efy0aC4EpnHBCIukQ8DZwk5l9bqzLUw9Iup6s79cKtJlZX9LzTWSBOWPPZOvkO+8yLjAnKS4wJynpp2sMEzU0WkNTc0Ub6+uNZ9R6VPxcja1Rm8bmxqjN9Pb2qE1TQ3X/5cbGuF13d0/cpiduU03/vq8/fq27Ol7tMLN5ZXE1CUzSKuBfyMZ6bjGzGwvxrcC3gfcDu4DfM7OtlfJsaGpm2oKFFc/bu++NeOGWxB/PNbRXPg/ArAUzozbnnXNu1Gb+9LgIAWa2lT0tOpItr++I2ux4fXvU5u2eA1GbA/vfjNr84partg0VN+ImUlIjcDPZIOLJwBpJJxfMrgD2mNlJwFeAL430fM74pJY+2Apgs5m9bGbdwPfJnq/luYTDz9HuBC4oPKZxJji1COw44NXc8fYQVmpjZr1ko89zajinM86opQ9WVhMVR22rsUHSZ4DPAKix7u47nBqopQbbDpyQOz6e7NlbqU1wMJhJNjvgCMzsG2Z2ppmdqYb4XZszfqhFYI8CSyWdKKkFWA2sL9isJ5swB9kMgAfMn01NKkbcHplZr6QrgR+TDVOsM7OnJd0APGZm64FvAt+RtJms5lo9GoV2xg81dXgsm015dyHsutznQ2QzMqvPs7+fvoOVx2f6G1qi+bS0xcev+nt2RW1m9sUvUfO+16M2h/ri5QE4ds6JUZvTFx4ftVnYPiVqs+dQV9TmqZf7ozaV8EdFTlJcYE5SXGBOUlxgTlJ8VLPAM5v+jYXd+4aX6K40ZalXfjVjLmuu+GpVti6wAgu799H2oWsOHx+zIJpmxRmnR22mVnFXC7B4SfwusrE//jj3rV0dUZvq7iKfHRT24Fc+EU03gDeRTlJcYE5S6q6JlOKzOltnxpuRtvg4I4e2bSoNn7rrcPji96+J5rNl4/1Rm9b26prIpu7lUZu+nrejNj1d8UmZp59StubLkRyaV7ZsB5yUC/9JhfRegzlJcYE5SXGBOUlxgTlJqcXp4wRJD0p6VtLTkq4qsTlP0l5Jj4fXdWV5OROXWu4ie4FrzGyTpOnARkkbzOyZgt1DZnZxDedxxjEjrsHM7HUz2xQ+7weeZbDThzPJGZU+mKRFZOtu/V9J9FmSfinpHknxgRdnQlHzQKukdrLlI682s+JT4k3AQjM7IOmjwH+SLV5bzOMdryJooGv/wYrntN2lK14eQXd35eUHAKbPXVwa3tR+eMbo1La50XyWfTBecW/d/ELUBmDr1rhH9qnvPSFqc8zR8TJ97NwlUZtpDzxUGn7WMYefY95SIX1NNZikZjJxfdfM/qMYb2b7LKyOHKZXN0sa9IvlvYpwv9wJRS13kSJz6njWzP55CJujBzy5Ja0I54tPhHcmDLU0kWeTrY78pKTHQ9i1ZAviYmb/Suaq9ieSesnWRF3tbmuTi1rc1v6HyNLZZvY14GsjPYcz/vGRfCcpLjAnKS4wJykuMCcpdTejFQGNlcfCRHy66ttvxZ0eFp/7ycGBv/gO8953zjuH710eXx6zd0989uiMxfHlOgFammdFbXa/tTFqM3vW0VGbex6JX6NXOssHml8aIryI12BOUlxgTlJcYE5SXGBOUlxgTlJcYE5SXGBOUlxgTlLqbqBVEk0tlYvVX8UerabuqM2UvvKZs/nw1qb4f/DtKgZ+Z0ypYgMvYEZbFbOZjjojajJtXnwzsE6L//wdfeXfv6MvvuoQ1D6jdaukJ4NL2mMl8ZJ0k6TNkp6Q9Ou1nM8Zf4xGDXa+mQ31zOEisjn4S4EPAl8P784kIXUf7BLg25bxc2CWpGMSn9OpI2oVmAH3SdoYPIOKVLNhljOBqbWJPNvMdkiaD2yQ9JyZ/XcuftibYSG/sZ1I1PRrmtmO8L6TbCncFQWTajbMKmyG5QKbSNTittYW1qRAUhuwEniqYLYe+GS4m/wQsNfM4vuuOBOGWprIBcBdwe2xCfiemd0r6Y/hHbe1u4GPApuBTuBTtRXXGW/U4rb2MjBo/e4grIHPBvzZcPJVQyMt7eXrgg7Q0xPfoKm3K75hVl9/+aBmPrxjd7zCPdgZL8/iefOiNgDz58U3hd/x5t6oTcfuuH9zcxUb1Xd1luczVHgR7/A4SXGBOUlxgTlJcYE5SXGBOUlxgTlJcYE5SXGBOUlxgTlJqb8p0w3NNLYdX9Gmp7PyIsEA9MYXAd7fVZ5PPnzuvPguaW9sfTlq098e3yENYNe2+H9+38HOqE37/PiUZjXHy2TsH1Z4Ea/BnKS4wJykuMCcpLjAnKTUMuFwWW4Xtccl7ZN0dcHGd1ub5NQyH+x5YDmApEbgNbJp00V8t7VJzGg1kRcAL5nZtlHKz5kgjJbAVgO3DxHnu61NYkZjt7UW4GPA35RED3u3taYps5j9ngsrnnP/nvj6Dfs7XovavPF8+U5i+fAtW86L5tO2IL4gbl9jfHoywMwZrVGbqa0H4vnMqzztHGDXwd1Rm45dbw4rvMho1GAXAZvMbNBSyyPZba2huW0UiuTUC6MhsDUM0Tz6bmtOTU2kpGnAR4A/yoXl3dZ8t7VJTk0CM7NOYE4hLO+25rutTXJ8JN9JigvMSYoLzEmKC8xJSt3NaG3o76b14PaKNuqJz2jtnzk1arN81eWDA7+0gRWXHg7/2YM/jOZz1vlrozZTW6tbm6KhiuWrmqbEZ+vu7YqvX/HiS89FbWbNKZ9dPFR4Ea/BnKS4wJykuMCcpLjAnKS4wJykuMCcpLjAnKS4wJykRAdaJa0DLgZ2mtmpIWw2cAewCNgKXG5me0rSrgX+Nhx+0cxui56Pblr7X61o06f4ortm8d3GHr7jm/Hw/p5oPv2d+6I2zRetidoAzJoRX6rgre74TNS+/vg1Ou6YZVGbl7aUL4vQdSi+mx1UV4PdCqwqhH0WuN/MlgL3h+MjCCK8nmzzqxXA9ZLiv7ozoYgKLGwNU/zLXAIM1Ea3AR8vSXohsMHMdofabQODhepMcEbaB1swsGNHeJ9fYuMbYTlJH3ZXtREWHOlV1NwSf0jtjB9GWoO9MbDvY3jfWWJT1UZYcKRXUVNzfIcOZ/wwUoGtBwbmqKwFflRi82NgpaSjQud+ZQhzJhFRgUm6HXgYWCZpu6QrgBuBj0h6kcyr6MZge6akWwDMbDfwBeDR8LohhDmTiGgfzMyGGsC5oMT2MeDTueN1wLoRl84Z99TdjFYMLDKG11XNGq1T4n25U88vWfTnWz8/Inzzpkei+Wx7/OGozVsXlY3kDGZGFeU++qj4zfjM9vhyBvs64z2kQz3PDBF+KJoW/FGRkxgXmJMUF5iTFBeYkxQXmJMUF5iTFBeYkxQXmJMU1dt6cJLeBIqrVc8FOsagOLUwmcq80MxK10aoO4GVIekxMztzrMsxHLzMGd5EOklxgTlJGS8C+8ZYF2AEeJkZJ30wZ/wyXmowZ5xS1wKTtErS85I2Sxrke1mvSNoq6cmwheFjY12eMiStk7RT0lO5sNmSNkh6MbzX7MdatwILWwTeTLZVzcnAGkknj22phsX5Zra8jocqbmUEDtXDpW4FRuYNvtnMXjazbuD7ZA6/zihQg0P1sKhngY1nx10D7pO0Mfh8jheqcageFvU3J/8wVTvu1iFnm9kOSfOBDZKeCzXGpKOea7CqHXfrDTPbEd53km0zvWJsS1Q11ThUD4t6FtijwFJJJ4ZNT1eTOfzWNZLaJE0f+EzmcPxU5VR1QzUO1cOibptIM+uVdCWZN3gjsM7Mnh7jYlXDAuCusE1mE/A9M7t3bIs0mOBQfR4wV9J2sqW2bgR+EJyrXwEuq/k8PpLvpKSem0hnAuACc5LiAnOS4gJzkuICc5LiAnOS4gJzkuICc5Ly/xgz3KlRgR8bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_testset(104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29608262, 0.02825493, 0.9423902 , 0.95727515], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox[101,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.  , 1.  , 1.  ])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bbox[101,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_score[14,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bbox[8,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox[8,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
