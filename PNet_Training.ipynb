{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pkg_resources\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "import os\n",
    "\n",
    "FACES_PATH = '../data/face_detection/faces/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(PNet, self).__init__(name=\"PNet\")\n",
    "        # Define layers here.\n",
    "        self.conv1 = tf.keras.layers.Conv2D(10, (3, 3), name=\"conv1\")\n",
    "        self.prelu1 = tf.keras.layers.PReLU(tf.constant_initializer(0.25), shared_axes=[1, 2], name=\"prelu1\")\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool1\")\n",
    "        self.conv2 = tf.keras.layers.Conv2D(16, (3, 3), name=\"conv2\")\n",
    "        self.prelu2 = tf.keras.layers.PReLU(tf.constant_initializer(0.25), shared_axes=[1, 2], name=\"prelu2\")\n",
    "        self.conv3 = tf.keras.layers.Conv2D(32, (3, 3), name=\"conv3\")\n",
    "        self.prelu3 = tf.keras.layers.PReLU(tf.constant_initializer(0.25), shared_axes=[1, 2], name=\"prelu3\")\n",
    "        self.cls_output = tf.keras.layers.Conv2D(2, (1, 1), activation=\"softmax\", name=\"conv4-1\")\n",
    "        self.bbox_pred = tf.keras.layers.Conv2D(4, (1, 1), name=\"conv4-2\")\n",
    "        #self.landmark_pred = keras.layers.Conv2D(10, (1, 1), name=\"conv4_3\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define your forward pass here,\n",
    "        # using layers you previously defined (in `__init__`).\n",
    "        scores = None\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.prelu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.prelu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.prelu3(x)\n",
    "        scores = [self.cls_output(x), self.bbox_pred(x)]#, self.landmark_pred(x)]\n",
    "        \n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  /cpu:0\n"
     ]
    }
   ],
   "source": [
    "# Set up some global variables\n",
    "USE_GPU = False\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the PNet  to ensure that the implementation does not crash and produces outputs of the expected shape.\n",
    "Pnet will output are:\n",
    "1. Face classification,  size (batch,1,1,2) for 2 calss classification, \"Face\", and \"Not face\"\n",
    "2. Bounding box  (batch,1,1,4) for 4 boundind box corrdinates (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               multiple                  280       \n",
      "_________________________________________________________________\n",
      "prelu1 (PReLU)               multiple                  10        \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               multiple                  1456      \n",
      "_________________________________________________________________\n",
      "prelu2 (PReLU)               multiple                  16        \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               multiple                  4640      \n",
      "_________________________________________________________________\n",
      "prelu3 (PReLU)               multiple                  32        \n",
      "_________________________________________________________________\n",
      "conv4-1 (Conv2D)             multiple                  66        \n",
      "_________________________________________________________________\n",
      "conv4-2 (Conv2D)             multiple                  132       \n",
      "=================================================================\n",
      "Total params: 6,632\n",
      "Trainable params: 6,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "P-Net output size testing: \n",
      "classificatin score output (32, 1, 1, 2) \n",
      "bounsing box score output (32, 1, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "def test_PNet(batch=64):    \n",
    "    model = PNet()\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((batch, 12, 12, 3))\n",
    "        classification_scores, bbox_score = model(x)\n",
    "        print(model.summary())\n",
    "        print('\\nP-Net output size testing: \\nclassificatin score output', classification_scores.shape,\n",
    "              '\\nbounsing box score output', bbox_score.shape)\n",
    "\n",
    "batch_test = 32\n",
    "test_PNet(batch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pos_images():\n",
    "    #Read positive images:\n",
    "    path, __, filenames = next(os.walk(FACES_PATH+'pos_train/'))\n",
    "    file_count = 2048 #len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[0.0,1.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    file = open(FACES_PATH+'coordinates.txt','r')\n",
    "    lines = file.readlines()\n",
    "    lines = [line[:-1] for line in lines]\n",
    "    idx=[1,0,3,2]\n",
    "    for line in lines:\n",
    "        line = line.split(\" \")\n",
    "        line = line[1]\n",
    "        line=line[1:-1]\n",
    "        line = line.split(\",\")\n",
    "        #Transpose coordinates\n",
    "        x=0\n",
    "        nline=[]\n",
    "        for i in idx:\n",
    "            nline.append(line[i])\n",
    "            x=x+1\n",
    "        line=[[[float(c) for c in nline]]]\n",
    "        coordinates.append(line)\n",
    "    #Return images, probs, and coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "def read_neg_images():\n",
    "    #Read negative images:\n",
    "    path, __, filenames = next(os.walk(FACES_PATH+'neg_train/'))\n",
    "    file_count = 2048 #len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[1.0,0.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    for i in range(file_count):\n",
    "        coordinates.append([[[0.0,0.0,0.0,0.0]]])\n",
    "    #Return images, prob, coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "#Read in all images, probabilities, and coordinates\n",
    "pimages, pprob, pcoordinates = read_pos_images()\n",
    "nimages, nprob, ncoordinates = read_neg_images()\n",
    "o_images=np.append(pimages,nimages,axis=0)\n",
    "o_images=np.reshape(o_images,(-1,12,12,3))\n",
    "o_prob=pprob+nprob\n",
    "o_coordinates=pcoordinates+ncoordinates\n",
    "\n",
    "#Shuffle them up using an index\n",
    "idx=np.arange(len(o_prob))\n",
    "np.random.shuffle(idx)\n",
    "images=np.empty_like(o_images)\n",
    "c=0\n",
    "for i in idx:\n",
    "    images[c]=o_images[i]\n",
    "    c=c+1\n",
    "images=(np.float32)(images-127.5)/128.0\n",
    "images = np.transpose(images, (0, 2, 1, 3)) #Transpose images\n",
    "prob=[]\n",
    "for i in idx:\n",
    "    prob.append(o_prob[i])\n",
    "coordinates=[]\n",
    "for i in idx:\n",
    "    coordinates.append(o_coordinates[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train , Image batch shape  (4096, 12, 12, 3)\n",
      "y_train , Classification ground true batch shape  (4096, 1, 1, 2)\n",
      "y_train , Coordinates ground true batch shape  (4096, 1, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('X_train , Image batch shape ', images.shape)\n",
    "print('y_train , Classification ground true batch shape ' ,np.array(prob).shape)\n",
    "print('y_train , Coordinates ground true batch shape ', np.array(coordinates).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X_data for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape (4096, 12, 12, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X_data shape',X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.99609375"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create \"y_data\" for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.concatenate((np.array(prob), np.array(coordinates)), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data shape (4096, 1, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "print('y_data shape',y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_data Classification shape (4096, 1, 1, 2)\n",
      "y_data Coordinate shape (4096, 1, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "print('y_data Classification shape', y_data[:,:,:,:2].shape)\n",
    "print('y_data Coordinate shape',y_data[:,:,:,2:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide dataset to \"train', \"val\" and \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X, y, training_prec = 0.7, val_prec = 0.1, test_prec = 0.2):\n",
    "        data_length = len(X)\n",
    "        num_training = np.int(data_length * training_prec)\n",
    "        num_validation = np.int(data_length * val_prec)\n",
    "        \n",
    "        mask = range(num_training)\n",
    "        X_train = X[mask]\n",
    "        y_train = y[mask]\n",
    "        mask = range(num_training, num_training + num_validation)\n",
    "        X_val = X[mask]\n",
    "        y_val = y[mask]\n",
    "        mask = range(num_training + num_validation, data_length)\n",
    "        X_test = X[mask]\n",
    "        y_test = y[mask]\n",
    "        \n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (2867, 12, 12, 3)\n",
      "Train labels shape:  (2867, 1, 1, 6) float64\n",
      "Validation data shape:  (409, 12, 12, 3)\n",
      "Validation labels shape:  (409, 1, 1, 6)\n",
      "Test data shape:  (820, 12, 12, 3)\n",
      "Test labels shape:  (820, 1, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data(X_data, y_data)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets test a single batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_init_fn():\n",
    "    learning_rate = 1e-3\n",
    "    return tf.keras.optimizers.Adam(learning_rate) \n",
    "    #return tf.keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PNet()\n",
    "optimizer = optimizer_init_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "bbox_loss = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.BinaryCrossentropy(name='train_classification_loss')\n",
    "train_bbox_loss = tf.keras.metrics.MeanSquaredError(name='train_bbox_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    classification_scores, bbox_scores = model(X_train , training=True)\n",
    "    prediction_loss = classification_loss(y_data[:,:,:,:2], classification_scores)\n",
    "    coordinate_loss = bbox_loss(y_data[:,:,:,2:], bbox_scores)\n",
    "    loss = prediction_loss + 0.5 * coordinate_loss\n",
    "    # Print loss \n",
    "    print('Classification loss',prediction_loss)\n",
    "    print(coordinate_loss)\n",
    "    print(loss)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Update the metrics\n",
    "    train_loss.update_state(y_data[:,:,:,:2], classification_scores)\n",
    "    train_bbox_loss.update_state(y_data[:,:,:,2:], bbox_scores)\n",
    "    train_accuracy.update_state(y_data[:,:,:,:2], classification_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'Loss: {}, Accuracy: {}'\n",
    "print (template.format(train_loss.result(),\n",
    "                       train_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on  training set and periodically checks\n",
    "    accuracy on the validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"    \n",
    "    with tf.device(device):\n",
    "        #compute the loss function over the classification and ovr bounding box \n",
    "        classification_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "        bbox_loss = tf.keras.losses.MeanSquaredError()        \n",
    "        \n",
    "        model = PNet()\n",
    "        optimizer = optimizer_init_fn()\n",
    "        \n",
    "        train_loss = tf.keras.metrics.BinaryCrossentropy(name='train_classification_loss')\n",
    "        train_bbox_loss = tf.keras.metrics.MeanSquaredError(name='train_bbox_loss')\n",
    "        \n",
    "        train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "            \n",
    "        #val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        val_loss = tf.keras.metrics.BinaryCrossentropy(name='val_classification_loss')\n",
    "        val_bbox_loss = tf.keras.metrics.MeanSquaredError(name='val_bbox_loss')\n",
    "\n",
    "        val_accuracy = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')\n",
    "        \n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "            train_loss.reset_states()\n",
    "            train_bbox_loss.reset_states()\n",
    "            \n",
    "            train_accuracy.reset_states()\n",
    "            \n",
    "            for x_np, y_np in train_dset:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    \n",
    "                    # Use the model function to build the forward pass.\n",
    "                    classification_scores, bbox_scores = model(x_np , training=True)\n",
    "                    prediction_loss = classification_loss(y_np[:,:,:,:2], classification_scores)\n",
    "                    coordinate_loss = bbox_loss(y_np[:,:,:,2:], bbox_scores)\n",
    "                    loss = prediction_loss + 0.5 * coordinate_loss\n",
    "                    # Print loss \n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "                    # Update the metrics\n",
    "                    train_loss.update_state(y_np[:,:,:,:2], classification_scores)\n",
    "                    train_bbox_loss.update_state(y_np[:,:,:,2:], bbox_scores)\n",
    "                    train_accuracy.update_state(y_np[:,:,:,:2], classification_scores)\n",
    "\n",
    "                   \n",
    "                    if t % print_every == 0:\n",
    "                        val_loss.reset_states()\n",
    "                        val_accuracy.reset_states()\n",
    "                        for test_x, test_y in val_dset:\n",
    "                            # During validation at end of epoch, training set to False\n",
    "                            classification_scores, bbox_scores = model(test_x, training=False)\n",
    "                            t_prediction_loss = classification_loss(test_y[:,:,:,:2], classification_scores)\n",
    "                            t_coordinate_loss = bbox_loss(test_y[:,:,:,2:], bbox_scores)\n",
    "                            t_loss = t_prediction_loss + 0.5 * t_coordinate_loss\n",
    "\n",
    "                            val_loss.update_state(test_y[:,:,:,:2], classification_scores)\n",
    "                            val_bbox_loss.update_state(test_y[:,:,:,2:], bbox_scores)\n",
    "                            val_accuracy.update_state(test_y[:,:,:,:2], classification_scores)\n",
    "                        \n",
    "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
    "                        print (template.format(t, epoch+1,\n",
    "                                             train_loss.result(),\n",
    "                                             train_accuracy.result()*100,\n",
    "                                             val_loss.result(),\n",
    "                                             val_accuracy.result()*100))\n",
    "                    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 0.6764088869094849, Accuracy: 56.25, Val Loss: 0.6777464151382446, Val Accuracy: 57.94621276855469\n",
      "Iteration 1, Epoch 1, Loss: 0.668533205986023, Accuracy: 60.15625, Val Loss: 0.6744998693466187, Val Accuracy: 56.234718322753906\n",
      "Iteration 2, Epoch 1, Loss: 0.6670225262641907, Accuracy: 59.89583206176758, Val Loss: 0.6720108985900879, Val Accuracy: 55.99021911621094\n",
      "Iteration 3, Epoch 1, Loss: 0.6783003807067871, Accuracy: 56.640625, Val Loss: 0.6694439053535461, Val Accuracy: 55.74571990966797\n",
      "Iteration 4, Epoch 1, Loss: 0.677046000957489, Accuracy: 56.25, Val Loss: 0.6670352220535278, Val Accuracy: 55.99021911621094\n",
      "Iteration 5, Epoch 1, Loss: 0.676058828830719, Accuracy: 55.72916793823242, Val Loss: 0.6645098924636841, Val Accuracy: 55.99021911621094\n",
      "Iteration 6, Epoch 1, Loss: 0.6784628033638, Accuracy: 55.13392639160156, Val Loss: 0.6619030833244324, Val Accuracy: 55.99021911621094\n",
      "Iteration 7, Epoch 1, Loss: 0.6826684474945068, Accuracy: 54.1015625, Val Loss: 0.6589927077293396, Val Accuracy: 56.72371292114258\n",
      "Iteration 8, Epoch 1, Loss: 0.6795405149459839, Accuracy: 54.16666793823242, Val Loss: 0.6558631658554077, Val Accuracy: 57.21271514892578\n",
      "Iteration 9, Epoch 1, Loss: 0.6761478185653687, Accuracy: 54.843746185302734, Val Loss: 0.6525286436080933, Val Accuracy: 57.45721435546875\n",
      "Iteration 10, Epoch 1, Loss: 0.6768800020217896, Accuracy: 54.6875, Val Loss: 0.6489967107772827, Val Accuracy: 58.19070816040039\n",
      "Iteration 11, Epoch 1, Loss: 0.6751835942268372, Accuracy: 55.20833206176758, Val Loss: 0.6453146934509277, Val Accuracy: 58.43520736694336\n",
      "Iteration 12, Epoch 1, Loss: 0.6706650853157043, Accuracy: 56.009613037109375, Val Loss: 0.6417900919914246, Val Accuracy: 58.9242057800293\n",
      "Iteration 13, Epoch 1, Loss: 0.6697126626968384, Accuracy: 56.02678680419922, Val Loss: 0.6378346085548401, Val Accuracy: 59.65769958496094\n",
      "Iteration 14, Epoch 1, Loss: 0.671692430973053, Accuracy: 55.624996185302734, Val Loss: 0.6330878138542175, Val Accuracy: 61.36919403076172\n",
      "Iteration 15, Epoch 1, Loss: 0.6698725819587708, Accuracy: 56.0546875, Val Loss: 0.6284632086753845, Val Accuracy: 62.10268783569336\n",
      "Iteration 16, Epoch 1, Loss: 0.6682423949241638, Accuracy: 56.61764907836914, Val Loss: 0.6240063905715942, Val Accuracy: 63.080684661865234\n",
      "Iteration 17, Epoch 1, Loss: 0.666496217250824, Accuracy: 56.85763931274414, Val Loss: 0.6188016533851624, Val Accuracy: 63.56968307495117\n",
      "Iteration 18, Epoch 1, Loss: 0.6651281714439392, Accuracy: 57.15460968017578, Val Loss: 0.6136521100997925, Val Accuracy: 64.30317687988281\n",
      "Iteration 19, Epoch 1, Loss: 0.6624649167060852, Accuracy: 57.421875, Val Loss: 0.6083546280860901, Val Accuracy: 65.52567291259766\n",
      "Iteration 20, Epoch 1, Loss: 0.6579737663269043, Accuracy: 58.1101188659668, Val Loss: 0.6024909019470215, Val Accuracy: 66.0146713256836\n",
      "Iteration 21, Epoch 1, Loss: 0.6549091935157776, Accuracy: 58.45170593261719, Val Loss: 0.5965163707733154, Val Accuracy: 66.50366973876953\n",
      "Iteration 22, Epoch 1, Loss: 0.6538453698158264, Accuracy: 58.423912048339844, Val Loss: 0.5905673503875732, Val Accuracy: 71.63814544677734\n",
      "Iteration 23, Epoch 1, Loss: 0.6497687697410583, Accuracy: 59.1796875, Val Loss: 0.584281861782074, Val Accuracy: 73.3496322631836\n",
      "Iteration 24, Epoch 1, Loss: 0.6460187435150146, Accuracy: 59.8125, Val Loss: 0.5772657990455627, Val Accuracy: 75.06112670898438\n",
      "Iteration 25, Epoch 1, Loss: 0.6433751583099365, Accuracy: 60.51682662963867, Val Loss: 0.5700740814208984, Val Accuracy: 76.52812194824219\n",
      "Iteration 26, Epoch 1, Loss: 0.6415340304374695, Accuracy: 61.11111068725586, Val Loss: 0.5633546113967896, Val Accuracy: 76.03911590576172\n",
      "Iteration 27, Epoch 1, Loss: 0.6386842131614685, Accuracy: 61.55133819580078, Val Loss: 0.5556010007858276, Val Accuracy: 77.26161193847656\n",
      "Iteration 28, Epoch 1, Loss: 0.6368702054023743, Accuracy: 62.17672348022461, Val Loss: 0.5478786826133728, Val Accuracy: 77.99510955810547\n",
      "Iteration 29, Epoch 1, Loss: 0.6348403692245483, Accuracy: 62.5, Val Loss: 0.5398156046867371, Val Accuracy: 77.99510955810547\n",
      "Iteration 30, Epoch 1, Loss: 0.6322435736656189, Accuracy: 62.85282516479492, Val Loss: 0.5324089527130127, Val Accuracy: 77.99510955810547\n",
      "Iteration 31, Epoch 1, Loss: 0.6320556402206421, Accuracy: 62.98828125, Val Loss: 0.5263327360153198, Val Accuracy: 78.72860717773438\n",
      "Iteration 32, Epoch 1, Loss: 0.6292946338653564, Accuracy: 63.399620056152344, Val Loss: 0.5199994444847107, Val Accuracy: 78.97309875488281\n",
      "Iteration 33, Epoch 1, Loss: 0.6286090016365051, Accuracy: 63.37316131591797, Val Loss: 0.5146142840385437, Val Accuracy: 77.99510955810547\n",
      "Iteration 34, Epoch 1, Loss: 0.6260027289390564, Accuracy: 63.88393020629883, Val Loss: 0.5105737447738647, Val Accuracy: 79.21760559082031\n",
      "Iteration 35, Epoch 1, Loss: 0.6229593753814697, Accuracy: 64.36631774902344, Val Loss: 0.5073742270469666, Val Accuracy: 78.97309875488281\n",
      "Iteration 36, Epoch 1, Loss: 0.6199181079864502, Accuracy: 64.78041076660156, Val Loss: 0.5042003989219666, Val Accuracy: 78.97309875488281\n",
      "Iteration 37, Epoch 1, Loss: 0.616513729095459, Accuracy: 65.13158416748047, Val Loss: 0.49930161237716675, Val Accuracy: 78.97309875488281\n",
      "Iteration 38, Epoch 1, Loss: 0.6145200133323669, Accuracy: 65.30448913574219, Val Loss: 0.4913077652454376, Val Accuracy: 79.95110321044922\n",
      "Iteration 39, Epoch 1, Loss: 0.6118088960647583, Accuracy: 65.546875, Val Loss: 0.48283088207244873, Val Accuracy: 80.44010162353516\n",
      "Iteration 40, Epoch 1, Loss: 0.6097297072410583, Accuracy: 65.8536605834961, Val Loss: 0.4761497676372528, Val Accuracy: 80.92909240722656\n",
      "Iteration 41, Epoch 1, Loss: 0.6066465973854065, Accuracy: 66.2202377319336, Val Loss: 0.46976783871650696, Val Accuracy: 80.19560241699219\n",
      "Iteration 42, Epoch 1, Loss: 0.603972315788269, Accuracy: 66.46076202392578, Val Loss: 0.4647577702999115, Val Accuracy: 79.95110321044922\n",
      "Iteration 43, Epoch 1, Loss: 0.600520670413971, Accuracy: 66.83238983154297, Val Loss: 0.45953771471977234, Val Accuracy: 80.44010162353516\n",
      "Iteration 44, Epoch 1, Loss: 0.5984182357788086, Accuracy: 66.93408203125, Val Loss: 0.45628148317337036, Val Accuracy: 80.92909240722656\n",
      "Iteration 45, Epoch 2, Loss: 0.48410555720329285, Accuracy: 71.875, Val Loss: 0.45260557532310486, Val Accuracy: 81.17359161376953\n",
      "Iteration 46, Epoch 2, Loss: 0.4798404574394226, Accuracy: 75.78125, Val Loss: 0.45059189200401306, Val Accuracy: 82.1515884399414\n",
      "Iteration 47, Epoch 2, Loss: 0.453511118888855, Accuracy: 78.64582824707031, Val Loss: 0.44840481877326965, Val Accuracy: 81.90708923339844\n",
      "Iteration 48, Epoch 2, Loss: 0.4870428442955017, Accuracy: 76.171875, Val Loss: 0.43925124406814575, Val Accuracy: 82.39608764648438\n",
      "Iteration 49, Epoch 2, Loss: 0.4887484610080719, Accuracy: 75.3125, Val Loss: 0.42927148938179016, Val Accuracy: 82.64058685302734\n",
      "Iteration 50, Epoch 2, Loss: 0.4945251941680908, Accuracy: 74.73957824707031, Val Loss: 0.42105644941329956, Val Accuracy: 82.39608764648438\n",
      "Iteration 51, Epoch 2, Loss: 0.5049172043800354, Accuracy: 73.88392639160156, Val Loss: 0.41970914602279663, Val Accuracy: 83.86308288574219\n",
      "Iteration 52, Epoch 2, Loss: 0.5033630728721619, Accuracy: 74.21875, Val Loss: 0.4281812012195587, Val Accuracy: 83.37408447265625\n",
      "Iteration 53, Epoch 2, Loss: 0.4993463158607483, Accuracy: 75.34722137451172, Val Loss: 0.43920910358428955, Val Accuracy: 82.1515884399414\n",
      "Iteration 54, Epoch 2, Loss: 0.49276742339134216, Accuracy: 75.9375, Val Loss: 0.44065865874290466, Val Accuracy: 82.39608764648438\n",
      "Iteration 55, Epoch 2, Loss: 0.49526646733283997, Accuracy: 76.13636016845703, Val Loss: 0.43870988488197327, Val Accuracy: 83.61858367919922\n",
      "Iteration 56, Epoch 2, Loss: 0.49925777316093445, Accuracy: 75.91145324707031, Val Loss: 0.4264216721057892, Val Accuracy: 83.37408447265625\n",
      "Iteration 57, Epoch 2, Loss: 0.49561241269111633, Accuracy: 76.32211303710938, Val Loss: 0.412858784198761, Val Accuracy: 83.37408447265625\n",
      "Iteration 58, Epoch 2, Loss: 0.4901469349861145, Accuracy: 76.67411041259766, Val Loss: 0.40827494859695435, Val Accuracy: 83.12958526611328\n",
      "Iteration 59, Epoch 2, Loss: 0.48919644951820374, Accuracy: 76.45833587646484, Val Loss: 0.40900200605392456, Val Accuracy: 82.88508605957031\n",
      "Iteration 60, Epoch 2, Loss: 0.4920887053012848, Accuracy: 76.07421875, Val Loss: 0.41456884145736694, Val Accuracy: 81.4180908203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 61, Epoch 2, Loss: 0.4952158033847809, Accuracy: 75.73529815673828, Val Loss: 0.42307302355766296, Val Accuracy: 81.90708923339844\n",
      "Iteration 62, Epoch 2, Loss: 0.4899347126483917, Accuracy: 75.78125, Val Loss: 0.4222240447998047, Val Accuracy: 82.1515884399414\n",
      "Iteration 63, Epoch 2, Loss: 0.48909100890159607, Accuracy: 75.74012756347656, Val Loss: 0.41322988271713257, Val Accuracy: 82.88508605957031\n",
      "Iteration 64, Epoch 2, Loss: 0.4824223518371582, Accuracy: 76.171875, Val Loss: 0.40260744094848633, Val Accuracy: 82.1515884399414\n",
      "Iteration 65, Epoch 2, Loss: 0.4736040532588959, Accuracy: 76.93452453613281, Val Loss: 0.39473825693130493, Val Accuracy: 83.61858367919922\n",
      "Iteration 66, Epoch 2, Loss: 0.47343331575393677, Accuracy: 76.84659576416016, Val Loss: 0.3890717327594757, Val Accuracy: 84.3520736694336\n",
      "Iteration 67, Epoch 2, Loss: 0.4727829694747925, Accuracy: 76.97010803222656, Val Loss: 0.3883194625377655, Val Accuracy: 83.12958526611328\n",
      "Iteration 68, Epoch 2, Loss: 0.4662967622280121, Accuracy: 77.66926574707031, Val Loss: 0.39373770356178284, Val Accuracy: 83.37408447265625\n",
      "Iteration 69, Epoch 2, Loss: 0.46283331513404846, Accuracy: 77.9375, Val Loss: 0.3991376459598541, Val Accuracy: 83.61858367919922\n",
      "Iteration 70, Epoch 2, Loss: 0.4629579186439514, Accuracy: 77.94471740722656, Val Loss: 0.4003300368785858, Val Accuracy: 84.59657287597656\n",
      "Iteration 71, Epoch 2, Loss: 0.46364620327949524, Accuracy: 77.89351654052734, Val Loss: 0.3969307839870453, Val Accuracy: 84.59657287597656\n",
      "Iteration 72, Epoch 2, Loss: 0.4614960551261902, Accuracy: 78.125, Val Loss: 0.3868820071220398, Val Accuracy: 84.10757446289062\n",
      "Iteration 73, Epoch 2, Loss: 0.45841190218925476, Accuracy: 78.28663635253906, Val Loss: 0.3799993097782135, Val Accuracy: 84.3520736694336\n",
      "Iteration 74, Epoch 2, Loss: 0.45657867193222046, Accuracy: 78.64582824707031, Val Loss: 0.3767430782318115, Val Accuracy: 84.10757446289062\n",
      "Iteration 75, Epoch 2, Loss: 0.45568448305130005, Accuracy: 78.57862854003906, Val Loss: 0.3809555768966675, Val Accuracy: 84.3520736694336\n",
      "Iteration 76, Epoch 2, Loss: 0.45717641711235046, Accuracy: 78.369140625, Val Loss: 0.3896718919277191, Val Accuracy: 82.64058685302734\n",
      "Iteration 77, Epoch 2, Loss: 0.4542005658149719, Accuracy: 78.5037841796875, Val Loss: 0.3921017348766327, Val Accuracy: 82.39608764648438\n",
      "Iteration 78, Epoch 2, Loss: 0.45870429277420044, Accuracy: 78.26286315917969, Val Loss: 0.37997350096702576, Val Accuracy: 82.88508605957031\n",
      "Iteration 79, Epoch 2, Loss: 0.45649975538253784, Accuracy: 78.48214721679688, Val Loss: 0.3691464066505432, Val Accuracy: 84.84107971191406\n",
      "Iteration 80, Epoch 2, Loss: 0.45501863956451416, Accuracy: 78.6892318725586, Val Loss: 0.36267751455307007, Val Accuracy: 85.8190689086914\n",
      "Iteration 81, Epoch 2, Loss: 0.453005313873291, Accuracy: 78.84291076660156, Val Loss: 0.3655979335308075, Val Accuracy: 84.3520736694336\n",
      "Iteration 82, Epoch 2, Loss: 0.44988492131233215, Accuracy: 79.02960968017578, Val Loss: 0.3733574151992798, Val Accuracy: 83.61858367919922\n",
      "Iteration 83, Epoch 2, Loss: 0.4487445056438446, Accuracy: 79.04647827148438, Val Loss: 0.3775138854980469, Val Accuracy: 83.37408447265625\n",
      "Iteration 84, Epoch 2, Loss: 0.4478718638420105, Accuracy: 79.140625, Val Loss: 0.37618470191955566, Val Accuracy: 82.88508605957031\n",
      "Iteration 85, Epoch 2, Loss: 0.4458557665348053, Accuracy: 79.23018646240234, Val Loss: 0.37300732731819153, Val Accuracy: 83.37408447265625\n",
      "Iteration 86, Epoch 2, Loss: 0.44353145360946655, Accuracy: 79.38988494873047, Val Loss: 0.36410701274871826, Val Accuracy: 84.84107971191406\n",
      "Iteration 87, Epoch 2, Loss: 0.44263795018196106, Accuracy: 79.46947479248047, Val Loss: 0.3564089834690094, Val Accuracy: 84.59657287597656\n",
      "Iteration 88, Epoch 2, Loss: 0.4400416314601898, Accuracy: 79.65198516845703, Val Loss: 0.3562341034412384, Val Accuracy: 83.86308288574219\n",
      "Iteration 89, Epoch 2, Loss: 0.43809157609939575, Accuracy: 79.7697982788086, Val Loss: 0.3641699254512787, Val Accuracy: 83.37408447265625\n",
      "Iteration 90, Epoch 3, Loss: 0.4291287362575531, Accuracy: 73.4375, Val Loss: 0.37442559003829956, Val Accuracy: 83.86308288574219\n",
      "Iteration 91, Epoch 3, Loss: 0.388447642326355, Accuracy: 79.6875, Val Loss: 0.3801266849040985, Val Accuracy: 83.61858367919922\n",
      "Iteration 92, Epoch 3, Loss: 0.35872676968574524, Accuracy: 82.29167175292969, Val Loss: 0.38073253631591797, Val Accuracy: 83.61858367919922\n",
      "Iteration 93, Epoch 3, Loss: 0.3982287049293518, Accuracy: 79.6875, Val Loss: 0.36384034156799316, Val Accuracy: 82.88508605957031\n",
      "Iteration 94, Epoch 3, Loss: 0.39928027987480164, Accuracy: 80.0, Val Loss: 0.3482860326766968, Val Accuracy: 84.84107971191406\n",
      "Iteration 95, Epoch 3, Loss: 0.4108790159225464, Accuracy: 78.64582824707031, Val Loss: 0.33980435132980347, Val Accuracy: 85.57456970214844\n",
      "Iteration 96, Epoch 3, Loss: 0.4176059663295746, Accuracy: 78.34821319580078, Val Loss: 0.34327366948127747, Val Accuracy: 86.30806732177734\n",
      "Iteration 97, Epoch 3, Loss: 0.41804417967796326, Accuracy: 78.3203125, Val Loss: 0.3604070842266083, Val Accuracy: 86.55256652832031\n",
      "Iteration 98, Epoch 3, Loss: 0.41966700553894043, Accuracy: 78.47222137451172, Val Loss: 0.3795917332172394, Val Accuracy: 85.8190689086914\n",
      "Iteration 99, Epoch 3, Loss: 0.4144743084907532, Accuracy: 78.75, Val Loss: 0.38752099871635437, Val Accuracy: 85.57456970214844\n",
      "Iteration 100, Epoch 3, Loss: 0.4220777451992035, Accuracy: 78.69318389892578, Val Loss: 0.3893125057220459, Val Accuracy: 85.57456970214844\n",
      "Iteration 101, Epoch 3, Loss: 0.429563045501709, Accuracy: 78.38542175292969, Val Loss: 0.3765871524810791, Val Accuracy: 86.06356811523438\n",
      "Iteration 102, Epoch 3, Loss: 0.4282055199146271, Accuracy: 78.72596740722656, Val Loss: 0.3573906719684601, Val Accuracy: 87.04156494140625\n",
      "Iteration 103, Epoch 3, Loss: 0.4233291745185852, Accuracy: 79.01786041259766, Val Loss: 0.34687623381614685, Val Accuracy: 87.04156494140625\n",
      "Iteration 104, Epoch 3, Loss: 0.41759663820266724, Accuracy: 79.47916412353516, Val Loss: 0.3438933789730072, Val Accuracy: 84.59657287597656\n",
      "Iteration 105, Epoch 3, Loss: 0.42032113671302795, Accuracy: 79.39453125, Val Loss: 0.3481053113937378, Val Accuracy: 84.84107971191406\n",
      "Iteration 106, Epoch 3, Loss: 0.42414048314094543, Accuracy: 79.31985473632812, Val Loss: 0.3571620583534241, Val Accuracy: 83.37408447265625\n",
      "Iteration 107, Epoch 3, Loss: 0.4201444387435913, Accuracy: 79.34027862548828, Val Loss: 0.36227741837501526, Val Accuracy: 82.64058685302734\n",
      "Iteration 108, Epoch 3, Loss: 0.4176136553287506, Accuracy: 79.44078826904297, Val Loss: 0.3603500425815582, Val Accuracy: 83.37408447265625\n",
      "Iteration 109, Epoch 3, Loss: 0.411923348903656, Accuracy: 79.765625, Val Loss: 0.3546660840511322, Val Accuracy: 83.86308288574219\n",
      "Iteration 110, Epoch 3, Loss: 0.40258294343948364, Accuracy: 80.4315414428711, Val Loss: 0.3474288582801819, Val Accuracy: 84.10757446289062\n",
      "Iteration 111, Epoch 3, Loss: 0.4046591818332672, Accuracy: 80.3977279663086, Val Loss: 0.3388611376285553, Val Accuracy: 84.59657287597656\n",
      "Iteration 112, Epoch 3, Loss: 0.4065467119216919, Accuracy: 80.36685180664062, Val Loss: 0.33189526200294495, Val Accuracy: 86.06356811523438\n",
      "Iteration 113, Epoch 3, Loss: 0.40080761909484863, Accuracy: 80.72917175292969, Val Loss: 0.3325463533401489, Val Accuracy: 85.8190689086914\n",
      "Iteration 114, Epoch 3, Loss: 0.39728957414627075, Accuracy: 81.0, Val Loss: 0.337920606136322, Val Accuracy: 86.55256652832031\n",
      "Iteration 115, Epoch 3, Loss: 0.3978877067565918, Accuracy: 80.88941955566406, Val Loss: 0.34313860535621643, Val Accuracy: 87.28606414794922\n",
      "Iteration 116, Epoch 3, Loss: 0.39900246262550354, Accuracy: 80.96064758300781, Val Loss: 0.3452799320220947, Val Accuracy: 87.28606414794922\n",
      "Iteration 117, Epoch 3, Loss: 0.3963751196861267, Accuracy: 81.13838958740234, Val Loss: 0.33955666422843933, Val Accuracy: 87.53056335449219\n",
      "Iteration 118, Epoch 3, Loss: 0.39278513193130493, Accuracy: 81.35775756835938, Val Loss: 0.33434924483299255, Val Accuracy: 87.53056335449219\n",
      "Iteration 119, Epoch 3, Loss: 0.39071688055992126, Accuracy: 81.5625, Val Loss: 0.32904052734375, Val Accuracy: 86.55256652832031\n",
      "Iteration 120, Epoch 3, Loss: 0.3906804323196411, Accuracy: 81.55242156982422, Val Loss: 0.3275505304336548, Val Accuracy: 85.330078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 121, Epoch 3, Loss: 0.39132511615753174, Accuracy: 81.34765625, Val Loss: 0.3305686414241791, Val Accuracy: 85.330078125\n",
      "Iteration 122, Epoch 3, Loss: 0.3868938684463501, Accuracy: 81.7234878540039, Val Loss: 0.33431872725486755, Val Accuracy: 84.84107971191406\n",
      "Iteration 123, Epoch 3, Loss: 0.3911616802215576, Accuracy: 81.43382263183594, Val Loss: 0.33027932047843933, Val Accuracy: 85.08557891845703\n",
      "Iteration 124, Epoch 3, Loss: 0.38915443420410156, Accuracy: 81.5625, Val Loss: 0.32594749331474304, Val Accuracy: 85.57456970214844\n",
      "Iteration 125, Epoch 3, Loss: 0.3878253698348999, Accuracy: 81.77082824707031, Val Loss: 0.32168149948120117, Val Accuracy: 86.55256652832031\n",
      "Iteration 126, Epoch 3, Loss: 0.38677746057510376, Accuracy: 81.75675964355469, Val Loss: 0.32063230872154236, Val Accuracy: 86.55256652832031\n",
      "Iteration 127, Epoch 3, Loss: 0.38380110263824463, Accuracy: 81.90789031982422, Val Loss: 0.32283371686935425, Val Accuracy: 86.79706573486328\n",
      "Iteration 128, Epoch 3, Loss: 0.38225507736206055, Accuracy: 82.05128479003906, Val Loss: 0.32582566142082214, Val Accuracy: 86.55256652832031\n",
      "Iteration 129, Epoch 3, Loss: 0.38164207339286804, Accuracy: 82.109375, Val Loss: 0.3283759355545044, Val Accuracy: 85.330078125\n",
      "Iteration 130, Epoch 3, Loss: 0.3795941174030304, Accuracy: 82.20274353027344, Val Loss: 0.33088821172714233, Val Accuracy: 85.57456970214844\n",
      "Iteration 131, Epoch 3, Loss: 0.3775734305381775, Accuracy: 82.36607360839844, Val Loss: 0.32758328318595886, Val Accuracy: 86.06356811523438\n",
      "Iteration 132, Epoch 3, Loss: 0.3770394027233124, Accuracy: 82.41278839111328, Val Loss: 0.32102686166763306, Val Accuracy: 86.79706573486328\n",
      "Iteration 133, Epoch 3, Loss: 0.37523385882377625, Accuracy: 82.56391906738281, Val Loss: 0.31721383333206177, Val Accuracy: 86.30806732177734\n",
      "Iteration 134, Epoch 3, Loss: 0.3734535276889801, Accuracy: 82.6996841430664, Val Loss: 0.31847935914993286, Val Accuracy: 85.8190689086914\n"
     ]
    }
   ],
   "source": [
    "#device = '/device:GPU:0'   # Change this to a CPU/GPU as you wish!\n",
    "device = '/cpu:0'        # Change this to a CPU/GPU as you wish!\n",
    "print_every = 1\n",
    "num_epochs = 3\n",
    "\n",
    "model = PNet()\n",
    "\n",
    "def model_init_fn():\n",
    "    return PNet()\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    learning_rate = 1e-3\n",
    "    return tf.keras.optimizers.Adam(learning_rate) \n",
    "    #return tf.keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "train(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12, 12, 3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[10:11,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_scores, bbox_scores = model(X_train[11:12,:,:,:], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0.45885938 0.5411406 ]]]], shape=(1, 1, 1, 2), dtype=float32)\n",
      "tf.Tensor([[[[-0.22488847 -0.08204336  0.14587773 -0.12911837]]]], shape=(1, 1, 1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(classification_scores)\n",
    "print(bbox_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.         0.         0.25       0.08333333 1.         0.41666667]]]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[11:12,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        #Initialize training\n",
    "        sess = tf.compat.v1.Session()\n",
    "        #train_net=PNet(sess)\n",
    "        train_net=PNet()\n",
    "        bimg=tf.compat.v1.placeholder(tf.float32, shape=(100,12,12,3))\n",
    "        bprob=tf.compat.v1.placeholder(tf.float32, shape=(100,1,1,2))\n",
    "        bprobmask=tf.compat.v1.placeholder(tf.float32, shape=(100,1))\n",
    "        bcoord=tf.compat.v1.placeholder(tf.float32, shape=(100,1,1,4))\n",
    "        loss=tf.reduce_mean(tf.square(bprob-train_net.get_layer('conv4-1')))+bprobmask*0.5*tf.reduce_mean(tf.square(bcoord-train_net.get_layer('conv4-2')))\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train = optimizer.minimize(loss)\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        #Test\n",
    "        img=cv2.imread(\"1.bmp\")\n",
    "        img1=(img-127.5)/128.0\n",
    "        img2=np.expand_dims(img1, 0)\n",
    "        print(train_net.feed(img2))\n",
    "        \n",
    "        #Grab a batch of images, probs, and coordinates, and feed into training\n",
    "        for j in range(10):\n",
    "            i=0\n",
    "            f=100\n",
    "            while f<len(prob):\n",
    "                batchimg=images[i:f]\n",
    "                batchprob=prob[i:f]\n",
    "                k=np.array(prob[i:f])\n",
    "                k1=np.reshape(k,(100,2))\n",
    "                k2=k1[:,1]*1.0\n",
    "                k3=np.reshape(k2,(100,1))\n",
    "                batchprobmask=k3\n",
    "                batchcoord=coordinates[i:f]\n",
    "                i=i+100\n",
    "                f=f+100\n",
    "                sess.run(train,feed_dict={'pnet/input:0': batchimg, bprob: batchprob, bcoord: batchcoord,bprobmask:batchprobmask})\n",
    "            print(train_net.feed(img2))\n",
    "\n",
    "        tf.trainable_variables()\n",
    "        wt=np.load('./data/mtcnn_weights.npy')\n",
    "\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv1/weights:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv1']['weights']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv1/biases:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv1']['biases']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/prelu1/alpha:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['prelu1']['alpha']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/prelu2/alpha:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['prelu2']['alpha']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/prelu3/alpha:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['prelu3']['alpha']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv2/weights:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv2']['weights']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv2/biases:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv2']['biases']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv3/weights:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv3']['weights']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv3/biases:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv3']['biases']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv4-1/weights:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv4-1']['weights']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv4-1/biases:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv4-1']['biases']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv4-2/weights:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv4-2']['weights']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv4-2/biases:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv4-2']['biases']=w1[0]\n",
    "        np.save('./data/mtcnn_weights.npy',wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing an image\n",
    "img=cv2.imread(\"1.bmp\")\n",
    "img1=(img-127.5)/128.0\n",
    "img2=np.expand_dims(img1, 0)\n",
    "print(train_net.feed(img2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct coordinates: 1.bmp: [0.25,0,1,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
