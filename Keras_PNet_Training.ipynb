{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Outputs\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACES_PATH = '../data/face_detection/faces/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 6000\n",
    "\n",
    "def read_pos_images():\n",
    "    #Read positive images:\n",
    "    path, __, filenames = next(os.walk(FACES_PATH+'pos_train/'))\n",
    "    file_count = training_size #len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[0.0,1.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    file = open(FACES_PATH+'coordinates.txt','r')\n",
    "    lines = file.readlines()\n",
    "    lines = [line[:-1] for line in lines]\n",
    "    #idx=[1,0,3,2]\n",
    "    idx=[0,1,2,3]\n",
    "    f_count = 0\n",
    "    for line in lines:\n",
    "        line = line.split(\" \")\n",
    "        line = line[1]\n",
    "        line=line[1:-1]\n",
    "        line = line.split(\",\")\n",
    "        #Transpose coordinates\n",
    "        x=0\n",
    "        nline=[]\n",
    "        for i in idx:\n",
    "            nline.append(line[i])\n",
    "            x=x+1\n",
    "        line=[[[float(c) for c in nline]]]\n",
    "        coordinates.append(line)\n",
    "        f_count = f_count+1\n",
    "        if f_count == file_count:\n",
    "            break\n",
    "    #Return images, probs, and coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "def read_neg_images():\n",
    "    #Read negative images:\n",
    "    path, __, filenames = next(os.walk(FACES_PATH+'neg_train/'))\n",
    "    file_count = training_size #len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[1.0,0.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    for i in range(file_count):\n",
    "        coordinates.append([[[0.0,0.0,0.0,0.0]]])\n",
    "    #Return images, prob, coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "#Read in all images, probabilities, and coordinates\n",
    "pimages, pprob, pcoordinates = read_pos_images()\n",
    "nimages, nprob, ncoordinates = read_neg_images()\n",
    "o_images=np.append(pimages,nimages,axis=0)\n",
    "o_images=np.reshape(o_images,(-1,12,12,3))\n",
    "o_prob=pprob+nprob\n",
    "o_coordinates=pcoordinates+ncoordinates\n",
    "\n",
    "#Shuffle them up using an index\n",
    "idx=np.arange(len(o_prob))\n",
    "np.random.shuffle(idx)\n",
    "images=np.empty_like(o_images)\n",
    "c=0\n",
    "for i in idx:\n",
    "    images[c]=o_images[i]\n",
    "    c=c+1\n",
    "#images=(np.float32)(images-127.5)/128.0\n",
    "images=(np.float32)(images)/255\n",
    "\n",
    "#images = np.transpose(images, (0, 2, 1, 3)) #Transpose images\n",
    "prob=[]\n",
    "for i in idx:\n",
    "    prob.append(o_prob[i])\n",
    "coordinates=[]\n",
    "for i in idx:\n",
    "    coordinates.append(o_coordinates[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train , Image batch shape ', images.shape)\n",
    "print('y_train , Classification ground true batch shape ' ,np.array(prob).shape)\n",
    "print('y_train , Coordinates ground true batch shape ', np.array(coordinates).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X_data for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_data shape',X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create \"y_data\" for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.concatenate((np.array(prob), np.array(coordinates)), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('y_data shape',y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('y_data Classification shape', y_data[:,:,:,:2].shape)\n",
    "print('y_data Coordinate shape',y_data[:,:,:,2:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide dataset to \"train', \"val\" and \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X, y, training_prec = 0.7, val_prec = 0.1, test_prec = 0.2):\n",
    "        data_length = len(X)\n",
    "        num_training = np.int(data_length * training_prec)\n",
    "        num_validation = np.int(data_length * val_prec)\n",
    "        \n",
    "        mask = range(num_training)\n",
    "        X_train = X[mask]\n",
    "        y_train = y[mask]\n",
    "        mask = range(num_training, num_training + num_validation)\n",
    "        X_val = X[mask]\n",
    "        y_val = y[mask]\n",
    "        mask = range(num_training + num_validation, data_length)\n",
    "        X_test = X[mask]\n",
    "        y_test = y[mask]\n",
    "        \n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data(X_data, y_data)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build P-Net Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import MaxPooling2D, Conv2D, Input, Layer, Concatenate, concatenate\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "#from keras.layers.wrappers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PNet():\n",
    "    \n",
    "    initializer = tf.keras.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "    # input layer\n",
    "    visible = Input(shape=(12,12,3))\n",
    "    \n",
    "    # CNN Stage 1\n",
    "    conv1 = Conv2D(10, kernel_size=(3,3))(visible)\n",
    "    prelu1 = PReLU(alpha_initializer='zero', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(prelu1)\n",
    "   \n",
    "    #CNN Stage 2\n",
    "    conv2 = Conv2D(16, kernel_size=(3,3))(pool1)\n",
    "    prelu2 = PReLU(alpha_initializer='zero', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(conv2)\n",
    "    \n",
    "    # CNN stage 3\n",
    "    conv3 = Conv2D(32, kernel_size=(3,3),)(prelu2)\n",
    "    prelu3 = PReLU(alpha_initializer='zero', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(conv3)\n",
    "    \n",
    "    # output \n",
    "    pred_classification = Conv2D(2, kernel_size=(1,1), activation='softmax', name='classification')(prelu3)\n",
    "    pred_bbox = Conv2D(4, kernel_size=(1,1), name='bbox')(prelu3)\n",
    "    \n",
    "    model = Model(inputs=visible, outputs=[pred_classification, pred_bbox])\n",
    "                  \n",
    " \n",
    "    #compute the loss function over bounding box \n",
    "    bbox_loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # Define bbox loss : MSE(bounding_bbox) * y_classification[1] (...ignore if no face)\n",
    "    # Actually, \n",
    "    # we could use 'mse' but because bbox error is \"zero\" if \"no face\", we need to multiply 'mse' by \"y_classification\"  \n",
    "    def bbox_loss_fn():\n",
    "            #Create boox loss function \n",
    "        def loss(y_true,y_pred):\n",
    "            return (bbox_loss(pred_bbox, y_bbox) * y_classification[:,:,:,1])\n",
    "        # Return a function\n",
    "        return loss\n",
    "    \n",
    " \n",
    "    # create placeholder for targets\n",
    "    y_classification = tf.keras.backend.placeholder(dtype='float32', shape=pred_classification.shape) # shapes of output1 your target has\n",
    "    y_bbox = tf.keras.backend.placeholder(dtype='float32', shape=pred_bbox.shape) # shapes of output2 your target has\n",
    "    \n",
    "    # Set optimizer\n",
    "    learning_rate = 1e-3\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=adam, \n",
    "                  loss ={'classification': 'binary_crossentropy',\n",
    "                         'bbox': bbox_loss_fn()},\n",
    "                  loss_weights = {'classification': 1.0, \n",
    "                                  'bbox': 0.5},\n",
    "                  target_tensors=[y_classification,y_bbox],\n",
    "                  metrics={'classification': 'accuracy',\n",
    "                           'bbox': 'mse'})\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    # plot graph\n",
    "    plot_model(model, to_file='multiple_outputs.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, [y_train[:,:,:,:2],y_train[:,:,:,2:]], batch_size=64, epochs=50,\n",
    "          validation_data=(X_val, [y_val[:,:,:,:2],y_val[:,:,:,2:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the PNet  to ensure that the implementation does not crash and produces outputs of the expected shape.\n",
    "Pnet will output are:\n",
    "1. Face classification,  size (batch,1,1,2) for 2 calss classification, \"Face\", and \"Not face\"\n",
    "2. Bounding box  (batch,1,1,4) for 4 boundind box corrdinates (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('P-Net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[['loss', 'val_loss']].plot(figsize=(8,5))\n",
    "plt.title('P-Net model loss vs. epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[['classification_accuracy', 'val_classification_accuracy']].plot(figsize=(8,5))\n",
    "plt.title('P-Net model accuracy vs. epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = predictions[0]\n",
    "bbox = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.squeeze(score)\n",
    "bbox = np.squeeze(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_score = np.squeeze(y_test[:,:,:,:2])\n",
    "y_test_bbox = np.squeeze(y_test[:,:,:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_score, np.round(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_score, np.round(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test_score[:,1:2], np.round(score[:,1:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score[10:20,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_testset(index):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(2, 2))\n",
    "    ax.imshow(X_test[index])\n",
    "    plt.title(score[index,1:])\n",
    "    # Create a Rectangle patch\n",
    "    x = round(12*bbox[index,0])\n",
    "    y = round(12*bbox[index,1])\n",
    "    w = round(12*bbox[index,2]) - x\n",
    "    h = round(12*bbox[index,3]) - y\n",
    "    rect = patches.Rectangle((x,y),w,h,linewidth=1,edgecolor='r',facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_testset(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(test_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
